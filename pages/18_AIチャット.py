# -*- coding: utf-8 -*-
# pages/18_AIãƒãƒ£ãƒƒãƒˆ.py
from __future__ import annotations

import os
import json
from typing import Optional, List, Dict, Any

import streamlit as st
import docx
from openai import OpenAI

from config.config import has_gemini_api_key, DEFAULT_USDJPY, estimate_tokens_from_text
from lib.gemini_responder import GeminiResponder
from lib.costs_new import estimate_chat_cost, ChatUsage


# ============================================================
# Page
# ============================================================
st.set_page_config(
    page_title="ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆGPT / Geminiï¼‰",
    page_icon="ğŸ’¬",
    layout="wide",
)

st.title("ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆGPT / Geminiï¼‰")
st.caption(
    "æ–‡æ›¸ã‚’ä¼šè©±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‰æï¼‰ã¨ã—ã¦ã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
    " æ–‡æ›¸ãŒãªãã¦ã‚‚é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆã¨ã—ã¦ä½¿ãˆã¾ã™ã€‚"
)

# ============================================================
# ã€ç½®æ›ã€‘Sidebar: settingsï¼ˆã“ã®ãƒ–ãƒ­ãƒƒã‚¯å…¨ä½“ã‚’ç½®ãæ›ãˆï¼‰
# ç½®æ›ç¯„å›²ï¼š
#   with st.sidebar: ã‹ã‚‰
#   col_b ã®ã€Œæ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã€ãƒœã‚¿ãƒ³å‡¦ç†ã® ëï¼ˆst.rerun()ï¼‰ã¾ã§
# ã‚’ã€ä¸‹ã®ãƒ–ãƒ­ãƒƒã‚¯ã«ä¸¸ã”ã¨ç½®æ›ã—ã¦ãã ã•ã„ã€‚
# ============================================================
with st.sidebar:
    st.header("è¨­å®š")

    OPENAI_MODELS = ["gpt-5-mini", "gpt-5-nano"]
    GEMINI_MODELS = ["gemini-2.0-flash"]

    model_options = list(OPENAI_MODELS)
    if has_gemini_api_key():
        model_options += GEMINI_MODELS

    chat_model = st.radio(
        "ãƒ¢ãƒ‡ãƒ«",
        model_options,
        index=0,
        help="Gemini ã¯ API ã‚­ãƒ¼è¨­å®šæ™‚ã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚",
    )

    max_output_tokens = st.number_input(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¸Šé™ï¼‰",
        min_value=256,
        max_value=20000,
        value=10000,
        step=256,
    )

    debug_mode = st.toggle("ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º", value=False)

    st.caption(f"ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼ˆæ¦‚ç®—ï¼‰: {DEFAULT_USDJPY:.2f} JPY/USD")

    st.divider()

    col_a, col_b = st.columns(2)
    with col_a:
        if st.button("ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="btn_reset_chat"):
            st.session_state.pop("chat_messages", None)
            st.session_state.pop("chat_costs", None)
            st.session_state.pop("openai_prev_response_id", None)
            st.session_state.pop("chat_draft_key", None)
            st.rerun()

    with col_b:
        if st.button("æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢", key="btn_clear_docctx"):
            st.session_state.pop("doc_context", None)
            st.rerun()

    # ============================================================
    # å±¥æ­´ï¼šãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ / ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆJSON / TXTï¼‰
    # ============================================================
    st.divider()
    st.subheader("å±¥æ­´ï¼ˆä¿å­˜/å¾©å…ƒï¼‰")

    # --- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä»Šã‚ã‚‹å±¥æ­´ã‚’ãã®ã¾ã¾æ­£æœ¬ã¨ã—ã¦æ‰±ã†ï¼‰---
    messages = st.session_state.get("chat_messages", []) or []

    payload = {
        "schema": "chat_history_v1",
        "model": st.session_state.get("chat_model", None) or chat_model,
        "openai_prev_response_id": st.session_state.get("openai_prev_response_id"),
        "doc_context": st.session_state.get("doc_context"),  # âœ… è¿½åŠ ï¼šå‰ææ–‡æ›¸ã‚‚ä¿å­˜
        "messages": messages,
    }

    # TXTæ•´å½¢
    def _history_as_text(msgs):
        lines = []

        # ===== ã“ã“ã‹ã‚‰è¿½åŠ ï¼ˆæ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ˆé ­ã«æ›¸ãï¼‰=====
        ctx = st.session_state.get("doc_context")
        if ctx and (ctx.get("text") or "").strip():
            kind = ctx.get("kind", "")
            text = ctx.get("text", "")
            head = text[:1000]
            lines.append(
                f"ã€å‰ææ–‡æ›¸: {kind} / ç´„ {len(text)} æ–‡å­— / å…ˆé ­1000æ–‡å­—ã€‘\n{head}"
            )
            lines.append("")  # ç©ºè¡Œ
        # ===== ã“ã“ã¾ã§è¿½åŠ  =====

        for m in msgs:
            role = (m.get("role") or "").strip()
            content = (m.get("content") or "").rstrip()
            if not content:
                continue
            if role == "user":
                lines.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼:\n" + content)
            elif role == "assistant":
                lines.append("AI:\n" + content)
            else:
                lines.append(f"{role}:\n" + content)
            lines.append("")  # blank line
        return "\n".join(lines).strip() + "\n"

    json_str = json.dumps(payload, ensure_ascii=False, indent=2)
    txt_str = _history_as_text(messages)

    # --- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆJSON / TXTï¼‰---
    st.download_button(
        "â¬‡ï¸ å±¥æ­´ã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=json_str.encode("utf-8"),
        file_name="chat_history.json",
        mime="application/json",
        disabled=(len(messages) == 0),
        key="dl_history_json",
    )

    st.download_button(
        "â¬‡ï¸ å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=txt_str.encode("utf-8"),
        file_name="chat_history.txt",
        mime="text/plain",
        disabled=(len(messages) == 0),
        key="dl_history_txt",
    )

    st.caption("â€» JSONã¯å¾©å…ƒç”¨ã®æ­£æœ¬ã€TXTã¯èª­ã¿ã‚„ã™ã„ãƒ­ã‚°ã§ã™ã€‚")

    # --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆJSONï¼‰---
    up = st.file_uploader(
        "â¬†ï¸ å±¥æ­´JSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å¾©å…ƒ",
        type=["json"],
        key="upl_history_json",
        help="chat_history.jsonï¼ˆschema=chat_history_v1ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
    )

    def _validate_messages(obj):
        if not isinstance(obj, list):
            return False
        for m in obj:
            if not isinstance(m, dict):
                return False
            if m.get("role") not in ("user", "assistant", "system"):
                return False
            if not isinstance(m.get("content", ""), str):
                return False
        return True

    # âœ… ãƒœã‚¿ãƒ³æŠ¼ä¸‹ã§ã®ã¿å¾©å…ƒã™ã‚‹ï¼ˆè‡ªå‹•å¾©å…ƒã—ãªã„ï¼‰
    restore_clicked = st.button(
        "âœ… ã“ã®JSONã§å±¥æ­´ã‚’å¾©å…ƒ",
        type="primary",
        disabled=(up is None),
        key="btn_restore_history",
        help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸJSONã‚’èª­ã¿è¾¼ã¿ã€å±¥æ­´ã‚’ç½®ãæ›ãˆã¾ã™ã€‚",
    )


    if restore_clicked:
        try:
            raw = up.read()
            if not raw:
                st.error("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸJSONãŒç©ºã§ã™ï¼ˆreadçµæœãŒç©ºï¼‰ã€‚ã‚‚ã†ä¸€åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                st.stop()

            loaded = json.loads(raw.decode("utf-8", errors="ignore"))

            # âœ… doc_context ã‚’å–ã‚Šå‡ºã™ï¼ˆç„¡ã‘ã‚Œã° Noneï¼‰
            restored_docctx = None
            if isinstance(loaded, dict):
                restored_docctx = loaded.get("doc_context")

            # v1å½¢å¼ï¼ˆæ¨å¥¨ï¼‰ï¼š{"schema":"chat_history_v1","messages":[...]}
            if isinstance(loaded, dict) and "messages" in loaded:
                msgs = loaded.get("messages")
            else:
                # äº’æ›ï¼šmessagesé…åˆ—ã ã‘ã®JSONã‚‚å—ã‘ã‚‹
                msgs = loaded

            if not _validate_messages(msgs):
                st.error("ã“ã®JSONã¯å±¥æ­´å½¢å¼ã¨ã—ã¦ä¸æ­£ã§ã™ï¼ˆmessagesã®æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰ã€‚")
                st.stop()

            st.session_state.chat_messages = msgs

            # âœ… doc_context ã‚’å¾©å…ƒï¼ˆæ§‹é€ ãƒã‚§ãƒƒã‚¯ã—ã¦ã‹ã‚‰å…¥ã‚Œã‚‹ï¼‰
            if isinstance(restored_docctx, dict):
                kind = restored_docctx.get("kind")
                text = restored_docctx.get("text")
                if isinstance(kind, str) and isinstance(text, str) and text.strip():
                    st.session_state.doc_context = {"kind": kind, "text": text}
                else:
                    st.session_state.pop("doc_context", None)
            else:
                st.session_state.pop("doc_context", None)

            # æ–™é‡‘ã‚„ OpenAI ç¶™ç¶šID ã¯äº‹æ•…é˜²æ­¢ã®ãŸã‚ãƒªã‚»ãƒƒãƒˆ
            st.session_state.chat_costs = []
            st.session_state.openai_prev_response_id = None
            st.session_state.chat_draft_key = (st.session_state.get("chat_draft_key", 0) or 0) + 1

            doc_note = ""
            ctx2 = st.session_state.get("doc_context")
            if ctx2 and (ctx2.get("text") or "").strip():
                doc_note = f" / doc_context: {ctx2.get('kind','')} / ç´„ {len(ctx2.get('text',''))} æ–‡å­—"

            st.success(
                f"âœ… å±¥æ­´ã‚’å¾©å…ƒã—ã¾ã—ãŸï¼ˆ{len(msgs)}ä»¶ï¼‰ã€‚OpenAIã®ä¼šè©±ç¶™ç¶šIDã¯ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚{doc_note}"
            )
            st.rerun()

        except Exception as e:
            st.error(f"å±¥æ­´JSONã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

            

# ============================================================
# Helpers
# ============================================================
def get_openai_client() -> OpenAI:
    api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
    if not api_key:
        raise RuntimeError(
            "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.streamlit/secrets.toml` ã« OPENAI_API_KEY ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
        )
    return OpenAI(api_key=api_key)


def is_gemini_model(m: str) -> bool:
    return m.startswith("gemini-")


def _ensure_state() -> None:
    if "chat_messages" not in st.session_state:
        # è¡¨ç¤ºç”¨ã®å±¥æ­´ï¼ˆsystemã¯ä¿æŒã—ãªã„ï¼è¡¨ç¤ºã‚‚ã—ãªã„ï¼‰
        st.session_state.chat_messages = []  # List[Dict[str,str]]
    if "chat_costs" not in st.session_state:
        st.session_state.chat_costs = []  # 1ã‚¿ãƒ¼ãƒ³ã”ã¨ã®æ¦‚ç®—ãƒ­ã‚°
    if "chat_draft_key" not in st.session_state:
        st.session_state.chat_draft_key = 0
    # äº’æ›ã®ãŸã‚æ®‹ã™ãŒã€Bæ–¹å¼ï¼ˆå±¥æ­´ã‚’inputã«æ¸¡ã™ï¼‰ã§ã¯ä½¿ç”¨ã—ãªã„
    if "openai_prev_response_id" not in st.session_state:
        st.session_state.openai_prev_response_id = None


def _get_doc_context_text() -> str:
    ctx = st.session_state.get("doc_context")
    if not ctx:
        return ""
    kind = (ctx.get("kind") or "").strip()
    text = (ctx.get("text") or "").strip()
    if not text:
        return ""
    max_chars = 15000
    used = text[:max_chars]
    return f"ã€ä¼šè©±ã®å‰ææ–‡æ›¸ï¼š{kind}ï¼ˆå…ˆé ­ã€œæœ€å¤§{max_chars}æ–‡å­—ï¼‰ã€‘\n{used}\n"


def _build_openai_instructions() -> str:
    """
    Responses API ã¯ previous_response_id ã‚’ä½¿ã†å ´åˆã§ã‚‚
    instructions ã¯ã€Œå‰å›ã®instructionsã‚’å¼•ãç¶™ãŒãªã„ã€ä»•æ§˜ãªã®ã§æ¯å›æ¸¡ã™ã€‚
    """
    base = "ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    doc_text = _get_doc_context_text()
    if doc_text:
        base += (
            "\n\nä»¥ä¸‹ã¯ä¼šè©±ã®å‰æã¨ãªã‚‹å‚è€ƒæ–‡æ›¸ã§ã™ã€‚"
            "ã“ã®æ–‡æ›¸ã«åŸºã¥ãè³ªå•ã«ã¯æ–‡æ›¸ã«æ²¿ã£ã¦ç­”ãˆã€æ–‡æ›¸ã«ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšä¸æ˜ã¨è¨€ã£ã¦ãã ã•ã„ã€‚\n\n"
            + doc_text
        )
    return base


def _build_gemini_prompt_from_history(latest_user_text: str) -> str:
    """
    GeminiResponder.complete ã¯ system_instruction + user_content ãªã®ã§
    user_contentå´ã«å±¥æ­´ã‚’ã¾ã¨ã‚ã¦æ¸¡ã—ã¦ä¼šè©±ç¶™ç¶šã‚’æ“¬ä¼¼çš„ã«å®Ÿç¾ã€‚
    """
    doc_text = _get_doc_context_text()

    lines = []
    for m in st.session_state.chat_messages:
        role = m.get("role")
        if role == "user":
            lines.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {m.get('content','')}")
        elif role == "assistant":
            lines.append(f"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {m.get('content','')}")

    history_block = "\n".join(lines).strip()

    parts = []
    if doc_text:
        parts.append(
            "ä»¥ä¸‹ã¯ä¼šè©±ã®å‰æã¨ãªã‚‹å‚è€ƒæ–‡æ›¸ã§ã™ã€‚"
            "ã“ã®æ–‡æ›¸ã«åŸºã¥ãè³ªå•ã«ã¯æ–‡æ›¸ã«æ²¿ã£ã¦ç­”ãˆã€æ–‡æ›¸ã«ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšä¸æ˜ã¨è¨€ã£ã¦ãã ã•ã„ã€‚\n\n"
            + doc_text
        )
    if history_block:
        parts.append("ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n" + history_block)
    parts.append("ã€ä»Šå›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã€‘\n" + latest_user_text)
    parts.append("ã€æŒ‡ç¤ºã€‘\nä¸å¯§ãªæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªã‚‰ç¢ºèªè³ªå•ã‚’æœ€å°é™ã«ã—ã¦ãã ã•ã„ã€‚")

    return "\n\n".join(parts).strip()


def _safe_response_text_from_responses_api(resp: Any) -> str:
    """
    Responses API ã®è¿”ã‚Šå€¤ã‹ã‚‰ã€Œè¦‹ã¤ã‹ã‚‹é™ã‚Šã® text ã‚’å…¨éƒ¨æ‹¾ã†ã€ç‰ˆã€‚
    SDK/ãƒ¢ãƒ‡ãƒ«å·®åˆ†ã§ output ã®æ§‹é€ ãŒå¤‰ã‚ã£ã¦ã‚‚æ‹¾ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
    """

    # 1) SDKã®ä¾¿åˆ©ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒã‚ã‚‹ãªã‚‰æœ€å„ªå…ˆ
    t = getattr(resp, "output_text", None)
    if isinstance(t, str) and t.strip():
        return t.strip()

    # 2) resp ã‚’ dict åŒ–ï¼ˆã§ãã‚Œã°ï¼‰
    try:
        d = resp.model_dump()
    except Exception:
        try:
            d = resp.dict()
        except Exception:
            d = None

    def _collect_text(x: Any, acc: List[str]) -> None:
        """
        dict/list/object ã‚’å†å¸°çš„ã«è¾¿ã£ã¦ã€"text" ã¨ã„ã†ã‚­ãƒ¼/å±æ€§ã‚’è¦‹ã¤ã‘ãŸã‚‰å›åã™ã‚‹ã€‚
        """
        if x is None:
            return

        # str
        if isinstance(x, str):
            if x.strip():
                acc.append(x)
            return

        # list/tuple
        if isinstance(x, (list, tuple)):
            for it in x:
                _collect_text(it, acc)
            return

        # dict
        if isinstance(x, dict):
            # å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š {"type":"output_text","text":"..."}
            if isinstance(x.get("text"), str) and x.get("text", "").strip():
                acc.append(x["text"])
            # ä»–ã‚‚å†å¸°
            for v in x.values():
                _collect_text(v, acc)
            return

        # objectï¼ˆSDKã®Typed objectãªã©ï¼‰
        # "text" å±æ€§ãŒã‚ã‚Œã°æ‹¾ã†
        txt = getattr(x, "text", None)
        if isinstance(txt, str) and txt.strip():
            acc.append(txt)

        # ä»£è¡¨çš„ãªå±æ€§ã‚’å†å¸°
        for attr in ("output", "content", "message", "choices", "items", "data"):
            v = getattr(x, attr, None)
            if v is not None:
                _collect_text(v, acc)

    acc: List[str] = []
    if d is not None:
        _collect_text(d, acc)
    else:
        _collect_text(resp, acc)

    # ã‹ã¶ã‚Šã‚„ã‚´ãƒŸã‚’æ¸›ã‚‰ã™ï¼ˆå®Œå…¨ä¸€è‡´ã®ã¿ç°¡æ˜“é™¤å»ï¼‰
    seen = set()
    uniq = []
    for s in acc:
        s2 = s.strip()
        if not s2:
            continue
        if s2 in seen:
            continue
        seen.add(s2)
        uniq.append(s2)

    return "\n".join(uniq).strip()


def _add_turn_cost(model: str, input_tokens: int, output_tokens: int, note: str) -> None:
    try:
        cost = estimate_chat_cost(
            model,
            ChatUsage(input_tokens=int(input_tokens or 0), output_tokens=int(output_tokens or 0)),
            rate=DEFAULT_USDJPY,
        )
        st.session_state.chat_costs.append(
            {
                "model": model,
                "input_tokens": int(input_tokens or 0),
                "output_tokens": int(output_tokens or 0),
                "usd": float(cost.get("usd", 0.0)),
                "jpy": float(cost.get("jpy", 0.0)),
                "note": note or "",
            }
        )
    except Exception:
        st.session_state.chat_costs.append(
            {
                "model": model,
                "input_tokens": int(input_tokens or 0),
                "output_tokens": int(output_tokens or 0),
                "usd": 0.0,
                "jpy": 0.0,
                "note": "ï¼ˆæ–™é‡‘è¨ˆç®—å¤±æ•—ï¼‰",
            }
        )


# ============================================================
# State init
# ============================================================
_ensure_state()

# ============================================================
# 1) æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰
# ============================================================
st.subheader("1ï¸âƒ£ æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰")
st.caption("ã“ã“ã§ã‚»ãƒƒãƒˆã—ãŸæ–‡æ›¸ã¯ã€ä¼šè©±ã®å‰æï¼ˆå‚è€ƒè³‡æ–™ï¼‰ã¨ã—ã¦æ¯ã‚¿ãƒ¼ãƒ³å‚ç…§ã•ã‚Œã¾ã™ã€‚")

tab_file, tab_text = st.tabs(["ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘"])

tmp_text: str = ""
tmp_kind: str = ""

with tab_file:
    uploaded = st.file_uploader(
        "Word / ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰",
        type=["docx", "txt", "json", "md"],
        key="ctx_file_uploader",
    )

    if uploaded is not None:
        file_name = uploaded.name
        ext = file_name.lower().rsplit(".", 1)[-1]
        try:
            if ext == "docx":
                doc = docx.Document(uploaded)
                tmp_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                tmp_kind = "Word(.docx)"
            elif ext in ("txt", "md"):
                raw = uploaded.read()
                tmp_text = raw.decode("utf-8", errors="ignore")
                tmp_kind = f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.{ext})"
            elif ext == "json":
                raw = uploaded.read()
                obj = json.loads(raw.decode("utf-8", errors="ignore"))
                tmp_text = json.dumps(obj, ensure_ascii=False, indent=2)
                tmp_kind = "JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.jsonï¼‰"
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

with tab_text:
    pasted = st.text_area(
        "ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘ï¼ˆä»»æ„ï¼‰",
        height=180,
        placeholder="ã“ã“ã«è²¼ã‚Šä»˜ã‘ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ä¼šè©±ã®å‰ææ–‡æ›¸ã¨ã—ã¦ã‚»ãƒƒãƒˆã§ãã¾ã™ã€‚",
        key="ctx_text_paste",
    )
    if pasted.strip():
        tmp_text = pasted
        tmp_kind = "è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆ"

col_set, col_show = st.columns([1, 2])
with col_set:
    if st.button("ã“ã®æ–‡æ›¸ã‚’ä¼šè©±ã«ã‚»ãƒƒãƒˆ", disabled=not bool((tmp_text or "").strip())):
        st.session_state.doc_context = {"kind": tmp_kind, "text": tmp_text}
        st.success(f"âœ… æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼ˆ{tmp_kind} / ç´„ {len(tmp_text)} æ–‡å­—ï¼‰")

with col_show:
    ctx = st.session_state.get("doc_context")
    if ctx and (ctx.get("text") or "").strip():
        st.info(f"ğŸ“Œ ç¾åœ¨ã®æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼š{ctx.get('kind','')}ï¼ˆç´„ {len(ctx.get('text',''))} æ–‡å­—ï¼‰")
        with st.expander("æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­ï¼‰", expanded=False):
            t = (ctx.get("text") or "")
            preview = t[:1000] + ("\nâ€¦ï¼ˆçœç•¥ï¼‰" if len(t) > 1000 else "")
            st.code(preview, language="text")
    else:
        st.caption("ï¼ˆæ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯æœªè¨­å®šï¼‰")

st.divider()

# ============================================================
# 2) Chat UI
# ============================================================
st.subheader("2ï¸âƒ£ ãƒãƒ£ãƒƒãƒˆ")

# å±¥æ­´è¡¨ç¤º
for m in st.session_state.chat_messages:
    with st.chat_message(m.get("role", "assistant")):
        st.write(m.get("content", ""))

# å…¥åŠ›æ¬„ï¼ˆã‚¯ãƒªã‚¢ã¯ key ã‚’å¤‰ãˆã‚‹æ–¹å¼ï¼‰
draft_key = f"chat_draft_{st.session_state.chat_draft_key}"
user_text = st.text_area(
    "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
    key=draft_key,
    height=90,
    placeholder="ã“ã“ã«å…¥åŠ›ã—ã¦ã€Œé€ä¿¡ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼ˆShift+Enterã§æ”¹è¡Œï¼‰ã€‚",
)

col_send, col_hint = st.columns([1, 4])
with col_send:
    send = st.button("é€ä¿¡", type="primary")
with col_hint:
    st.caption("â€» æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¦ã„ã‚‹å ´åˆã€ä¼šè©±ã®å‰æã¨ã—ã¦æ¯ã‚¿ãƒ¼ãƒ³å‚ç…§ã•ã‚Œã¾ã™ã€‚")

# ï¼ˆãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºé ˜åŸŸï¼šå¸¸ã«å‡ºã™ã¨é‚ªé­”ãªã®ã§ toggle æ™‚ã ã‘ï¼‰
if debug_mode:
    st.caption("ãƒ‡ãƒãƒƒã‚°ã¯ã“ã®ä¸‹ã«å‡ºã¾ã™ï¼ˆé€ä¿¡å¾Œã®çµæœãªã©ï¼‰ã€‚")

if send:
    if not (user_text or "").strip():
        st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™ã€‚")
        st.stop()

    user_text = user_text.strip()

    # è¡¨ç¤ºç”¨å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_messages.append({"role": "user", "content": user_text})

    used_gemini = is_gemini_model(chat_model)

    answer = ""
    input_tokens: Optional[int] = None
    output_tokens: Optional[int] = None
    note = ""

    # é€ä¿¡â†’ç”ŸæˆãŒçµ‚ã‚ã£ãŸã‚‰å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ã—ãŸã„ã®ã§ã€å…ˆã«æ¬¡keyã‚’æº–å‚™
    next_draft_key_value = st.session_state.chat_draft_key + 1

    with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
        if used_gemini:
            if not has_gemini_api_key():
                st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Gemini ã‚’ä½¿ã†ã«ã¯ã‚­ãƒ¼è¨­å®šãŒå¿…è¦ã§ã™ã€‚")
                st.stop()

            responder = GeminiResponder()
            gemini_user_content = _build_gemini_prompt_from_history(user_text)

            result = responder.complete(
                model=chat_model,
                system_instruction="ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                user_content=gemini_user_content,
                max_output_tokens=int(max_output_tokens),
            )
            answer = (result.text or "").strip()

            input_tokens = int(estimate_tokens_from_text(gemini_user_content))
            output_tokens = int(estimate_tokens_from_text(answer))
            note = "ï¼ˆGemini: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"

            if debug_mode:
                with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šGemini", expanded=False):
                    st.write({"len_answer": len(answer), "input_tokens_est": input_tokens, "output_tokens_est": output_tokens})

#############################

        else:
            # OpenAIï¼šResponses APIï¼ˆBæ–¹å¼ï¼šå±¥æ­´ã‚’ input ã«æ¯å›æ¸¡ã™ / previous_response_id ã¯ä½¿ã‚ãªã„ï¼‰
            try:
                client = get_openai_client()
            except Exception as e:
                st.error(str(e))
                st.stop()

            instructions = _build_openai_instructions()

            # âœ… UIã®å±¥æ­´ã‚’ãã®ã¾ã¾ OpenAI input ã«æ¸¡ã™ï¼ˆsystemã¯ instructions å´ï¼‰
            input_messages: List[Dict[str, str]] = []
            for m in (st.session_state.get("chat_messages") or []):
                role = (m.get("role") or "").strip()
                content = (m.get("content") or "")
                if role in ("user", "assistant") and isinstance(content, str) and content.strip():
                    input_messages.append({"role": role, "content": content})

            try:
                resp = client.responses.create(
                    model=chat_model,
                    instructions=instructions,
                    input=input_messages,  # âœ… Bæ–¹å¼ã®æœ¬ä½“
                    max_output_tokens=int(max_output_tokens),
                )
            except Exception as e:
                st.error(f"OpenAI API å‘¼ã³å‡ºã—ã«å¤±æ•—: {e}")
                st.stop()

            # ã¾ãš dump ã‚’ä¿å­˜ï¼ˆç©ºã§ã‚‚å¿…ãšæ®‹ã™ï¼‰
            try:
                st.session_state["last_openai_dump"] = resp.model_dump()
            except Exception:
                st.session_state["last_openai_dump"] = str(resp)

            # âœ… æŠ½å‡º
            answer = _safe_response_text_from_responses_api(resp).strip()
            st.session_state["last_answer"] = answer

            if not answer:
                st.error("OpenAIã®æŠ½å‡ºçµæœãŒç©ºã§ã—ãŸã€‚ä¸‹ã®ãƒ‡ãƒãƒƒã‚°ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                if debug_mode:
                    with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šOpenAIãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ï¼ˆmodel_dumpï¼‰", expanded=True):
                        st.write(st.session_state.get("last_openai_dump"))
                st.stop()

            # usageï¼ˆå–ã‚Œã‚Œã°å®Ÿæ¸¬ã€ãªã‘ã‚Œã°æ¨å®šï¼‰
            u = getattr(resp, "usage", None)
            if u is not None:
                input_tokens = int(getattr(u, "input_tokens", 0) or 0)
                output_tokens = int(getattr(u, "output_tokens", 0) or 0)

            if not input_tokens:
                # å±¥æ­´é…åˆ—ã‚’ç°¡æ˜“ã«ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦æ¨å®šï¼ˆæ¦‚ç®—ç”¨ï¼‰
                hist_txt = "\n".join([f"{x['role']}: {x['content']}" for x in input_messages])
                input_tokens = int(estimate_tokens_from_text(instructions + "\n\n" + hist_txt))
                note = "ï¼ˆOpenAI: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"
            if not output_tokens:
                output_tokens = int(estimate_tokens_from_text(answer))
                note = "ï¼ˆOpenAI: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"

            if debug_mode:
                with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šOpenAI Responses", expanded=False):
                    st.write(
                        {
                            "mode": "history_in_input",
                            "len_messages": len(input_messages),
                            "status": getattr(resp, "status", None),
                            "len_answer": len(answer),
                            "usage": {
                                "input_tokens": int(input_tokens or 0),
                                "output_tokens": int(output_tokens or 0),
                            },
                        }
                    )



#######################

    # answer ãŒç©ºãªã‚‰ã€ã“ã“ã§æ­¢ã‚ã¦ â€œç©ºã®assistantâ€ ã‚’å±¥æ­´ã«å…¥ã‚Œãªã„
    if not answer:
        st.error("å›ç­”ãŒç©ºã§ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºã‚’ONã«ã—ã¦ã€OpenAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # è¡¨ç¤ºç”¨å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_messages.append({"role": "assistant", "content": answer})

    # æ–™é‡‘æ¦‚ç®—ï¼ˆ1ã‚¿ãƒ¼ãƒ³ï¼‰
    _add_turn_cost(
        model=chat_model,
        input_tokens=int(input_tokens or 0),
        output_tokens=int(output_tokens or 0),
        note=note,
    )

    # å…¥åŠ›æ¬„ã‚¯ãƒªã‚¢ï¼škey ã‚’é€²ã‚ã¦ rerun
    st.session_state.chat_draft_key = next_draft_key_value
    st.rerun()


# ============================================================
# 3) ã‚³ã‚¹ãƒˆè¡¨ç¤ºï¼ˆä»»æ„ï¼‰
# ============================================================
st.divider()
st.subheader("3ï¸âƒ£ æ–™é‡‘ï¼ˆæ¦‚ç®—ï¼‰")

if st.session_state.chat_costs:
    total_jpy = sum(float(x.get("jpy", 0.0)) for x in st.session_state.chat_costs)
    total_usd = sum(float(x.get("usd", 0.0)) for x in st.session_state.chat_costs)

    last = st.session_state.chat_costs[-1]
    st.write(f"- ç›´è¿‘ã‚¿ãƒ¼ãƒ³: **Â¥{last.get('jpy',0.0):,.2f}**ï¼ˆ${last.get('usd',0.0):.6f}ï¼‰ {last.get('note','')}")
    st.write(f"- ç´¯è¨ˆ: **Â¥{total_jpy:,.2f}**ï¼ˆ${total_usd:.6f}ï¼‰")

    with st.expander("ã‚¿ãƒ¼ãƒ³åˆ¥ã®å†…è¨³", expanded=False):
        for i, r in enumerate(st.session_state.chat_costs, start=1):
            st.write(
                f"{i:02d}. {r.get('model','')}  "
                f"in={int(r.get('input_tokens',0)):,} / out={int(r.get('output_tokens',0)):,}  "
                f"â†’ Â¥{float(r.get('jpy',0.0)):,.2f}ï¼ˆ${float(r.get('usd',0.0)):.6f}ï¼‰ {r.get('note','')}"
            )
else:
    st.caption("ï¼ˆã¾ã å®Ÿè¡Œã—ã¦ã„ã¾ã›ã‚“ï¼‰")
