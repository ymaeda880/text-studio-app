# -*- coding: utf-8 -*-
# pages/44_é ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º.py
# ç›®çš„ï¼š
#   å˜ç‹¬è¡Œã®é ãƒ©ãƒ™ãƒ«æŠ½å‡º â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯(valid=True) ã®ãƒšãƒ¼ã‚¸æœ¬æ–‡ã‚’TXTã«çµåˆã€‚
#   â˜… è¿½åŠ è¦ä»¶ï¼špage_label ãŒç„¡ã„ãƒšãƒ¼ã‚¸ã‚‚å¿…ãšå‡ºåŠ›ï¼ˆheaderã¯ page_label=Noneï¼‰ã€‚

from __future__ import annotations
import io, re, tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ“„ é ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆvalidï¼‹ãƒ©ãƒ™ãƒ«ç„¡ã—ã‚‚å‡ºåŠ›ï¼‰", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ é ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆvalid=Trueï¼‹labelç„¡ã—ãƒšãƒ¼ã‚¸ã‚‚TXTã¸ï¼‰")
st.caption("OCRã¯è¡Œã„ã¾ã›ã‚“ã€‚PDFã®ãƒ†ã‚­ã‚¹ãƒˆå±¤ã‹ã‚‰æŠ½å‡ºã—ã€å˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«â†’é€£ç•ªãƒã‚§ãƒƒã‚¯ã§ valid=True ã®ãƒšãƒ¼ã‚¸ã«åŠ ãˆã€ãƒ©ãƒ™ãƒ«ç„¡ã—ãƒšãƒ¼ã‚¸ã‚‚TXTã«å‡ºåŠ›ã—ã¾ã™ã€‚")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ æŠ½å‡ºã—ã¦TXTã‚’ä½œæˆ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)

if not uploaded or not run:
    st.stop()
if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()

# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_text_per_page(pdf_path: Path) -> List[str]:
    texts: List[str] = []
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        for p in doc:
            texts.append(p.get_text("text") or "")
    else:
        with pdfplumber.open(str(pdf_path)) as pdf:
            for p in pdf.pages:
                texts.append(p.extract_text() or "")
    return texts

with tempfile.TemporaryDirectory() as td:
    td = Path(td)
    pdf_path = td / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")

# =========================
# æ­£è¦åŒ–ãƒ»ãƒ©ãƒ™ãƒ«æ¤œå‡º
# =========================
HY = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D\u30FC]"
LEADER_CHARS_CLASS = r"[\.ï¼ãƒ»ï½¥â€¦â€§ï½¡]"
LEADERS_SPACED = rf"(?:\s*{LEADER_CHARS_CLASS}\s*){{3,}}"

def z2h_numhy(s: str) -> str:
    s = (s or "").replace("\u3000", " ")
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼»ï¼½ï½›ï½", "0123456789()[]{}"))
    return re.sub(HY, "-", s)

def normalize_strict(s: str) -> str:
    s = z2h_numhy(s)
    s = re.sub(rf"\s*{LEADERS_SPACED}\s*$", "", s)
    s = re.sub(r"[ \t]+", " ", s)
    return s.strip()

ALPHAJP = r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]+"

def build_label_line_regex_mixed() -> re.Pattern:
    core_seq    = r"[0-9ï¼-ï¼™]{1,6}"
    core_chap   = rf"[0-9ï¼-ï¼™]+(?:\s*{HY}\s*[0-9ï¼-ï¼™]+)+"
    series_word = rf"[ï¼ˆ(ï¼»\[]?{ALPHAJP}[ï¼‰)\]ï¼½]?"
    SEP_OPT     = rf"(?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?"
    core_series = rf"{series_word}{SEP_OPT}[0-9ï¼-ï¼™]+"
    core = rf"(?:{core_seq}|{core_chap}|{core_series})"
    return re.compile(rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$", re.MULTILINE)

LABEL_LINE_RE = build_label_line_regex_mixed()

def extract_single_page_label(page_text: str) -> Tuple[Optional[str], Optional[str]]:
    if not page_text:
        return None, None
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        s = normalize_strict(raw)
        if not s:
            continue
        m = LABEL_LINE_RE.match(s)
        if m:
            return z2h_numhy(m.group("label")), raw
    return None, None

# =========================
# é€£ç•ªãƒã‚§ãƒƒã‚¯
# =========================
def _parse_label_kind(label: str) -> Tuple[str, Any]:
    lab = z2h_numhy(label)
    if re.fullmatch(r"[0-9]+", lab):
        return "seq", int(lab)
    parts = lab.split("-")
    if len(parts) >= 2 and all(p.isdigit() for p in parts):
        return "chap", [int(p) for p in parts]
    m = re.fullmatch(rf"({ALPHAJP})-([0-9]+)", lab)
    if m:
        return "series", (m.group(1), int(m.group(2)))
    return "unknown", None

def valid_and_reason_auto(label: str, prev_ok: Optional[str]) -> Tuple[bool, str]:
    k, cur = _parse_label_kind(label)
    if k == "unknown":
        return False, "ä¸æ˜ãªãƒ©ãƒ™ãƒ«å½¢å¼"
    if prev_ok is None:
        return True, ""
    pk, prev = _parse_label_kind(prev_ok)
    if pk == "unknown":
        return True, ""
    if k != pk:
        return True, "å½¢å¼åˆ‡æ›¿"
    if k == "seq":
        return (cur == prev + 1, "" if cur == prev + 1 else "éé€£ç•ª")
    if k == "chap":
        c, p = (cur + [1, 1])[:2]; pc, pp = (prev + [1, 1])[:2]
        ok = (c == pc and p == pp + 1) or (c == pc + 1 and p == 1)
        return (ok, "" if ok else "éé€£ç•ª")
    if k == "series":
        s, n = cur; ps, pn = prev
        if s != ps:
            return True, "å½¢å¼åˆ‡æ›¿"
        return (n == pn + 1, "" if n == pn + 1 else "éé€£ç•ª")
    return True, ""

# =========================
# æŠ½å‡º â†’ å‡ºåŠ›
# =========================
# 1) ãƒšãƒ¼ã‚¸ã”ã¨ã®å˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«æŠ½å‡º
segments: List[Dict[str, Any]] = []
page_labels: List[Optional[str]] = []
for i, ptxt in enumerate(pages_text, start=1):
    label, matched = extract_single_page_label(ptxt)
    page_labels.append(label)
    segments.append({
        "pdf_page": i,
        "page_label": label if label else None,   # â† Noneã‚’ä¿æŒ
        "body": normalize_strict(ptxt),
        "matched_line": matched if matched else "-"
    })

# 2) é€£ç•ªãƒã‚§ãƒƒã‚¯ã§ valid=True ã‚’åˆ¤å®šï¼ˆãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹ãƒšãƒ¼ã‚¸ã®ã¿ï¼‰
prev_ok: Optional[str] = None
valid_flags: Dict[int, bool] = {}
for s in segments:
    if s["page_label"] is None:
        valid_flags[s["pdf_page"]] = False
        continue
    ok, _ = valid_and_reason_auto(s["page_label"], prev_ok)
    if ok:
        prev_ok = s["page_label"]
    valid_flags[s["pdf_page"]] = ok

# 3) TXT çµåˆ
#    - ãƒ©ãƒ™ãƒ«æœ‰ã‚Šã‹ã¤ valid=True ã®ãƒšãƒ¼ã‚¸ â†’ å‡ºåŠ›
#    - ãƒ©ãƒ™ãƒ«ç„¡ã—ï¼ˆpage_label is Noneï¼‰ã®ãƒšãƒ¼ã‚¸ â†’ å‡ºåŠ›ï¼ˆheaderã¯ page_label=Noneï¼‰
txt_buf = io.StringIO()
num_valid = 0
num_none  = 0

for s in segments:
    label = s["page_label"]
    include = False
    label_str = "None"

    if label is None:
        include = True
        num_none += 1
    else:
        if valid_flags.get(s["pdf_page"], False):
            include = True
            label_str = str(label)
            num_valid += 1
        else:
            include = False  # ãƒ©ãƒ™ãƒ«æœ‰ã‚Šã ãŒ invalid ã¯å‡ºã•ãªã„ï¼ˆä»•æ§˜ã©ãŠã‚Šï¼‰

    if include:
        header = f"==== pdfé ï¼ˆpdf_pageï¼‰={s['pdf_page']} pdfé ãƒ©ãƒ™ãƒ«ï¼ˆpage_labelï¼‰={label_str} (chars={len(s['body'])}) ====\n"
        txt_buf.write(header)
        txt_buf.write(s["body"].rstrip("\n") + "\n\n")

# 4) ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if num_valid > 0 or num_none > 0:
    st.download_button(
        "ğŸ“¥ extracted_pages_valid_and_none.txt ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=txt_buf.getvalue().encode("utf-8"),
        file_name="extracted_pages_valid.txt",  # æ—¢å­˜åã‚’ç¶­æŒï¼ˆä¸­èº«ã¯Noneã‚‚å«ã‚€ï¼‰
        mime="text/plain",
        use_container_width=True,
    )
    st.success(f"å‡ºåŠ›ãƒšãƒ¼ã‚¸æ•°: valid={num_valid}, label=None={num_none}")
else:
    st.warning("å‡ºåŠ›å¯¾è±¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆvalid=True ã‚‚ label=None ã‚‚ç„¡ã—ï¼‰ã€‚")

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug")
    st.code(f"LABEL_LINE_RE = {build_label_line_regex_mixed().pattern}")
    st.dataframe(pd.DataFrame(segments), use_container_width=True)
