# -*- coding: utf-8 -*-
# pages/21_AIæ–‡ç« ä½œæˆ.py
# ============================================================
# ğŸ“ æ–‡ç« ä½œæˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹  / GPTãƒ»Gemini å…±é€šï¼‰
#
# ç›®çš„ï¼š
# - å…ƒæ–‡ç« ï¼ˆè²¼ã‚Šä»˜ã‘ / ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ï¼‹ç”¨é€”ãƒ†ãƒ³ãƒ—ãƒ¬ï¼‹è¿½åŠ æŒ‡ç¤º â†’ æœ€çµ‚æ–‡ç« ã‚’ç”Ÿæˆ
#
# âœ… ãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹ ï¼ˆAIå®Ÿè¡Œ + busy è¨˜éŒ²ï¼‰ï¼š
# - AIå‘¼ã³å‡ºã—ã¯ common_lib.aiï¼ˆproviderå·®ã‚’å¸åï¼‰
# - busyï¼ˆai_runs.dbï¼‰ã‚’ with busy_run ã§å¿…ãšè¨˜éŒ²
# - tokens / cost ã¯ã€Œè¿”ã£ã¦ããŸç¯„å›²ã®ã¿ã€è¡¨ç¤ºï¼ˆæ¨è¨ˆã—ãªã„ï¼‰
# - å®Ÿè¡Œçµæœã®åæ˜ ã¯ apply_text_result_to_busy ã«å¯„ã›ã‚‹
#
# UIæ–¹é‡ï¼š
# - use_container_width ã¯ä½¿ã‚ãªã„
# - st.form ã¯ä½¿ã‚ãªã„
# - st.button()/st.download_button() ã« width å¼•æ•°ã¯ä½¿ã‚ãªã„
# ============================================================

from __future__ import annotations

# ============================================================
# importsï¼ˆstdlibï¼‰
# ============================================================
import sys
import json
from pathlib import Path
from typing import Optional, Dict, Tuple
from functools import lru_cache

# ============================================================
# importsï¼ˆthird-partyï¼‰
# ============================================================
import streamlit as st
import docx

# ============================================================
# ãƒ‘ã‚¹è¨­å®šï¼ˆcommon_lib ã‚’ import ã§ãã‚‹ã‚ˆã†ã«ï¼‰
# ============================================================
_THIS = Path(__file__).resolve()
APP_DIR = _THIS.parents[1]
PROJ_DIR = _THIS.parents[2]
MONO_ROOT = _THIS.parents[3]

for p in (MONO_ROOT, PROJ_DIR, APP_DIR):
    if str(p) not in sys.path:
        sys.path.insert(0, str(p))

PROJECTS_ROOT = MONO_ROOT
APP_NAME = _THIS.parents[1].name
PAGE_NAME = _THIS.stem

# ============================================================
# common_lib.aiï¼ˆæ­£æœ¬ï¼‰
# ============================================================
from common_lib.ai import call_text  # type: ignore
from common_lib.ai.usage_extract import extract_text_in_out_tokens  # type: ignore

# ============================================================
# common_lib UI / authï¼ˆæ­£æœ¬ï¼‰
# ============================================================
from common_lib.sessions.page_entry import page_session_heartbeat  # type: ignore
from common_lib.ui.ui_basics import subtitle  # type: ignore
from common_lib.ui.banner_lines import render_banner_line_by_key  # type: ignore
from common_lib.ui import render_run_summary_compact  # type: ignore
from common_lib.ui.model_picker import render_text_model_picker  # type: ignore
from common_lib.ai.models import TEXT_MODEL_CATALOG, DEFAULT_TEXT_MODEL_KEY  # type: ignore

# ============================================================
# busyï¼ˆæ­£æœ¬ï¼‰
# ============================================================
from common_lib.busy import busy_run  # type: ignore
from common_lib.busy.apply_text_result import apply_text_result_to_busy  # type: ignore

# ============================================================
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«1å›ã ã‘ï¼‰
# ============================================================
st.set_page_config(
    page_title="ğŸ“ AIæ–‡ç« ä½œæˆ",
    page_icon="ğŸ“",
    layout="wide",
)

# ============================================================
# ãƒãƒŠãƒ¼ï¼ˆä¸Šéƒ¨ï¼‰
# ============================================================
render_banner_line_by_key("purple_light")

# ============================================================
# ãƒ­ã‚°ã‚¤ãƒ³ / heartbeatï¼ˆæ­£æœ¬ï¼‰
# ============================================================
sub = page_session_heartbeat(
    st,
    PROJECTS_ROOT,
    app_name=APP_NAME,
    page_name=PAGE_NAME,
)

# ============================================================
# ã‚¿ã‚¤ãƒˆãƒ«
# ============================================================
left, right = st.columns([2, 1])
with left:
    st.title("ğŸ“ AIæ–‡ç« ä½œæˆ")
with right:
    st.success(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³ä¸­: **{sub}**")

subtitle("AIã§æ–‡ç« ã‚’ä½œæˆ")
st.caption(
    "å…ƒã¨ãªã‚‹æ–‡ç« ï¼ˆè²¼ã‚Šä»˜ã‘ / Word / txt / json / mdï¼‰ï¼‹ ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆãƒ¡ãƒ¼ãƒ«/å ±å‘Šæ›¸ãªã©ï¼‰ï¼‹ è¿½åŠ æŒ‡ç¤ºã‚’ã¤ãªã„ã§ã€æ–‡ç« ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
)

# ============================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ï¼ˆæœ€å°ï¼‰
# ============================================================
K_MODEL_KEY = f"{PAGE_NAME}__model_key"
K_SYSTEM = f"{PAGE_NAME}__system"
K_ADDITIONAL = f"{PAGE_NAME}__additional"
K_MAX_OUT_TOK = f"{PAGE_NAME}__max_output_tokens"

K_LAST_ANSWER = f"{PAGE_NAME}__last_answer"
K_LAST_IN_TOK = f"{PAGE_NAME}__last_in_tok"
K_LAST_OUT_TOK = f"{PAGE_NAME}__last_out_tok"
K_LAST_COST_OBJ = f"{PAGE_NAME}__last_cost_obj"
K_LAST_MODEL = f"{PAGE_NAME}__last_model"
K_LAST_NOTE = f"{PAGE_NAME}__last_note"
K_LAST_RUN_ID = f"{PAGE_NAME}__last_run_id"

# ============================================================
# åˆæœŸåŒ–
# ============================================================
st.session_state.setdefault(K_MODEL_KEY, DEFAULT_TEXT_MODEL_KEY)
st.session_state.setdefault(K_SYSTEM, "ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§æ–‡ç« ã‚’ä½œæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
st.session_state.setdefault(K_ADDITIONAL, "")
st.session_state.setdefault(K_MAX_OUT_TOK, 4000)

st.session_state.setdefault(K_LAST_ANSWER, "")
st.session_state.setdefault(K_LAST_IN_TOK, None)
st.session_state.setdefault(K_LAST_OUT_TOK, None)
st.session_state.setdefault(K_LAST_COST_OBJ, None)
st.session_state.setdefault(K_LAST_MODEL, "")
st.session_state.setdefault(K_LAST_NOTE, "")
st.session_state.setdefault(K_LAST_RUN_ID, None)

# ============================================================
# provider / model_key utilities
# ============================================================
def _parse_model_key(model_key: str) -> Tuple[str, str]:
    if ":" not in model_key:
        return ("openai", model_key)
    p, m = model_key.split(":", 1)
    return p.strip(), m.strip()


@lru_cache(maxsize=1)
def _gemini_available() -> bool:
    """
    Gemini åˆ©ç”¨å¯å¦ã®åˆ¤å®šï¼ˆgoogle-genai ãŒ import ã§ãã‚‹ã‹ï¼‰
    - sidebar å†æç”»ã”ã¨ã« import ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹
    """
    try:
        from google import genai  # type: ignore  # google-genai
        _ = genai
        return True
    except Exception:
        return False

# ============================================================
# Templates
# ============================================================
TEMPLATES: Dict[str, str] = {
    "ãƒ¡ãƒ¼ãƒ«æ–‡ï¼ˆãƒ“ã‚¸ãƒã‚¹ï¼‰": """ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®ä½œæˆã«é•·ã‘ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¸å¯§ã§ç°¡æ½”ã€èª¤è§£ãŒç”Ÿã˜ã«ãã„ãƒ¡ãƒ¼ãƒ«æ–‡ã‚’æ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»ä»¶åã‚‚ä½œã‚‹
ãƒ»æ•¬èªã¯éä¸è¶³ãªã
ãƒ»ç®‡æ¡æ›¸ãã‚’é©åˆ‡ã«ä½¿ã†
ãƒ»å¿…è¦ãªã‚‰ã€Œå¿µã®ãŸã‚ã€ã€Œå·®ã—æ”¯ãˆãªã‘ã‚Œã°ã€ç­‰ã®ã‚¯ãƒƒã‚·ãƒ§ãƒ³è¨€è‘‰ã‚’å…¥ã‚Œã‚‹
""",
    "ãƒ¡ãƒ¼ãƒ«æ–‡ï¼ˆåŒåƒšï¼‰": """ã‚ãªãŸã¯ç¤¾å†…å‘ã‘ã®é€£çµ¡æ–‡ï¼ˆåŒåƒšå®›ã¦ï¼‰ã®ä½œæˆã«é•·ã‘ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ç •ã‘ã™ããšã€ã—ã‹ã—å …ã™ããªã„ãƒˆãƒ¼ãƒ³ã§ã€æ—¥æœ¬èªã®ãƒ¡ãƒ¼ãƒ«/ãƒãƒ£ãƒƒãƒˆæ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»è¦ç‚¹â†’è©³ç´°â†’ä¾é ¼ï¼ˆã‚ã‚Œã°ï¼‰ã®é †
ãƒ»èª­ã¿ã‚„ã™ã•é‡è¦–ï¼ˆçŸ­ã„æ®µè½ã€ç®‡æ¡æ›¸ãï¼‰
""",
    "å ±å‘Šæ›¸(ä¸€èˆ¬ï¼‰": """ã‚ãªãŸã¯å ±å‘Šæ›¸ã®ä½œæˆã«é•·ã‘ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®å…ƒã¨ãªã‚‹æ–‡ç« ã‚„ç´ æã‚’ã¾ã¨ã‚ã‚‹å½¢ã§ï¼Œå ±å‘Šæ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»ç®‡æ¡æ›¸ãã§ã¯ãªãï¼Œæ›¸ãä¸‹ã—æ–‡ã§æ›¸ã„ã¦ãã ã•ã„ï¼
ãƒ»è‡ªç„¶ãªæµã‚Œã®ä¸€é€£ã®æ›¸ãä¸‹ã—æ–‡ã§æ›¸ã„ã¦ãã ã•ã„ï¼
""",
    "å ±å‘Šæ›¸": """ã‚ãªãŸã¯å ±å‘Šæ›¸ã®ä½œæˆã«é•·ã‘ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®å…ƒã¨ãªã‚‹æ–‡ç« ã‚„ç´ æã‚’è¸ã¾ãˆã¦ã€æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãã€æ§‹é€ åŒ–ã•ã‚ŒãŸå ±å‘Šæ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»çµè«–ï¼ˆè¦ç´„ï¼‰â†’èƒŒæ™¯â†’è¦³å¯Ÿ/äº‹å®Ÿâ†’åˆ†æâ†’ææ¡ˆ/æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
ãƒ»å¿…è¦ãªã‚‰è¦‹å‡ºã—ã‚’ä»˜ã‘ã‚‹
ãƒ»ä¸»è¦³ã¨äº‹å®Ÿã‚’åˆ†ã‘ã‚‹
""",
    "è­°äº‹ãƒ¡ãƒ¢": """ã‚ãªãŸã¯è­°äº‹ãƒ¡ãƒ¢ã®ä½œæˆã«é•·ã‘ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
å…ƒæ–‡ç« ã‚’è¸ã¾ãˆã€æ„æ€æ±ºå®šãƒ»å®¿é¡Œãƒ»è«–ç‚¹ãŒåˆ†ã‹ã‚‹å½¢ã§ã€æ—¥æœ¬èªã§è­°äº‹ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»æ±ºå®šäº‹é …
ãƒ»æœªæ±ºäº‹é …/è«–ç‚¹
ãƒ»ToDoï¼ˆæ‹…å½“/æœŸé™ãŒåˆ†ã‹ã‚‹ãªã‚‰æ˜è¨˜ï¼‰
""",
    "ãƒ—ãƒ¬ã‚¼ãƒ³ç”¨ã‚¹ãƒ©ã‚¤ãƒ‰": """ã‚ãªãŸã¯ã‚¹ãƒ©ã‚¤ãƒ‰ã®ä½œæˆã«é•·ã‘ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®å…ƒã¨ãªã‚‹æ–‡ç« ã‚’è¸ã¾ãˆã€æ—¥æœ¬èªã§ãƒ—ãƒ¬ã‚¼ãƒ³ç”¨ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»ãƒ‘ãƒ¯ãƒ¼ãƒã‚¤ãƒ³ãƒˆã«ã‚³ãƒ”ãƒšã§ãã‚‹å½¢å¼ã§å‡ºã—ã¦ãã ã•ã„ï¼
""",
}

# ============================================================
# Prompt builderï¼ˆãƒšãƒ¼ã‚¸å›ºæœ‰ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
# ============================================================
def build_final_prompt(
    *,
    template_name: str,
    base_text_kind: str,
    base_text: str,
    additional_instruction: str,
    max_chars: int,
) -> str:
    tmpl = TEMPLATES.get(template_name, "")
    used_text = (base_text or "")[:max_chars]

    add = (additional_instruction or "").strip()
    add_block = f"\n\nã€è¿½åŠ ã®æŒ‡ç¤ºï¼ˆä»»æ„ï¼‰ã€‘\n{add}\n" if add else ""

    return f"""{tmpl.strip()}

ã‚ãªãŸã¯æ—¥æœ¬èªã§æ–‡ç« ã‚’ä½œæˆã—ã¾ã™ã€‚æ¬¡ã®ç´ æã‚’è¸ã¾ãˆã¦ã€æŒ‡å®šã®ç›®çš„ã«åˆã†æœ€çµ‚æ–‡ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
é‡è¦: ç´ æã«ãªã„äº‹å®Ÿã¯æé€ ã—ãªã„ã§ãã ã•ã„ã€‚ä¸æ˜ãªç‚¹ã¯ã€æ–­å®šã›ãšã«ã€Œä¸æ˜ã€ã¨ã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã¨ãªã‚‹æ–‡ç« ï¼ˆ{base_text_kind} / å…ˆé ­ã€œæœ€å¤§{max_chars}æ–‡å­—ï¼‰ã€‘
{used_text}{add_block}

ã€å‡ºåŠ›è¦ä»¶ã€‘
ãƒ»èª­ã¿ã‚„ã™ã„æ®µè½æ§‹æˆ
ãƒ»å†—é•·ã•ã‚’é¿ã‘ã‚‹
ãƒ»å¿…è¦ãªã‚‰ç®‡æ¡æ›¸ã
""".strip()

# ============================================================
# Sidebarï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠ / system / max tokensï¼‰
# ============================================================
with st.sidebar:
    st.header("è¨­å®š")

    model_key = render_text_model_picker(
        title="ãƒ¢ãƒ‡ãƒ«é¸æŠ",
        catalog=TEXT_MODEL_CATALOG,
        session_key=K_MODEL_KEY,
        default_key=DEFAULT_TEXT_MODEL_KEY,
        page_name=PAGE_NAME,
        gemini_available=_gemini_available(),
    )

    st.divider()

    st.text_area("Systemï¼ˆä»»æ„ï¼‰", key=K_SYSTEM, height=120)

    st.number_input(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¸Šé™ï¼‰",
        min_value=256,
        max_value=20000,
        value=int(st.session_state.get(K_MAX_OUT_TOK) or 4000),
        step=256,
        key=K_MAX_OUT_TOK,
        help="â€» backend ãŒå¯¾å¿œã—ã¦ã„ã‚‹å ´åˆã®ã¿ä¸Šé™ã¨ã—ã¦æœ‰åŠ¹ã€‚æ¨è¨ˆã‚„æ¦‚ç®—è¡¨ç¤ºã¯ã—ã¾ã›ã‚“ã€‚",
    )

# ============================================================
# Input sourceï¼ˆTEXT FIRSTï¼‰
# ============================================================
st.subheader("1ï¸âƒ£ å…ƒã¨ãªã‚‹æ–‡ç« ã®å…¥åŠ›")

tab_text, tab_file = st.tabs(["ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘ï¼ˆæ¨å¥¨ï¼‰", "ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"])

source_text: str = ""
source_kind: str = ""

# ------------------------------------------------------------
# tab: text pasteï¼ˆå„ªå…ˆï¼‰
# ------------------------------------------------------------
with tab_text:
    pasted = st.text_area(
        "å…ƒã¨ãªã‚‹æ–‡ç« ã‚’è²¼ã‚Šä»˜ã‘",
        height=260,
        placeholder="ã“ã“ã«å…ƒã¨ãªã‚‹æ–‡ç« ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚ï¼ˆãƒ¡ãƒ¼ãƒ«ä¸‹æ›¸ãã€ãƒ¡ãƒ¢ã€Wordã‹ã‚‰ã‚³ãƒ”ãƒšç­‰ï¼‰",
    )
    if pasted.strip():
        source_text = pasted
        source_kind = "è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆ"
        st.info(f"ğŸ“Œ å…¥åŠ›æ¸ˆã¿: {source_kind}ï¼ˆç´„ {len(source_text)} æ–‡å­—ï¼‰")

# ------------------------------------------------------------
# tab: file uploadï¼ˆè²¼ã‚Šä»˜ã‘ãŒç©ºã®ã¨ãã ã‘æ¡ç”¨ï¼‰
# ------------------------------------------------------------
with tab_file:
    uploaded = st.file_uploader(
        "Word / ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["docx", "txt", "json", "md"],
    )

    if uploaded is not None:
        file_name = uploaded.name
        ext = file_name.lower().rsplit(".", 1)[-1]

        try:
            if ext == "docx":
                doc = docx.Document(uploaded)
                file_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                file_kind = "Word(.docx)"
            elif ext in ("txt", "md"):
                raw = uploaded.read()
                file_text = raw.decode("utf-8", errors="ignore")
                file_kind = f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.{ext})"
            elif ext == "json":
                raw = uploaded.read()
                obj = json.loads(raw.decode("utf-8", errors="ignore"))
                file_text = json.dumps(obj, ensure_ascii=False, indent=2)
                file_kind = "JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.jsonï¼‰"
            else:
                file_text = ""
                file_kind = ""
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            file_text = ""
            file_kind = ""

        if file_text and not source_text.strip():
            source_text = file_text
            source_kind = file_kind
            st.success(f"âœ… {source_kind} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆç´„ {len(source_text)} æ–‡å­—ï¼‰")

        if file_text:
            with st.expander("èª­ã¿è¾¼ã‚“ã æœ¬æ–‡ï¼ˆå…ˆé ­éƒ¨åˆ†ã‚’ç¢ºèªï¼‰", expanded=False):
                preview = file_text[:1000]
                if len(file_text) > 1000:
                    preview += "\nâ€¦ï¼ˆçœç•¥ï¼‰"
                st.code(preview, language="text")

# ------------------------------------------------------------
# no input warning
# ------------------------------------------------------------
if not source_text.strip():
    st.warning("ã¾ã å…¥åŠ›ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è²¼ã‚Šä»˜ã‘ã‚‹ã‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# ============================================================
# Generation controls
# ============================================================
st.subheader("2ï¸âƒ£ æ–‡ç« ç”Ÿæˆ")

col_a, col_b = st.columns([1, 2], vertical_alignment="top")

with col_a:
    template_name = st.radio(
        "ãƒ†ãƒ³ãƒ—ãƒ¬",
        list(TEMPLATES.keys()),
        index=0,
        help="ç”¨é€”ã«åˆã‚ã›ãŸâ€œå›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆâ€ã‚’é¸ã³ã¾ã™ã€‚",
    )

with col_b:
    st.text_area(
        "è¿½åŠ ã®æŒ‡ç¤ºï¼ˆä»»æ„ï¼‰",
        height=140,
        placeholder="ä¾‹ï¼šã€ã‚‚ã†å°‘ã—çŸ­ãã€ã€ç®‡æ¡æ›¸ãã‚’å¤šã‚ã«ã€ã€çµã³ã«æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…¥ã‚Œã¦ã€ãªã©",
        key=K_ADDITIONAL,
    )

run = st.button("ğŸ“ æ–‡ç« ç”Ÿæˆ", type="primary")

# ============================================================
# Executeï¼ˆAI å®Ÿè¡Œï¼‰
# ============================================================
if run:
    if not source_text.strip():
        st.error("å…ˆã«å…ƒã¨ãªã‚‹æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ------------------------------------------------------------
    # final promptï¼ˆãƒšãƒ¼ã‚¸å›ºæœ‰ï¼‰
    # ------------------------------------------------------------
    max_chars = 15000
    final_prompt = build_final_prompt(
        template_name=template_name,
        base_text_kind=source_kind or "ä¸æ˜",
        base_text=source_text,
        additional_instruction=str(st.session_state.get(K_ADDITIONAL) or ""),
        max_chars=max_chars,
    )

    # ------------------------------------------------------------
    # model_key safeåŒ–ï¼ˆsidebar ã¨åŒã˜è€ƒãˆæ–¹ï¼‰
    # ------------------------------------------------------------
    safe_model_key = (model_key or "").strip() or DEFAULT_TEXT_MODEL_KEY
    provider, model = _parse_model_key(safe_model_key)

    # ------------------------------------------------------------
    # system / max output tokensï¼ˆä»»æ„ï¼‰
    # ------------------------------------------------------------
    system = (st.session_state.get(K_SYSTEM) or "").strip() or None
    max_output_tokens = int(st.session_state.get(K_MAX_OUT_TOK) or 0) or None

    # ------------------------------------------------------------
    # ç›´è¿‘è¡¨ç¤ºã‚’åˆæœŸåŒ–
    # ------------------------------------------------------------
    st.session_state[K_LAST_ANSWER] = ""
    st.session_state[K_LAST_IN_TOK] = None
    st.session_state[K_LAST_OUT_TOK] = None
    st.session_state[K_LAST_COST_OBJ] = None
    st.session_state[K_LAST_MODEL] = model
    st.session_state[K_LAST_NOTE] = ""
    st.session_state[K_LAST_RUN_ID] = None

    # ------------------------------------------------------------
    # busy_run + call_textï¼ˆæ­£æœ¬ï¼‰
    # ------------------------------------------------------------
    with st.spinner("AI ãŒæ–‡ç« ã‚’ç”Ÿæˆä¸­..."):
        with busy_run(
            projects_root=PROJECTS_ROOT,
            user_sub=str(sub),
            app_name=APP_NAME,
            page_name=PAGE_NAME,
            task_type="text",
            provider=provider,
            model=model,
            meta={"max_output_tokens": max_output_tokens},
        ) as br:
            run_id = br.run_id
            st.session_state[K_LAST_RUN_ID] = run_id

            # ------------------------------------------------------------
            # call_textï¼ˆmax_output_tokens ã¯ backend å¯¾å¿œæ™‚ã®ã¿ï¼‰
            # - å¯¾å¿œã—ã¦ã„ãªã„ç’°å¢ƒã§ã‚‚å£Šã‚Œãªã„ã‚ˆã† TypeError fallback
            # ------------------------------------------------------------
            try:
                if max_output_tokens is not None:
                    res = call_text(
                        provider=provider,
                        model=model,
                        prompt=final_prompt,
                        system=system,
                        max_output_tokens=max_output_tokens,
                    )
                else:
                    res = call_text(
                        provider=provider,
                        model=model,
                        prompt=final_prompt,
                        system=system,
                    )
            except TypeError:
                res = call_text(
                    provider=provider,
                    model=model,
                    prompt=final_prompt,
                    system=system,
                )

            answer = (getattr(res, "text", "") or "").strip()
            st.session_state[K_LAST_ANSWER] = answer

            # ------------------------------------------------------------
            # usage/cost ã®åæ˜ ï¼ˆæ¨è¨ˆã—ãªã„ï¼‰
            # ------------------------------------------------------------
            pp = apply_text_result_to_busy(
                br=br,
                res=res,
                extract_text_in_out_tokens=extract_text_in_out_tokens,
                note_ok="ok",
                note_no_usage="no_usage",
                note_no_cost="no_cost",
            )
            st.session_state[K_LAST_IN_TOK] = pp.in_tokens
            st.session_state[K_LAST_OUT_TOK] = pp.out_tokens
            st.session_state[K_LAST_COST_OBJ] = pp.cost_obj
            st.session_state[K_LAST_NOTE] = pp.note
            st.session_state[K_LAST_MODEL] = model

            # ------------------------------------------------------------
            # å›ç­”ãŒç©ºã®ã¨ãã®æ³¨æ„ï¼ˆæ¨æ¸¬ã—ãªã„ï¼‰
            # ------------------------------------------------------------
            if not answer:
                st.session_state[K_LAST_NOTE] = (st.session_state.get(K_LAST_NOTE) or "") + " / empty_text"

# ============================================================
# Outputï¼ˆç”Ÿæˆçµæœ + run summaryï¼‰
# ============================================================
if st.session_state.get(K_LAST_ANSWER):
    st.divider()
    st.subheader("âœ… ç”Ÿæˆçµæœ")
    st.write(st.session_state[K_LAST_ANSWER])

    render_run_summary_compact(
        projects_root=PROJECTS_ROOT,
        run_id=st.session_state.get(K_LAST_RUN_ID),
        model=st.session_state.get(K_LAST_MODEL),
        in_tokens=st.session_state.get(K_LAST_IN_TOK),
        out_tokens=st.session_state.get(K_LAST_OUT_TOK),
        cost=st.session_state.get(K_LAST_COST_OBJ),
        note=st.session_state.get(K_LAST_NOTE) or "",
        show_divider=True,
    )

    with st.expander("ğŸ”§ å®Ÿéš›ã«é€ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç¢ºèªç”¨ï¼‰", expanded=False):
        # ç”Ÿæˆå¾Œã« source_text ãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ç›´è¿‘ã®æ§‹ç¯‰ã‚’å†ç¾ã™ã‚‹
        max_chars = 15000
        final_prompt_for_view = build_final_prompt(
            template_name=template_name,
            base_text_kind=source_kind or "ä¸æ˜",
            base_text=source_text,
            additional_instruction=str(st.session_state.get(K_ADDITIONAL) or ""),
            max_chars=max_chars,
        )
        st.code(final_prompt_for_view, language="text")
