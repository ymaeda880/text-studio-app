# -*- coding: utf-8 -*-
# pages/701_AIãƒãƒ£ãƒƒãƒˆ.py
from __future__ import annotations

import os
import json
from typing import Optional, List, Dict, Any

import streamlit as st
import docx
from openai import OpenAI

from config.config import has_gemini_api_key, DEFAULT_USDJPY, estimate_tokens_from_text
from lib.gemini_responder import GeminiResponder
from lib.costs_new import estimate_chat_cost, ChatUsage


# ============================================================
# Page
# ============================================================
st.set_page_config(
    page_title="ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆGPT / Geminiï¼‰",
    page_icon="ğŸ’¬",
    layout="wide",
)

st.title("ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆGPT / Geminiï¼‰")
st.caption(
    "æ–‡æ›¸ã‚’ä¼šè©±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‰æï¼‰ã¨ã—ã¦ã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
    " æ–‡æ›¸ãŒãªãã¦ã‚‚é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆã¨ã—ã¦ä½¿ãˆã¾ã™ã€‚"
)


# ============================================================
# Sidebar: settings
# ============================================================
with st.sidebar:
    st.header("è¨­å®š")

    OPENAI_MODELS = ["gpt-5-mini", "gpt-5-nano"]
    GEMINI_MODELS = ["gemini-2.0-flash"]

    model_options = list(OPENAI_MODELS)
    if has_gemini_api_key():
        model_options += GEMINI_MODELS

    chat_model = st.radio(
        "ãƒ¢ãƒ‡ãƒ«",
        model_options,
        index=2,
        help="Gemini ã¯ API ã‚­ãƒ¼è¨­å®šæ™‚ã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚",
    )

    max_output_tokens = st.number_input(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¸Šé™ï¼‰",
        min_value=256,
        max_value=20000,
        value=1000,
        step=256,
    )

    debug_mode = st.toggle("ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º", value=False)

    st.caption(f"ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼ˆæ¦‚ç®—ï¼‰: {DEFAULT_USDJPY:.2f} JPY/USD")

    st.divider()

    col_a, col_b = st.columns(2)
    with col_a:
        if st.button("ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
            st.session_state.pop("chat_messages", None)
            st.session_state.pop("chat_costs", None)
            st.session_state.pop("openai_prev_response_id", None)
            st.rerun()

    with col_b:
        if st.button("æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.pop("doc_context", None)
            st.rerun()


# ============================================================
# Helpers
# ============================================================
def get_openai_client() -> OpenAI:
    api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
    if not api_key:
        raise RuntimeError(
            "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.streamlit/secrets.toml` ã« OPENAI_API_KEY ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
        )
    return OpenAI(api_key=api_key)


def is_gemini_model(m: str) -> bool:
    return m.startswith("gemini-")


def _ensure_state() -> None:
    if "chat_messages" not in st.session_state:
        # è¡¨ç¤ºç”¨ã®å±¥æ­´ï¼ˆsystemã¯ä¿æŒã—ãªã„ï¼è¡¨ç¤ºã‚‚ã—ãªã„ï¼‰
        st.session_state.chat_messages = []  # List[Dict[str,str]]
    if "chat_costs" not in st.session_state:
        st.session_state.chat_costs = []  # 1ã‚¿ãƒ¼ãƒ³ã”ã¨ã®æ¦‚ç®—ãƒ­ã‚°
    if "chat_draft_key" not in st.session_state:
        st.session_state.chat_draft_key = 0
    # OpenAI Responses API ã®ä¼šè©±ç¶™ç¶šID
    if "openai_prev_response_id" not in st.session_state:
        st.session_state.openai_prev_response_id = None


def _get_doc_context_text() -> str:
    ctx = st.session_state.get("doc_context")
    if not ctx:
        return ""
    kind = (ctx.get("kind") or "").strip()
    text = (ctx.get("text") or "").strip()
    if not text:
        return ""
    max_chars = 15000
    used = text[:max_chars]
    return f"ã€ä¼šè©±ã®å‰ææ–‡æ›¸ï¼š{kind}ï¼ˆå…ˆé ­ã€œæœ€å¤§{max_chars}æ–‡å­—ï¼‰ã€‘\n{used}\n"


def _build_openai_instructions() -> str:
    """
    Responses API ã¯ previous_response_id ã‚’ä½¿ã†å ´åˆã§ã‚‚
    instructions ã¯ã€Œå‰å›ã®instructionsã‚’å¼•ãç¶™ãŒãªã„ã€ä»•æ§˜ãªã®ã§æ¯å›æ¸¡ã™ã€‚
    """
    base = "ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    doc_text = _get_doc_context_text()
    if doc_text:
        base += (
            "\n\nä»¥ä¸‹ã¯ä¼šè©±ã®å‰æã¨ãªã‚‹å‚è€ƒæ–‡æ›¸ã§ã™ã€‚"
            "ã“ã®æ–‡æ›¸ã«åŸºã¥ãè³ªå•ã«ã¯æ–‡æ›¸ã«æ²¿ã£ã¦ç­”ãˆã€æ–‡æ›¸ã«ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšä¸æ˜ã¨è¨€ã£ã¦ãã ã•ã„ã€‚\n\n"
            + doc_text
        )
    return base


def _build_gemini_prompt_from_history(latest_user_text: str) -> str:
    """
    GeminiResponder.complete ã¯ system_instruction + user_content ãªã®ã§
    user_contentå´ã«å±¥æ­´ã‚’ã¾ã¨ã‚ã¦æ¸¡ã—ã¦ä¼šè©±ç¶™ç¶šã‚’æ“¬ä¼¼çš„ã«å®Ÿç¾ã€‚
    """
    doc_text = _get_doc_context_text()

    lines = []
    for m in st.session_state.chat_messages:
        role = m.get("role")
        if role == "user":
            lines.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {m.get('content','')}")
        elif role == "assistant":
            lines.append(f"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {m.get('content','')}")

    history_block = "\n".join(lines).strip()

    parts = []
    if doc_text:
        parts.append(
            "ä»¥ä¸‹ã¯ä¼šè©±ã®å‰æã¨ãªã‚‹å‚è€ƒæ–‡æ›¸ã§ã™ã€‚"
            "ã“ã®æ–‡æ›¸ã«åŸºã¥ãè³ªå•ã«ã¯æ–‡æ›¸ã«æ²¿ã£ã¦ç­”ãˆã€æ–‡æ›¸ã«ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšä¸æ˜ã¨è¨€ã£ã¦ãã ã•ã„ã€‚\n\n"
            + doc_text
        )
    if history_block:
        parts.append("ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n" + history_block)
    parts.append("ã€ä»Šå›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã€‘\n" + latest_user_text)
    parts.append("ã€æŒ‡ç¤ºã€‘\nä¸å¯§ãªæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªã‚‰ç¢ºèªè³ªå•ã‚’æœ€å°é™ã«ã—ã¦ãã ã•ã„ã€‚")

    return "\n\n".join(parts).strip()


def _safe_response_text_from_responses_api(resp: Any) -> str:
    """
    Responses API ã®è¿”ã‚Šå€¤ã‹ã‚‰ã€Œè¦‹ã¤ã‹ã‚‹é™ã‚Šã® text ã‚’å…¨éƒ¨æ‹¾ã†ã€ç‰ˆã€‚
    SDK/ãƒ¢ãƒ‡ãƒ«å·®åˆ†ã§ output ã®æ§‹é€ ãŒå¤‰ã‚ã£ã¦ã‚‚æ‹¾ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
    """

    # 1) SDKã®ä¾¿åˆ©ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒã‚ã‚‹ãªã‚‰æœ€å„ªå…ˆ
    t = getattr(resp, "output_text", None)
    if isinstance(t, str) and t.strip():
        return t.strip()

    # 2) resp ã‚’ dict åŒ–ï¼ˆã§ãã‚Œã°ï¼‰
    try:
        d = resp.model_dump()
    except Exception:
        try:
            d = resp.dict()
        except Exception:
            d = None

    def _collect_text(x: Any, acc: List[str]) -> None:
        """
        dict/list/object ã‚’å†å¸°çš„ã«è¾¿ã£ã¦ã€"text" ã¨ã„ã†ã‚­ãƒ¼/å±æ€§ã‚’è¦‹ã¤ã‘ãŸã‚‰å›åã™ã‚‹ã€‚
        """
        if x is None:
            return

        # str
        if isinstance(x, str):
            if x.strip():
                acc.append(x)
            return

        # list/tuple
        if isinstance(x, (list, tuple)):
            for it in x:
                _collect_text(it, acc)
            return

        # dict
        if isinstance(x, dict):
            # å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š {"type":"output_text","text":"..."}
            if isinstance(x.get("text"), str) and x.get("text", "").strip():
                acc.append(x["text"])
            # ä»–ã‚‚å†å¸°
            for v in x.values():
                _collect_text(v, acc)
            return

        # objectï¼ˆSDKã®Typed objectãªã©ï¼‰
        # "text" å±æ€§ãŒã‚ã‚Œã°æ‹¾ã†
        txt = getattr(x, "text", None)
        if isinstance(txt, str) and txt.strip():
            acc.append(txt)

        # ä»£è¡¨çš„ãªå±æ€§ã‚’å†å¸°
        for attr in ("output", "content", "message", "choices", "items", "data"):
            v = getattr(x, attr, None)
            if v is not None:
                _collect_text(v, acc)

    acc: List[str] = []
    if d is not None:
        _collect_text(d, acc)
    else:
        _collect_text(resp, acc)

    # ã‹ã¶ã‚Šã‚„ã‚´ãƒŸã‚’æ¸›ã‚‰ã™ï¼ˆå®Œå…¨ä¸€è‡´ã®ã¿ç°¡æ˜“é™¤å»ï¼‰
    seen = set()
    uniq = []
    for s in acc:
        s2 = s.strip()
        if not s2:
            continue
        if s2 in seen:
            continue
        seen.add(s2)
        uniq.append(s2)

    return "\n".join(uniq).strip()


def _add_turn_cost(model: str, input_tokens: int, output_tokens: int, note: str) -> None:
    try:
        cost = estimate_chat_cost(
            model,
            ChatUsage(input_tokens=int(input_tokens or 0), output_tokens=int(output_tokens or 0)),
            rate=DEFAULT_USDJPY,
        )
        st.session_state.chat_costs.append(
            {
                "model": model,
                "input_tokens": int(input_tokens or 0),
                "output_tokens": int(output_tokens or 0),
                "usd": float(cost.get("usd", 0.0)),
                "jpy": float(cost.get("jpy", 0.0)),
                "note": note or "",
            }
        )
    except Exception:
        st.session_state.chat_costs.append(
            {
                "model": model,
                "input_tokens": int(input_tokens or 0),
                "output_tokens": int(output_tokens or 0),
                "usd": 0.0,
                "jpy": 0.0,
                "note": "ï¼ˆæ–™é‡‘è¨ˆç®—å¤±æ•—ï¼‰",
            }
        )


# ============================================================
# State init
# ============================================================
_ensure_state()

# ============================================================
# 1) æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰
# ============================================================
st.subheader("1ï¸âƒ£ æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰")
st.caption("ã“ã“ã§ã‚»ãƒƒãƒˆã—ãŸæ–‡æ›¸ã¯ã€ä¼šè©±ã®å‰æï¼ˆå‚è€ƒè³‡æ–™ï¼‰ã¨ã—ã¦æ¯ã‚¿ãƒ¼ãƒ³å‚ç…§ã•ã‚Œã¾ã™ã€‚")

tab_file, tab_text = st.tabs(["ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘"])

tmp_text: str = ""
tmp_kind: str = ""

with tab_file:
    uploaded = st.file_uploader(
        "Word / ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰",
        type=["docx", "txt", "json", "md"],
        key="ctx_file_uploader",
    )

    if uploaded is not None:
        file_name = uploaded.name
        ext = file_name.lower().rsplit(".", 1)[-1]
        try:
            if ext == "docx":
                doc = docx.Document(uploaded)
                tmp_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                tmp_kind = "Word(.docx)"
            elif ext in ("txt", "md"):
                raw = uploaded.read()
                tmp_text = raw.decode("utf-8", errors="ignore")
                tmp_kind = f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.{ext})"
            elif ext == "json":
                raw = uploaded.read()
                obj = json.loads(raw.decode("utf-8", errors="ignore"))
                tmp_text = json.dumps(obj, ensure_ascii=False, indent=2)
                tmp_kind = "JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.jsonï¼‰"
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

with tab_text:
    pasted = st.text_area(
        "ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘ï¼ˆä»»æ„ï¼‰",
        height=180,
        placeholder="ã“ã“ã«è²¼ã‚Šä»˜ã‘ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ä¼šè©±ã®å‰ææ–‡æ›¸ã¨ã—ã¦ã‚»ãƒƒãƒˆã§ãã¾ã™ã€‚",
        key="ctx_text_paste",
    )
    if pasted.strip():
        tmp_text = pasted
        tmp_kind = "è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆ"

col_set, col_show = st.columns([1, 2])
with col_set:
    if st.button("ã“ã®æ–‡æ›¸ã‚’ä¼šè©±ã«ã‚»ãƒƒãƒˆ", disabled=not bool((tmp_text or "").strip())):
        st.session_state.doc_context = {"kind": tmp_kind, "text": tmp_text}
        st.success(f"âœ… æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼ˆ{tmp_kind} / ç´„ {len(tmp_text)} æ–‡å­—ï¼‰")

with col_show:
    ctx = st.session_state.get("doc_context")
    if ctx and (ctx.get("text") or "").strip():
        st.info(f"ğŸ“Œ ç¾åœ¨ã®æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼š{ctx.get('kind','')}ï¼ˆç´„ {len(ctx.get('text',''))} æ–‡å­—ï¼‰")
        with st.expander("æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­ï¼‰", expanded=False):
            t = (ctx.get("text") or "")
            preview = t[:1000] + ("\nâ€¦ï¼ˆçœç•¥ï¼‰" if len(t) > 1000 else "")
            st.code(preview, language="text")
    else:
        st.caption("ï¼ˆæ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯æœªè¨­å®šï¼‰")

st.divider()

# ============================================================
# 2) Chat UI
# ============================================================
st.subheader("2ï¸âƒ£ ãƒãƒ£ãƒƒãƒˆ")

# å±¥æ­´è¡¨ç¤º
for m in st.session_state.chat_messages:
    with st.chat_message(m.get("role", "assistant")):
        st.write(m.get("content", ""))

# å…¥åŠ›æ¬„ï¼ˆã‚¯ãƒªã‚¢ã¯ key ã‚’å¤‰ãˆã‚‹æ–¹å¼ï¼‰
draft_key = f"chat_draft_{st.session_state.chat_draft_key}"
user_text = st.text_area(
    "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
    key=draft_key,
    height=90,
    placeholder="ã“ã“ã«å…¥åŠ›ã—ã¦ã€Œé€ä¿¡ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼ˆShift+Enterã§æ”¹è¡Œï¼‰ã€‚",
)

col_send, col_hint = st.columns([1, 4])
with col_send:
    send = st.button("é€ä¿¡", type="primary")
with col_hint:
    st.caption("â€» æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¦ã„ã‚‹å ´åˆã€ä¼šè©±ã®å‰æã¨ã—ã¦æ¯ã‚¿ãƒ¼ãƒ³å‚ç…§ã•ã‚Œã¾ã™ã€‚")

# ï¼ˆãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºé ˜åŸŸï¼šå¸¸ã«å‡ºã™ã¨é‚ªé­”ãªã®ã§ toggle æ™‚ã ã‘ï¼‰
if debug_mode:
    st.caption("ãƒ‡ãƒãƒƒã‚°ã¯ã“ã®ä¸‹ã«å‡ºã¾ã™ï¼ˆé€ä¿¡å¾Œã®çµæœãªã©ï¼‰ã€‚")

if send:
    if not (user_text or "").strip():
        st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™ã€‚")
        st.stop()

    user_text = user_text.strip()

    # è¡¨ç¤ºç”¨å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_messages.append({"role": "user", "content": user_text})

    used_gemini = is_gemini_model(chat_model)

    answer = ""
    input_tokens: Optional[int] = None
    output_tokens: Optional[int] = None
    note = ""

    # é€ä¿¡â†’ç”ŸæˆãŒçµ‚ã‚ã£ãŸã‚‰å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ã—ãŸã„ã®ã§ã€å…ˆã«æ¬¡keyã‚’æº–å‚™
    next_draft_key_value = st.session_state.chat_draft_key + 1

    with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
        if used_gemini:
            if not has_gemini_api_key():
                st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Gemini ã‚’ä½¿ã†ã«ã¯ã‚­ãƒ¼è¨­å®šãŒå¿…è¦ã§ã™ã€‚")
                st.stop()

            responder = GeminiResponder()
            gemini_user_content = _build_gemini_prompt_from_history(user_text)

            result = responder.complete(
                model=chat_model,
                system_instruction="ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                user_content=gemini_user_content,
                max_output_tokens=int(max_output_tokens),
            )
            answer = (result.text or "").strip()

            input_tokens = int(estimate_tokens_from_text(gemini_user_content))
            output_tokens = int(estimate_tokens_from_text(answer))
            note = "ï¼ˆGemini: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"

            if debug_mode:
                with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šGemini", expanded=False):
                    st.write({"len_answer": len(answer), "input_tokens_est": input_tokens, "output_tokens_est": output_tokens})

        else:
            # OpenAIï¼šResponses APIï¼ˆç¶™ç¶šä¼šè©±ã¯ previous_response_idï¼‰
            try:
                client = get_openai_client()
            except Exception as e:
                st.error(str(e))
                st.stop()

            instructions = _build_openai_instructions()
            prev_id = st.session_state.get("openai_prev_response_id")

            try:
                # Responses APIï¼šprevious_response_id ã§ä¼šè©±ç¶™ç¶š
                resp = client.responses.create(
                    model=chat_model,
                    instructions=instructions,
                    input=user_text,
                    previous_response_id=prev_id,
                    max_output_tokens=int(max_output_tokens),
                )
            except Exception as e:
                st.error(f"OpenAI API å‘¼ã³å‡ºã—ã«å¤±æ•—: {e}")
                st.stop()

            # ä¼šè©±ç¶™ç¶šIDã‚’ä¿å­˜ï¼ˆæ¬¡ã‚¿ãƒ¼ãƒ³ç”¨ï¼‰
            new_prev_id = getattr(resp, "id", None)
            if isinstance(new_prev_id, str) and new_prev_id.strip():
                st.session_state.openai_prev_response_id = new_prev_id

            # ã¾ãš dump ã‚’ä¿å­˜ï¼ˆç©ºã§ã‚‚å¿…ãšæ®‹ã™ï¼‰
            try:
                st.session_state["last_openai_dump"] = resp.model_dump()
            except Exception:
                st.session_state["last_openai_dump"] = str(resp)

            if not answer:
                st.error("OpenAIã®æŠ½å‡ºçµæœãŒç©ºã§ã—ãŸã€‚ä¸‹ã®ãƒ‡ãƒãƒƒã‚°ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                if st.session_state.get("debug_mode", False):
                    with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šOpenAIãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ï¼ˆmodel_dumpï¼‰", expanded=True):
                        st.write(st.session_state.get("last_openai_dump"))
                st.stop()


            answer = _safe_response_text_from_responses_api(resp).strip()
            st.session_state["last_answer"] = answer

            # usageï¼ˆå–ã‚Œã‚Œã°å®Ÿæ¸¬ã€ãªã‘ã‚Œã°æ¨å®šï¼‰
            u = getattr(resp, "usage", None)
            if u is not None:
                # Responses API ã® usage ã¯ input_tokens / output_tokens ãŒåŸºæœ¬
                input_tokens = int(getattr(u, "input_tokens", 0) or 0)
                output_tokens = int(getattr(u, "output_tokens", 0) or 0)

            if not input_tokens:
                input_tokens = int(estimate_tokens_from_text(instructions + "\n\n" + user_text))
                note = "ï¼ˆOpenAI: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"
            if not output_tokens:
                output_tokens = int(estimate_tokens_from_text(answer))
                note = "ï¼ˆOpenAI: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"

            if debug_mode:
                with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šOpenAI Responses", expanded=False):
                    st.write(
                        {
                            "prev_id_in": prev_id,
                            "resp_id_out": getattr(resp, "id", None),
                            "status": getattr(resp, "status", None),
                            "len_answer": len(answer),
                            "usage": {
                                "input_tokens": int(input_tokens or 0),
                                "output_tokens": int(output_tokens or 0),
                            },
                        }
                    )
                    if not answer:
                        st.warning("answer ãŒç©ºã§ã™ã€‚resp.output ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                        try:
                            # SDKå·®åˆ†ç”¨ã« dict åŒ–ã§ãã‚Œã°å‡ºã™
                            st.write(resp.model_dump())
                        except Exception:
                            st.write(str(resp))

    # answer ãŒç©ºãªã‚‰ã€ã“ã“ã§æ­¢ã‚ã¦ â€œç©ºã®assistantâ€ ã‚’å±¥æ­´ã«å…¥ã‚Œãªã„
    if not answer:
        st.error("å›ç­”ãŒç©ºã§ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºã‚’ONã«ã—ã¦ã€OpenAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # è¡¨ç¤ºç”¨å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_messages.append({"role": "assistant", "content": answer})

    # æ–™é‡‘æ¦‚ç®—ï¼ˆ1ã‚¿ãƒ¼ãƒ³ï¼‰
    _add_turn_cost(
        model=chat_model,
        input_tokens=int(input_tokens or 0),
        output_tokens=int(output_tokens or 0),
        note=note,
    )

    # å…¥åŠ›æ¬„ã‚¯ãƒªã‚¢ï¼škey ã‚’é€²ã‚ã¦ rerun
    st.session_state.chat_draft_key = next_draft_key_value
    st.rerun()


# ============================================================
# 3) ã‚³ã‚¹ãƒˆè¡¨ç¤ºï¼ˆä»»æ„ï¼‰
# ============================================================
st.divider()
st.subheader("3ï¸âƒ£ æ–™é‡‘ï¼ˆæ¦‚ç®—ï¼‰")

if st.session_state.chat_costs:
    total_jpy = sum(float(x.get("jpy", 0.0)) for x in st.session_state.chat_costs)
    total_usd = sum(float(x.get("usd", 0.0)) for x in st.session_state.chat_costs)

    last = st.session_state.chat_costs[-1]
    st.write(f"- ç›´è¿‘ã‚¿ãƒ¼ãƒ³: **Â¥{last.get('jpy',0.0):,.2f}**ï¼ˆ${last.get('usd',0.0):.6f}ï¼‰ {last.get('note','')}")
    st.write(f"- ç´¯è¨ˆ: **Â¥{total_jpy:,.2f}**ï¼ˆ${total_usd:.6f}ï¼‰")

    with st.expander("ã‚¿ãƒ¼ãƒ³åˆ¥ã®å†…è¨³", expanded=False):
        for i, r in enumerate(st.session_state.chat_costs, start=1):
            st.write(
                f"{i:02d}. {r.get('model','')}  "
                f"in={int(r.get('input_tokens',0)):,} / out={int(r.get('output_tokens',0)):,}  "
                f"â†’ Â¥{float(r.get('jpy',0.0)):,.2f}ï¼ˆ${float(r.get('usd',0.0)):.6f}ï¼‰ {r.get('note','')}"
            )
else:
    st.caption("ï¼ˆã¾ã å®Ÿè¡Œã—ã¦ã„ã¾ã›ã‚“ï¼‰")
