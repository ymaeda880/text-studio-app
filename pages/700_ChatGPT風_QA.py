# -*- coding: utf-8 -*-
# pages/700_ChatGPTé¢¨_QA.py
from __future__ import annotations

import os
import json
from typing import Optional

import streamlit as st
import docx
from openai import OpenAI

from config.config import has_gemini_api_key, DEFAULT_USDJPY, estimate_tokens_from_text
from lib.gemini_responder import GeminiResponder
from lib.costs_new import estimate_chat_cost, ChatUsage


# ============================================================
# Page
# ============================================================
st.set_page_config(
    page_title="ğŸ’¬ è³ªå•ãƒšãƒ¼ã‚¸ï¼ˆWord / ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdownï¼‰",
    page_icon="ğŸ’¬",
    layout="wide",
)

st.title("ğŸ’¬ ChatGPTé¢¨ï¼šæ–‡æ›¸ã‚’èª­ã¾ã›ã¦è³ªå•")

st.caption(
    "Wordï¼ˆ.docxï¼‰ã ã‘ã§ãªãã€.txt / .json / .md ã‚‚èª­ã¿è¾¼ã‚“ã§è³ªå•ã§ãã¾ã™ã€‚"
    " æ–‡æ›¸ã®å…¥åŠ›ãŒãªãã¦ã‚‚ã€ä¸€èˆ¬çš„ãªè³ªå•ã¨ã—ã¦ãã®ã¾ã¾è³ªå•ã§ãã¾ã™ã€‚"
)


# ============================================================
# Sidebar: model / cost settings
# ============================================================
with st.sidebar:
    st.header("è¨­å®š")

    # --- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGPT / Geminiï¼‰ ---
    OPENAI_MODELS = ["gpt-5-mini", "gpt-5-nano"]
    GEMINI_MODELS = ["gemini-2.0-flash"]

    model_options = list(OPENAI_MODELS)
    if has_gemini_api_key():
        model_options += GEMINI_MODELS

    chat_model = st.radio(
        "ãƒ¢ãƒ‡ãƒ«",
        model_options,
        index=0,
        help="Gemini ã¯ API ã‚­ãƒ¼è¨­å®šæ™‚ã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚",
    )

    max_output_tokens = st.number_input(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¸Šé™ï¼‰",
        min_value=256,
        max_value=20000,
        value=4000,
        step=256,
    )

    st.caption(f"ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼ˆæ¦‚ç®—ï¼‰: {DEFAULT_USDJPY:.2f} JPY/USD")


# ============================================================
# API clients (OpenAI / Gemini)
# ============================================================
def get_openai_client() -> OpenAI:
    api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
    if not api_key:
        raise RuntimeError(
            "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.streamlit/secrets.toml` ã« OPENAI_API_KEY ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
        )
    return OpenAI(api_key=api_key)


def is_gemini_model(m: str) -> bool:
    return m.startswith("gemini-")


# ============================================================
# å…¥åŠ›ã‚½ãƒ¼ã‚¹ï¼šãƒ•ã‚¡ã‚¤ãƒ« or ãƒ†ã‚­ã‚¹ãƒˆè²¼ã‚Šä»˜ã‘
# ============================================================
st.subheader("1ï¸âƒ£ æ–‡æ›¸ã®å…¥åŠ›æ–¹æ³•ï¼ˆä»»æ„ï¼‰")

tab_file, tab_text = st.tabs(["ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘"])

source_text: str = ""
source_kind: str = ""

with tab_file:
    uploaded = st.file_uploader(
        "Word / ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰",
        type=["docx", "txt", "json", "md"],
    )

    if uploaded is not None:
        file_name = uploaded.name
        ext = file_name.lower().rsplit(".", 1)[-1]

        try:
            if ext == "docx":
                doc = docx.Document(uploaded)
                source_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                source_kind = "Word(.docx)"

            elif ext in ("txt", "md"):
                raw = uploaded.read()
                source_text = raw.decode("utf-8", errors="ignore")
                source_kind = f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.{ext})"

            elif ext == "json":
                raw = uploaded.read()
                obj = json.loads(raw.decode("utf-8", errors="ignore"))
                source_text = json.dumps(obj, ensure_ascii=False, indent=2)
                source_kind = "JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.jsonï¼‰"

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        if source_text:
            st.success(f"âœ… {source_kind} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆç´„ {len(source_text)} æ–‡å­—ï¼‰")
            with st.expander("èª­ã¿è¾¼ã‚“ã æœ¬æ–‡ï¼ˆå…ˆé ­éƒ¨åˆ†ã‚’ç¢ºèªï¼‰", expanded=False):
                preview = source_text[:1000]
                if len(source_text) > 1000:
                    preview += "\nâ€¦ï¼ˆçœç•¥ï¼‰"
                st.code(preview, language="text")

with tab_text:
    pasted = st.text_area(
        "ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘ï¼ˆä»»æ„ï¼‰",
        height=250,
        placeholder="ã“ã“ã«ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚ï¼ˆWord ã‹ã‚‰ã‚³ãƒ”ãƒš / JSON / Markdown ãªã©ï¼‰",
    )
    if pasted.strip():
        source_text = pasted
        source_kind = "è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆ"
        st.info(f"ğŸ“Œ ç¾åœ¨ã®è³ªå•å¯¾è±¡ã¯ã€Œ{source_kind}ã€ï¼ˆç´„ {len(source_text)} æ–‡å­—ï¼‰ã§ã™ã€‚")


# ============================================================
# è³ªå•å…¥åŠ› & å®Ÿè¡Œ
# ============================================================
st.subheader("2ï¸âƒ£ è³ªå•ã™ã‚‹")

question = st.text_area(
    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæ–‡æ›¸ãªã—ã§ã‚‚OKï¼‰",
    placeholder="ä¾‹ï¼šã“ã®æ–‡æ›¸ã§æ”¹è¨‚ã•ã‚ŒãŸéƒ¨åˆ†ã¯ã©ã“ï¼Ÿ / ã“ã®JSONã§é‡è¦ãªã‚­ãƒ¼ã¯ï¼Ÿ / é‡‘èæ”¿ç­–ã®åŠ¹æœã‚’ç°¡å˜ã«èª¬æ˜ã—ã¦ ãªã©",
    height=120,
)

col_run, col_info = st.columns([1, 2])

with col_run:
    # æ–¹é‡ï¼šuse_container_width ã¯ä½¿ã‚ãªã„
    run = st.button("AIã«è³ªå•ã™ã‚‹", type="primary")

with col_info:
    st.caption(
        "â€» å…¥åŠ›ã‚½ãƒ¼ã‚¹ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯ã€è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆãŒå„ªå…ˆã•ã‚Œã¾ã™ã€‚"
        " ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã§è³ªå•ã—ãŸã„å ´åˆã¯ã€è²¼ã‚Šä»˜ã‘æ¬„ã‚’ç©ºã«ã—ã¦ãã ã•ã„ã€‚"
        " æ–‡æ›¸ãŒæœªå…¥åŠ›ãªã‚‰ä¸€èˆ¬è³ªå•ã¨ã—ã¦å›ç­”ã—ã¾ã™ã€‚"
    )


# ============================================================
# å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
# ============================================================
def build_prompt_doc(source_kind: str, question: str, used_text: str, max_chars: int) -> str:
    return f"""
ã‚ãªãŸã¯æ–‡æ›¸ç·¨é›†ã¨ãƒ‡ãƒ¼ã‚¿è§£é‡ˆã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æœ¬æ–‡ï¼ˆ{source_kind}ï¼‰ã‚’èª­ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
{question}

ã€æœ¬æ–‡ï¼ˆå…ˆé ­ã€œæœ€å¤§{max_chars}æ–‡å­—ã¾ã§ï¼‰ã€‘
{used_text}
""".strip()


def build_prompt_general(question: str) -> str:
    return f"""
ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚å‰æãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€å¿…è¦æœ€å°é™ã®ç¢ºèªè³ªå•ã‚’ã—ã¦ã‹ã‚‰ç­”ãˆã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
{question}
""".strip()


if run:
    if not question.strip():
        st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    q = question.strip()

    # æ–‡æ›¸ãŒã‚ã‚Œã°ã€Œæ–‡æ›¸QAã€ã€ãªã‘ã‚Œã°ã€Œä¸€èˆ¬QAã€
    doc_mode = bool(source_text.strip())

    if doc_mode:
        max_chars = 15000
        used_text = source_text[:max_chars]
        prompt = build_prompt_doc(source_kind, q, used_text, max_chars)
        mode_label = "ğŸ“„ æ–‡æ›¸ã«åŸºã¥ãå›ç­”"
    else:
        prompt = build_prompt_general(q)
        mode_label = "ğŸ’¬ ä¸€èˆ¬è³ªå•ã¨ã—ã¦å›ç­”ï¼ˆæ–‡æ›¸æœªä½¿ç”¨ï¼‰"

    answer = ""
    used_gemini = is_gemini_model(chat_model)

    # usageï¼ˆå–ã‚Œãªã„å ´åˆã‚‚ã‚ã‚‹ã®ã§ Optionalï¼‰
    input_tokens: Optional[int] = None
    output_tokens: Optional[int] = None
    note = ""

    with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
        if used_gemini:
            # --- Gemini ---
            if not has_gemini_api_key():
                st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Gemini ã‚’ä½¿ã†ã«ã¯ã‚­ãƒ¼è¨­å®šãŒå¿…è¦ã§ã™ã€‚")
                st.stop()

            responder = GeminiResponder()
            result = responder.complete(
                model=chat_model,
                system_instruction="ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                user_content=prompt,
                max_output_tokens=int(max_output_tokens),
            )
            answer = (result.text or "").strip()

            # Gemini ã¯ usage ãŒå–ã‚Œãªã„ã“ã¨ãŒå¤šã„ã®ã§æ¨å®š
            input_tokens = int(estimate_tokens_from_text(prompt))
            output_tokens = int(estimate_tokens_from_text(answer))
            note = "ï¼ˆGemini: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"

        else:
            # --- OpenAI (GPT) ---
            try:
                client = get_openai_client()
            except Exception as e:
                st.error(str(e))
                st.stop()

            res = client.chat.completions.create(
                model=chat_model,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                # gpt-5ç³»ã§ã¯ max_tokens ã§ã¯ãªã max_completion_tokens
                max_completion_tokens=int(max_output_tokens),
            )


            answer = (res.choices[0].message.content or "").strip()

            # usage ãŒå–ã‚Œã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ã†ï¼ˆSDKå·®åˆ†å¸åï¼‰
            try:
                u = res.usage
                if u is not None:
                    input_tokens = int(getattr(u, "prompt_tokens", None) or getattr(u, "input_tokens", 0) or 0)
                    output_tokens = int(
                        getattr(u, "completion_tokens", None) or getattr(u, "output_tokens", 0) or 0
                    )
            except Exception:
                input_tokens = None
                output_tokens = None

            # å–ã‚Œãªã‘ã‚Œã°æ¨å®šã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if not input_tokens:
                input_tokens = int(estimate_tokens_from_text(prompt))
                note = "ï¼ˆOpenAI: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"
            if not output_tokens:
                output_tokens = int(estimate_tokens_from_text(answer))
                note = "ï¼ˆOpenAI: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰"

    # --- å›ç­” ---
    st.markdown("### ğŸ§­ å›ç­”")
    st.caption(mode_label)
    st.write(answer)

    # --- æ–™é‡‘è¡¨ç¤ºï¼ˆæ¦‚ç®—ï¼‰ ---
    try:
        cost = estimate_chat_cost(
            chat_model,
            ChatUsage(input_tokens=int(input_tokens or 0), output_tokens=int(output_tokens or 0)),
            rate=DEFAULT_USDJPY,
        )
        st.markdown("### ğŸ’° æ–™é‡‘ï¼ˆæ¦‚ç®—ï¼‰")
        st.write(f"- ãƒ¢ãƒ‡ãƒ«: **{chat_model}**")
        st.write(f"- Input tokens: {int(input_tokens or 0):,}")
        st.write(f"- Output tokens: {int(output_tokens or 0):,}")
        st.info(f"ğŸ“Š æ¦‚ç®—: **Â¥{cost['jpy']:,.2f}**ï¼ˆ${cost['usd']:.6f}ï¼‰{note}")
    except Exception as e:
        st.warning(f"æ–™é‡‘è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

else:
    # åˆæœŸã‚¬ã‚¤ãƒ‰ï¼ˆæ–‡æ›¸ã¯ä»»æ„ï¼‰
    if not source_text.strip():
        st.info("æ–‡æ›¸ãªã—ã§ã‚‚è³ªå•ã§ãã¾ã™ï¼ˆä¸€èˆ¬è³ªå•ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚æ–‡æ›¸ã«åŸºã¥ãå›ç­”ãŒå¿…è¦ãªã‚‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")
