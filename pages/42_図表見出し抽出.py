# -*- coding: utf-8 -*-
# pages/42_å›³è¡¨è¦‹å‡ºã—æŠ½å‡º.py
#
# PDF ã‹ã‚‰ã€Œå›³/è¡¨/å›³è¡¨ã€ã®è¦‹å‡ºã—è¡Œã ã‘ã‚’æŠ½å‡ºã—ã¦ä¸€è¦§è¡¨ç¤ºã—ï¼Œ
# Excel (xlsx) ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ãƒšãƒ¼ã‚¸ã€‚

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Any, Tuple
import io
import re
import tempfile

import streamlit as st
import pandas as pd

# === å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆlib/ï¼‰ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ===
from lib.text_normalizer import (
    z2h_numhy,
    HY,
)
from lib.toc_check.toc_segments import (
    pdf_to_text_per_page,
    extract_single_page_label,
)
from lib.chart_check.helpers import (
    protect_for_excel_csv,
    protect_for_excel_xlsx,
)

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(
    page_title="ğŸ–¼ï¸ å›³è¡¨è¦‹å‡ºã—æŠ½å‡ºï¼ˆé ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰",
    page_icon="ğŸ–¼ï¸",
    layout="wide",
)
st.title("ğŸ–¼ï¸ å›³è¡¨è¦‹å‡ºã—æŠ½å‡ºï¼ˆå›³/è¡¨/å›³è¡¨ï¼‰")
st.caption(
    "PDFã‹ã‚‰ã€Œå›³ã€ã€Œè¡¨ã€ã€Œå›³è¡¨ã€ã®è¦‹å‡ºã—è¡Œã‚’è‡ªå‹•æŠ½å‡ºã—ã¦ä¸€è¦§è¡¨ç¤ºã—ã¾ã™ï¼"
    "æŠ½å‡ºã—ãŸçµæœã¯ Excelï¼ˆxlsxï¼‰ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼"
)
st.caption("AIã¯ä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“ï¼å®‰å¿ƒã—ã¦pdfã‚’ä¸¸ã”ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ æŠ½å‡ºã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    ctx_chars  = st.slider("ç•ªå·å‰å¾Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—æ•°ï¼ˆexcerpt ç”¨ï¼‰", 10, 300, 60, 5)
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)

if not uploaded or not run:
    st.stop()

# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
with tempfile.TemporaryDirectory() as td:
    pdf_path = Path(td) / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")

# =========================
# å›³è¡¨æŠ½å‡ºç”¨ã®æ­£è¦è¡¨ç¾ãªã©ï¼ˆ14_å›³è¡¨ãƒã‚§ãƒƒã‚¯.py ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
# =========================
DOT = r"[\.ï¼ãƒ»ï½¥]"
NUM_ZH = r"[0-9ï¼-ï¼™]+"
NUM_TOKEN = rf"""
(
    # ä¾‹ï¼š4.2-1(1/6), 4.2-1ï¼ˆ1ï¼ï¼–ï¼‰ ãªã©
    {NUM_ZH}
    (?:\s*(?:{DOT}|{HY})\s*{NUM_ZH})*
    (?:\s*[ï¼ˆ(]?\s*{NUM_ZH}\s*[\/ï¼]\s*{NUM_ZH}\s*[ï¼‰)])?
    |
    # ä¾‹ï¼š(1), ï¼ˆï¼’ï¼‰
    [ï¼ˆ(]\s*{NUM_ZH}\s*[ï¼‰)]
)
"""

EXTRACT_RE = re.compile(
    rf"(?P<kind>å›³è¡¨|å›³|è¡¨)\s*(?P<num>{NUM_TOKEN})",
    re.X
)


def canon_num(num: str) -> str:
    """
    å›³è¡¨ç•ªå·ã®æ­£è¦åŒ–ï¼š
    - å…¨è§’â†’åŠè§’
    - ãƒ‰ãƒƒãƒˆé¡ã‚’ "."
    - ãƒã‚¤ãƒ•ãƒ³é¡ã‚’ "-"
    - æ‹¬å¼§å†…ã®ä½™è¨ˆãªç©ºç™½å‰Šé™¤
    """
    # å…¨è§’ â†’ åŠè§’
    s = num.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰", "0123456789()"))

    # ãƒ‰ãƒƒãƒˆé¡ â†’ "."
    s = re.sub(DOT, ".", s)

    # ãƒã‚¤ãƒ•ãƒ³é¡ â†’ "-"
    s = re.sub(HY, "-", s)

    # "." ã¨ "-" ã®å‰å¾Œã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤
    s = re.sub(r"\s*\.\s*", ".", s)
    s = re.sub(r"\s*-\s*", "-", s)

    # è¤‡æ•°ã‚¹ãƒšãƒ¼ã‚¹ â†’ 1 å€‹
    s = re.sub(r"[ \u3000]+", " ", s)

    # æ‹¬å¼§å†…ã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤
    s = re.sub(r"\(\s*", "(", s)
    s = re.sub(r"\s*\)", ")", s)

    return s.strip()


def canon_label(kind: str, num: str) -> str:
    """
    å›³è¡¨ã‚­ãƒ¼ï¼ˆä¾‹ï¼š'è¡¨3.1.5-1(1/3)'ï¼‰ã‚’ç”Ÿæˆã€‚
    """
    return f"{kind}{canon_num(num)}"


# regex ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
try:
    import regex as re2
except Exception:
    re2 = re

PARTICLES_RE = re2.compile(r"(?:ã«|ã‚’|ã¯|ã¸|ã§|ã¨|ã®|ãªã©|ç­‰|ã¾ãŸã¯|åˆã¯|ãŠã‚ˆã³|åŠã³|ã‹ã¤)")


# ===== è¡ŒæŠ½å‡ºè£œåŠ©é–¢æ•° =====
def extract_line_covering_match(full: str, start: int, end: int) -> Tuple[int, str, int, int]:
    """
    ãƒãƒƒãƒã‚’å¿…ãšå«ã‚€è¡Œï¼ˆæ”¹è¡Œã¾ãŸãå¯¾å¿œï¼‰ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (è¡Œç•ªå·, è¡Œãƒ†ã‚­ã‚¹ãƒˆ, è¡Œé–‹å§‹ä½ç½®, è¡Œçµ‚äº†ä½ç½®)
    """
    line_start = full.rfind("\n", 0, start)
    line_start = 0 if line_start == -1 else line_start + 1
    line_end = full.find("\n", end)
    if line_end == -1:
        line_end = len(full)
    line_txt = full[line_start:line_end].rstrip("\r\n")
    approx_lineno = full.count("\n", 0, line_start) + 1
    return approx_lineno, line_txt, line_start, line_end


# ===== ãƒšãƒ¼ã‚¸å˜ä½ã®æŠ½å‡º =====
def judge_hits_in_page(page_text: str, ctx: int) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    1ãƒšãƒ¼ã‚¸åˆ†ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰
    - captions: è¦‹å‡ºã—ï¼ˆã‚¿ã‚¤ãƒˆãƒ«è¡Œç›¸å½“ï¼‰
    - refs    : æœ¬æ–‡ä¸­ã®å‚ç…§
    ã‚’æŠ½å‡ºã—ã¦è¿”ã™ã€‚

    ã“ã®ãƒšãƒ¼ã‚¸ï¼ˆ42_ï¼‰ã§ã¯ captions ã ã‘ã‚’åˆ©ç”¨ã™ã‚‹ãŒï¼Œ
    14_å›³è¡¨ãƒã‚§ãƒƒã‚¯.py ã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã‚’ç¶­æŒã™ã‚‹ã€‚
    """
    captions: List[Dict[str, Any]] = []
    refs: List[Dict[str, Any]] = []
    full = page_text.replace("\r\n", "\n").replace("\r", "\n")

    for m in EXTRACT_RE.finditer(full):
        kind, num, raw = m.group("kind"), m.group("num"), m.group(0)
        lineno, line_txt, line_start, line_end = extract_line_covering_match(full, m.start(), m.end())

        is_line_head = (full[line_start:m.start()].strip() == "")
        rel_end = (m.start() - line_start) + len(raw)
        after_on_line = line_txt[rel_end:] if rel_end <= len(line_txt) else ""
        particle_follow = bool(re2.match(rf"\s*{PARTICLES_RE.pattern}", after_on_line))
        has_period = ("ã€‚" in line_txt)
        is_reference = (not is_line_head) or particle_follow or has_period

        # å¼·èª¿ã¨ excerpt
        highlighted = line_txt.replace(raw, f"âŸª{raw}âŸ«", 1)
        left  = max(0, m.start() - ctx)
        right = min(len(full), m.end() + ctx)
        excerpt = full[left:m.start()] + f"âŸª{raw}âŸ«" + full[m.end():right]

        if is_reference:
            refs.append({
                "è¡Œç•ªå·": lineno,
                "å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ": raw.strip(),
                "å›³è¡¨ç¨®é¡": kind,
                "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
                "å›³è¡¨ã‚­ãƒ¼": canon_label(kind, num),
                "excerpt": excerpt,
                "è¡Œãƒ†ã‚­ã‚¹ãƒˆ": line_txt,
                "è¡Œãƒ†ã‚­ã‚¹ãƒˆ(å¼·èª¿)": highlighted,
                "åˆ¤å®š": "å‚ç…§",
                "rule(ç†ç”±)": (
                    "è¡Œé ­ã§ãªã„â†’å‚ç…§" if not is_line_head else
                    ("ç›´å¾ŒãŒåŠ©è©/æ¥ç¶šèªâ†’å‚ç…§" if particle_follow else "è¡Œã«å¥ç‚¹ã‚ã‚Šâ†’å‚ç…§")
                ),
            })
        else:
            # è¡Œé ­ã«ã€Œå›³3.1-1 ...ã€ãªã©ãŒæ¥ã¦ã„ã‚‹å ´åˆ â†’ è¦‹å‡ºã—ã¨ã¿ãªã™
            title = re.sub(r"^[\s:ï¼š.\-ï¼ã€ãƒ»]+", "", after_on_line).strip()
            captions.append({
                "è¡Œç•ªå·": lineno,
                "å›³è¡¨ç¨®é¡": kind,
                "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
                "å›³è¡¨ã‚­ãƒ¼": canon_label(kind, num),
                "è¦‹å‡ºã—ã‚¿ã‚¤ãƒˆãƒ«": title,
                "matched_line": line_txt,
                "matched_line(å¼·èª¿)": highlighted,
                "excerpt": excerpt,
                "åˆ¤å®š": "ã‚¿ã‚¤ãƒˆãƒ«",
                "rule(ç†ç”±)": "ãã®ä»–â†’ã‚¿ã‚¤ãƒˆãƒ«",
            })
    return captions, refs


# =========================
# å…¨ãƒšãƒ¼ã‚¸èµ°æŸ»ï¼ˆé ãƒ©ãƒ™ãƒ«ï¼‹å›³è¡¨è¦‹å‡ºã—ï¼‰
# =========================
page_labels: List[str] = []
per_page_rows: List[Dict[str, Any]] = []

for i, ptxt in enumerate(pages_text, start=1):
    label, matched = extract_single_page_label(ptxt)
    page_labels.append(label)
    per_page_rows.append({
        "pdf_page": i,
        "page_label": label or "-",
        "matched_line": matched or "-",
        "has_label": label is not None,
    })

df_per_page_labels = pd.DataFrame(per_page_rows)

caption_rows: List[Dict[str, Any]] = []
for i, ptxt in enumerate(pages_text, start=1):
    page_label = page_labels[i - 1] if i - 1 < len(page_labels) and page_labels[i - 1] else "-"
    captions, _ = judge_hits_in_page(ptxt, ctx=ctx_chars)
    for h in captions:
        caption_rows.append({"pdf_page": i, "page_label": page_label, **h})

df_captions = pd.DataFrame(caption_rows)

# =========================
# è¡¨ç¤º
# =========================
st.subheader("ğŸ“‘ å„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ï¼ˆ1é =é«˜ã€…1ï¼‰")
st.dataframe(df_per_page_labels, use_container_width=True)

st.subheader("ğŸ–¼ï¸ å›³/è¡¨/å›³è¡¨ è¦‹å‡ºã—ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰ä¸€è¦§")
if df_captions.empty:
    st.info("å›³è¡¨ã®è¦‹å‡ºã—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã‚„ PDF ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
else:
    # å…¨ä»¶ä¸€è¦§
    st.dataframe(df_captions, use_container_width=True)

    # è¡¨ãƒ»å›³ã‚’åˆ†ã‘ãŸä¸€è¦§ã‚’ä¸‹ã«è¡¨ç¤º
    df_tables = df_captions[df_captions["å›³è¡¨ç¨®é¡"] == "è¡¨"].copy()
    df_figs   = df_captions[df_captions["å›³è¡¨ç¨®é¡"] != "è¡¨"].copy()  # ã€Œå›³ã€ã€Œå›³è¡¨ã€ãªã©

    st.markdown("#### ğŸ“Š è¡¨ã®è¦‹å‡ºã—ä¸€è¦§ï¼ˆå›³è¡¨ç¨®é¡ = è¡¨ï¼‰")
    if df_tables.empty:
        st.info("è¡¨ã®è¦‹å‡ºã—ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.dataframe(df_tables, use_container_width=True)

    st.markdown("#### ğŸ–¼ï¸ å›³ã®è¦‹å‡ºã—ä¸€è¦§ï¼ˆå›³ãƒ»å›³è¡¨ï¼‰")
    if df_figs.empty:
        st.info("å›³ï¼ˆå›³ãƒ»å›³è¡¨ï¼‰ã®è¦‹å‡ºã—ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.dataframe(df_figs, use_container_width=True)

# =========================
# Excel / CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# =========================
from io import BytesIO

with st.sidebar:
    st.markdown("### ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

    # --- CSVï¼ˆãŠã¾ã‘ï¼‰ ---
    if not df_captions.empty:
        buf_csv = io.StringIO()
        df_captions.to_csv(buf_csv, index=False)
        st.download_button(
            "ğŸ“„ å›³è¡¨è¦‹å‡ºã—ï¼ˆCSVï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=buf_csv.getvalue().encode("utf-8-sig"),
            file_name="figure_table_captions.csv",
            mime="text/csv",
            use_container_width=True,
        )

    # --- Excel (xlsx) ---
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        # ã‚·ãƒ¼ãƒˆ1: é ãƒ©ãƒ™ãƒ«
        if not df_per_page_labels.empty:
            df_page_x = df_per_page_labels.copy()
            if "page_label" in df_page_x.columns:
                df_page_x["page_label"] = df_page_x["page_label"].map(protect_for_excel_xlsx)
            df_page_x.to_excel(writer, sheet_name="é ãƒ©ãƒ™ãƒ«ä¸€è¦§", index=False)

        # ã‚·ãƒ¼ãƒˆ2: å›³è¡¨è¦‹å‡ºã—ï¼ˆå…¨ä»¶ï¼‰
        if not df_captions.empty:
            df_cap_x = df_captions.copy()
            if "page_label" in df_cap_x.columns:
                df_cap_x["page_label"] = df_cap_x["page_label"].map(protect_for_excel_xlsx)
            df_cap_x.to_excel(writer, sheet_name="å›³è¡¨è¦‹å‡ºã—ä¸€è¦§", index=False)

        # ã‚·ãƒ¼ãƒˆ3: è¡¨ã®ã¿
        if not df_captions.empty:
            df_tables_x = df_captions[df_captions["å›³è¡¨ç¨®é¡"] == "è¡¨"].copy()
            if not df_tables_x.empty:
                if "page_label" in df_tables_x.columns:
                    df_tables_x["page_label"] = df_tables_x["page_label"].map(protect_for_excel_xlsx)
                df_tables_x.to_excel(writer, sheet_name="è¡¨ã®ã¿", index=False)

        # ã‚·ãƒ¼ãƒˆ4: å›³ãƒ»å›³è¡¨ã®ã¿
        if not df_captions.empty:
            df_figs_x = df_captions[df_captions["å›³è¡¨ç¨®é¡"] != "è¡¨"].copy()
            if not df_figs_x.empty:
                if "page_label" in df_figs_x.columns:
                    df_figs_x["page_label"] = df_figs_x["page_label"].map(protect_for_excel_xlsx)
                df_figs_x.to_excel(writer, sheet_name="å›³ãƒ»å›³è¡¨ã®ã¿", index=False)

    base = uploaded.name.rsplit(".", 1)[0]
    xlsx_filename = f"å›³è¡¨è¦‹å‡ºã—æŠ½å‡º_{base}.xlsx"

    st.download_button(
        "ğŸ“˜ å›³è¡¨è¦‹å‡ºã—ä¸€è¦§ï¼ˆxlsxï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=output.getvalue(),
        file_name=xlsx_filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
    )

# =========================
# ãƒ‡ãƒãƒƒã‚°
# =========================
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug æƒ…å ±")
    st.code(f"EXTRACT_RE = {EXTRACT_RE.pattern}")
    st.caption("ãƒãƒƒãƒã‚’å«ã‚€1è¡ŒæŠ½å‡ºï¼‹âŸªå¼·èª¿âŸ«ï¼‹excerptä»˜ãã€‚")
    st.write("df_per_page_labels.shape:", df_per_page_labels.shape)
    st.write("df_captions.shape:", df_captions.shape)
