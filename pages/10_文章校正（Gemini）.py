# pages/10_æ–‡ç« æ ¡æ­£ï¼ˆGeminiï¼‰.py â€” è§£æï¼ˆæ ¡æ­£æ–¹é‡ï¼šãƒšãƒ¼ã‚¸/è¡Œ/ç†ç”±ï¼‰ã‚ªãƒ³ãƒªãƒ¼æ¥µç°¡ç‰ˆ
# ãƒ»åŸæ–‡ã¯ã€Œ1è¡Œ=1è¡Œã€ã‚’å³å¯†ä¿æŒã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ï¼ˆCJKæŠ˜è¿”ã—/é•·èªZWSPï¼‰
# ãƒ»æ ¡æ­£æ–¹é‡ã¯Markdownè¡¨ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦PDF/Wordä¸Šã®è¡¨ã«æ•´å½¢
# ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å½¢å¼ã¯ PDF ã¾ãŸã¯ Word ã®ã©ã¡ã‚‰ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ PDFï¼‰
# ãƒ»OpenAI / Gemini ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§åˆ‡æ›¿å¯èƒ½ï¼ˆGeminiã¯GEMINI_API_KEYå¿…é ˆï¼‰
# ãƒ»APIä½¿ç”¨é‡ï¼ˆtokensï¼‰ã¨æ¦‚ç®—ã‚³ã‚¹ãƒˆï¼ˆUSD/JPYï¼‰ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤ºï¼†ãƒ¬ãƒãƒ¼ãƒˆã«åŸ‹ã‚è¾¼ã¿

from __future__ import annotations
from typing import List, Tuple, Dict
from pathlib import Path
import sys
import io
import base64
import datetime as _dt

import streamlit as st
from openai import OpenAI

# ===== å…±æœ‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆcommon_libï¼‰ã‚’ãƒ‘ã‚¹ã«è¿½åŠ  =====
PROJECTS_ROOT = Path(__file__).resolve().parents[3]  # or 3 for pages
if str(PROJECTS_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECTS_ROOT))

# === lib ã®åˆ©ç”¨ï¼ˆèª­è¾¼ / è²¼ã‚Šä»˜ã‘æ•´å½¢ï¼‰ â€»OCRãªã— ===
from lib.text_loaders import (
    load_text_generic, extract_pdf_text, load_text_from_paste
)

from lib.proofreading.prompts import (
    MODE_DEFS,
    COMMON_PROMPT,
    get_analyze_instruction,
    build_system_prompt,
)

from lib.proofreading.explanation import render_proof_policy_logic_expander

# === ä¾¡æ ¼ãƒ»ç‚ºæ›¿ãƒ»æ¦‚ç®—ï¼ˆconfigï¼‰===
from config.config import (
    DEFAULT_USDJPY,
    estimate_tokens_from_text,
    get_usdjpy,
    estimate_cost_usd,
    usd_to_jpy,
    format_cost_lines,
)

# ------------------------------------------------------------
# UIå®šæ•°
# ------------------------------------------------------------
st.set_page_config(page_title="Text Studio / è§£æï¼ˆæ ¡æ­£æ–¹é‡ï¼‰", page_icon="ğŸ“", layout="wide")

DEFAULT_MODEL = "gpt-5-mini"
DEFAULT_MODE = "é€šå¸¸æ ¡æ­£"
LINES_PER_PAGE = 40  # 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®è¡¨ç¤ºè¡Œæ•°

# ---- Gemini Keyï¼ˆä»»æ„ï¼‰----
GEMINI_API_KEY = None
try:
    if "GEMINI_API_KEY" in st.secrets and str(st.secrets["GEMINI_API_KEY"]).strip():
        GEMINI_API_KEY = str(st.secrets["GEMINI_API_KEY"]).strip()
except Exception:
    GEMINI_API_KEY = None

GEMINI_ENABLED = bool(GEMINI_API_KEY)

# ---- ãƒ¢ãƒ‡ãƒ«å€™è£œï¼ˆGeminiã‚‚è¿½åŠ ï¼‰----
MODEL_OPTIONS = [
    "gpt-5-mini",
    "gpt-5-nano",
    "gemini-2.0-flash",
]

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
st.session_state.setdefault("chat_model", DEFAULT_MODEL)
st.session_state.setdefault("proof_mode", DEFAULT_MODE)
st.session_state.setdefault("chat_model_last_valid", st.session_state["chat_model"])
st.session_state.setdefault("chat_model_picker", st.session_state["chat_model"])
st.session_state.setdefault("gemini_disabled_notice", False)

# ------------------------------------------------------------
# è¡¨ç¤ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------------------------------------
def display_pdf_bytes(data: bytes, height: int = 600):
    """Streamlit PDFè¡¨ç¤ºï¼ˆstreamlit[pdf] ãŒã‚ã‚Œã° st.pdfï¼‰ã€‚ãªã‘ã‚Œã° iframe åŸ‹ã‚è¾¼ã¿ã€‚"""
    try:
        st.pdf(data, height=height)  # Streamlit 1.31+ / streamlit[pdf]
    except Exception:
        b64 = base64.b64encode(data).decode()
        st.markdown(
            f'<iframe src="data:application/pdf;base64,{b64}" width="100%" height="{height}px"></iframe>',
            unsafe_allow_html=True
        )

def to_numbered_lines(raw: str) -> List[str]:
    return raw.replace("\r\n", "\n").replace("\r", "\n").split("\n")

def render_preview_with_numbers(lines: List[str], lines_per_page: int) -> str:
    _ = lines_per_page  # äº’æ›ã®ãŸã‚å¼•æ•°ã¯æ®‹ã™
    return "\n".join(f"[{i+1:04d}] {t}" for i, t in enumerate(lines))

# ------------------------------------------------------------
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
# ------------------------------------------------------------
def openai_client() -> OpenAI:
    return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ------------------------------------------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¢ãƒ‡ãƒ«é¸æŠã®åˆ¶å¾¡ï¼ˆGeminiæœªè¨­å®šãªã‚‰é¸æŠä¸å¯ï¼‰
# ------------------------------------------------------------
def _model_label(x: str) -> str:
    if x.startswith("gemini") and not GEMINI_ENABLED:
        return f"{x}ï¼ˆGEMINI_API_KEY æœªè¨­å®šï¼‰"
    return x

def _on_change_chat_model():
    picked = st.session_state.get("chat_model_picker", DEFAULT_MODEL)
    if picked.startswith("gemini") and not GEMINI_ENABLED:
        st.session_state["gemini_disabled_notice"] = True
        st.session_state["chat_model_picker"] = st.session_state.get("chat_model_last_valid", DEFAULT_MODEL)
    else:
        st.session_state["chat_model_last_valid"] = picked
        st.session_state["gemini_disabled_notice"] = False
        st.session_state["chat_model"] = picked

# ------------------------------------------------------------
# è§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤ºï¼ˆexpanderï¼‰
# ------------------------------------------------------------
def render_policy_preview(*, mode: str) -> str:
    analyze_base = get_analyze_instruction(mode)

    with st.expander("ğŸ§­ è§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰", expanded=False):
        tab3, tab1, tab2 = st.tabs([
            "âœï¸ è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            "ğŸ§­ System",
            "ğŸ“‹ å…±é€šæ–¹é‡",
        ])

        with tab1:
            st.markdown("#### ğŸ§­ è§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè§£æãƒ¢ãƒ¼ãƒ‰ï¼‰")
            st.code(analyze_base, language="markdown")

        with tab2:
            st.markdown("#### ğŸ“‹ å…±é€šæ–¹é‡ï¼ˆæ¯å›ä»˜ä¸ï¼‰")
            st.code(COMMON_PROMPT.strip(), language="markdown")

        with tab3:
            st.markdown("#### âœï¸ è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä»»æ„ï¼‰")
            extra = st.text_area(
                "è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›",
                key="extra_user_prompt",
                placeholder="ä¾‹ï¼‰å¤–æ¥èªã¯ã‚«ã‚¿ã‚«ãƒŠå„ªå…ˆã€‚è£½å“åã‚„å›ºæœ‰åè©ã¯åŸæ–‡ã©ãŠã‚Šã«ä¿æŒã€‚",
                height=100,
            ) or ""
            return extra

# ------------------------------------------------------------
# Markdownè¡¨ â†’ é…åˆ—ï¼ˆé /è¡Œ/é‡è¦åº¦/åŸæ–‡/ä¿®æ­£æ¡ˆ/ç†ç”±ï¼‰
# ------------------------------------------------------------
def _parse_plan_md_tables(md: str) -> List[Dict[str, str]]:
    items: List[Dict[str, str]] = []
    if not md:
        return items

    to_jp = {
        "page": "é ", "line": "è¡Œ", "issue": "é‡è¦åº¦",
        "original": "åŸæ–‡", "suggestion": "ä¿®æ­£æ¡ˆ", "reason": "ç†ç”±",
        "é ": "é ", "ãƒšãƒ¼ã‚¸": "é ", "è¡Œ": "è¡Œ",
        "é‡è¦åº¦": "é‡è¦åº¦", "å•é¡Œç‚¹": "é‡è¦åº¦", "åŸæ–‡": "åŸæ–‡",
        "ä¿®æ­£æ¡ˆ": "ä¿®æ­£æ¡ˆ", "ææ¡ˆ": "ä¿®æ­£æ¡ˆ", "ç†ç”±": "ç†ç”±", "æ ¹æ‹ ": "ç†ç”±",
    }
    expected = ["é ", "è¡Œ", "é‡è¦åº¦", "åŸæ–‡", "ä¿®æ­£æ¡ˆ", "ç†ç”±"]

    def _norm_head_cell(s: str) -> str:
        key = s.strip().lower()
        return to_jp.get(key, to_jp.get(s.strip(), s.strip()))

    def _row_to_dict(ln: str, cols_jp: List[str]) -> Dict[str, str] | None:
        cells = [c.strip() for c in ln.strip("|").split("|")]
        if len(cells) < 3:
            return None
        row = dict(zip(cols_jp, cells[:len(cols_jp)]))
        for k in expected:
            row.setdefault(k, "")
        return row

    lines = [ln for ln in (l.strip() for l in md.splitlines()) if ln]
    header_seen = False
    cols_jp: List[str] = []

    for ln in lines:
        if not (ln.startswith("|") and "|" in ln):
            continue

        raw_cells = [c.strip() for c in ln.strip("|").split("|")]

        def _is_md_separator(cell: str) -> bool:
            s = cell.strip().replace("-", "").replace(":", "")
            return s == ""

        if all(_is_md_separator(c) for c in raw_cells):
            continue

        if not header_seen:
            norm = [_norm_head_cell(c) for c in raw_cells]
            if len(set(norm) & set(expected)) >= 3:
                cols_jp = [c if c in expected else "" for c in norm]
                if len(cols_jp) < 6:
                    cols_jp += [""] * (6 - len(cols_jp))
                cols_jp = [cols_jp[i] or expected[i] for i in range(6)]
                header_seen = True
                continue

        if header_seen and cols_jp:
            row = _row_to_dict(ln, cols_jp)
            if row:
                items.append(row)

    return items

# ------------------------------------------------------------
# è§£æçµæœã® Word / PDF ç”Ÿæˆ
# ------------------------------------------------------------
def build_policy_docx_bytes(
    *,
    original_numbered_preview: str,
    plan_md: str,
    model: str,
    mode: str,
    extra_prompt: str,
    src_name: str,
    usage_summary: Dict[str, int] | None = None,
    usd_jpy: float | None = None,
) -> Tuple[bytes, str]:
    """Wordï¼ˆ.docxï¼‰ã§ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ï¼šåŸæ–‡=ç­‰å¹…é¢¨/è‡ªå‹•æŠ˜è¿”ã—ã€æ ¡æ­£æ–¹é‡=Markdownæ–‡å­—åˆ—ãã®ã¾ã¾"""
    try:
        from docx import Document
        from docx.shared import Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
    except Exception:
        # TXTãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        add_lines = []
        if usage_summary and usd_jpy is not None:
            in_t = int(usage_summary.get("input_tokens", 0))
            out_t = int(usage_summary.get("output_tokens", 0))
            add_lines += [""] + format_cost_lines(model=model, in_t=in_t, out_t=out_t, usd_jpy=usd_jpy)

        data = "\n".join([
            "=== æ ¡æ­£æ–¹é‡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆTXTãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ===",
            f"ç”Ÿæˆæ—¥æ™‚: {_dt.datetime.now():%Y-%m-%d %H:%M:%S}",
            f"ãƒ¢ãƒ‡ãƒ«: {model}",
            f"ãƒ¢ãƒ¼ãƒ‰: {mode}",
            f"è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {extra_prompt.strip()}" if extra_prompt.strip() else "",
            f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {src_name or '-'}",
            *add_lines,
            "\n--- åŸæ–‡ï¼ˆè¡Œç•ªå·ã¤ãï¼‰ ---\n",
            original_numbered_preview or "(ç©º)",
            "\n--- æ ¡æ­£æ–¹é‡ï¼ˆMarkdownï¼‰ ---\n",
            plan_md or "(ãªã—)",
        ]).encode("utf-8")
        return data, ".txt"

    doc = Document()
    h = doc.add_heading("æ ¡æ­£æ–¹é‡ãƒ¬ãƒãƒ¼ãƒˆ", 0)
    try:
        h.alignment = WD_ALIGN_PARAGRAPH.CENTER
    except Exception:
        pass

    p = doc.add_paragraph()
    p.add_run("ç”Ÿæˆæ—¥æ™‚: ").bold = True
    p.add_run(_dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    p.add_run("\nãƒ¢ãƒ‡ãƒ«: ").bold = True
    p.add_run(model)
    p.add_run("\nãƒ¢ãƒ¼ãƒ‰: ").bold = True
    p.add_run(mode)
    if extra_prompt.strip():
        p.add_run("\nè¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ").bold = True
        p.add_run(extra_prompt.strip())
    p.add_run("\nå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: ").bold = True
    p.add_run(src_name or "-")

    # è¿½åŠ ï¼šã‚³ã‚¹ãƒˆ
    if usage_summary and (usd_jpy is not None):
        in_t = int(usage_summary.get("input_tokens", 0))
        out_t = int(usage_summary.get("output_tokens", 0))
        for ln in format_cost_lines(model=model, in_t=in_t, out_t=out_t, usd_jpy=float(usd_jpy)):
            p.add_run("\n" + ln)

    doc.add_heading("åŸæ–‡ï¼ˆè¡Œç•ªå·ã¤ãï¼‰", level=1)
    para = doc.add_paragraph()
    r = para.add_run(original_numbered_preview if original_numbered_preview else "(ç©º)")
    try:
        r.font.name = "Courier New"
        r.font.size = Pt(10)
    except Exception:
        pass

    doc.add_heading("æ ¡æ­£æ–¹é‡ï¼ˆMarkdownï¼‰", level=1)
    para2 = doc.add_paragraph()
    r2 = para2.add_run(plan_md if plan_md else "(ãªã—)")
    try:
        r2.font.name = "Courier New"
        r2.font.size = Pt(10)
    except Exception:
        pass

    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue(), ".docx"


def build_policy_pdf_bytes(
    *,
    original_numbered_preview: str,
    plan_md: str,
    model: str,
    mode: str,
    extra_prompt: str,
    src_name: str,
    usage_summary: Dict[str, int] | None = None,
    usd_jpy: float | None = None,
) -> bytes:
    """æ•´å½¢PDFï¼šåŸæ–‡ã¯1è¡Œ=1è¡Œã®è¡Œãƒ†ãƒ¼ãƒ–ãƒ«ã€æ ¡æ­£æ–¹é‡ã¯Markdownè¡¨ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦è¡¨æç”»"""
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.enums import TA_LEFT, TA_CENTER
        from reportlab.lib import colors
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.cidfonts import UnicodeCIDFont
        from reportlab.lib.units import mm
        import re
    except Exception:
        return b""

    # æ—¥æœ¬èªCIDãƒ•ã‚©ãƒ³ãƒˆ
    font_name = None
    for fname in ("HeiseiMin-W3", "HeiseiKakuGo-W5"):
        try:
            pdfmetrics.registerFont(UnicodeCIDFont(fname))
            font_name = fname
            break
        except Exception:
            continue
    if not font_name:
        return b""

    buf = io.BytesIO()
    pagesize = A4
    margin = 18 * mm
    doc = SimpleDocTemplate(
        buf, pagesize=pagesize,
        leftMargin=margin, rightMargin=margin,
        topMargin=20 * mm, bottomMargin=18 * mm,
        title="æ ¡æ­£æ–¹é‡ãƒ¬ãƒãƒ¼ãƒˆ",
    )

    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name="TitleJP", fontName=font_name, fontSize=18, leading=22, alignment=TA_CENTER, spaceAfter=8))
    styles.add(ParagraphStyle(name="Meta", fontName=font_name, fontSize=10, leading=13, alignment=TA_LEFT, spaceAfter=6))
    styles.add(ParagraphStyle(name="H1", fontName=font_name, fontSize=13, leading=16, spaceBefore=6, spaceAfter=6))
    styles.add(ParagraphStyle(name="Body", fontName=font_name, fontSize=10, leading=14))
    styles.add(ParagraphStyle(name="MonoCJK", fontName=font_name, fontSize=9.5, leading=13, wordWrap="CJK"))

    text_width = pagesize[0] - doc.leftMargin - doc.rightMargin

    def _page_number(canvas, doc_):
        canvas.setFont(font_name, 9)
        canvas.drawRightString(pagesize[0] - doc_.rightMargin, 12 * mm, f"{doc_.page}")

    # åŸæ–‡ï¼ˆ1è¡Œ=1è¡Œã®ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã€CJKæŠ˜è¿”ã—ï¼‹è‹±æ•°å­—é•·èªã«ZWSPï¼‰
    ZWSP = "&#8203;"
    LONG_TOKEN = re.compile(r"([A-Za-z0-9_/#%~\-\.\?\=&]{30,})")

    def _soften(s: str) -> str:
        return LONG_TOKEN.sub(
            lambda m: ZWSP.join(m.group(1)[i:i+30] for i in range(0, len(m.group(1)), 30)),
            s
        )

    def _make_original_table(text: str) -> Table:
        rows = []
        MAX_CHARS_PER_ROW = 80

        for raw in (text or "").splitlines() or ["(ç©º)"]:
            s = raw.replace("\t", "    ")

            if len(s) > MAX_CHARS_PER_ROW:
                segments = [s[i:i+MAX_CHARS_PER_ROW] for i in range(0, len(s), MAX_CHARS_PER_ROW)]
            else:
                segments = [s]

            for seg in segments:
                seg = _soften(seg).replace("  ", "&nbsp;&nbsp;")
                p = Paragraph(seg if seg else "&nbsp;", styles["MonoCJK"])
                rows.append([p])

        col_w = max(10, text_width - 2)
        t = Table(rows, colWidths=[col_w], splitByRow=1)
        t.setStyle(TableStyle([
            ("BOX", (0, 0), (-1, -1), 0.4, colors.grey),
            ("BACKGROUND", (0, 0), (-1, -1), colors.whitesmoke),
            ("LEFTPADDING", (0, 0), (-1, -1), 4),
            ("RIGHTPADDING", (0, 0), (-1, -1), 4),
            ("TOPPADDING", (0, 0), (-1, -1), 4),
            ("BOTTOMPADDING", (0, 0), (-1, -1), 4),
            ("VALIGN", (0, 0), (-1, -1), "TOP"),
        ]))
        return t

    # æ ¡æ­£æ–¹é‡ãƒ†ãƒ¼ãƒ–ãƒ«
    items = _parse_plan_md_tables(plan_md)
    headers = ["è¡Œ", "é‡è¦åº¦", "åŸæ–‡", "ä¿®æ­£æ¡ˆ", "ç†ç”±"]
    table_data = [headers] + [[
        it.get("è¡Œ", ""), it.get("é‡è¦åº¦", ""),
        it.get("åŸæ–‡", ""), it.get("ä¿®æ­£æ¡ˆ", ""), it.get("ç†ç”±", "")
    ] for it in items]

    col_w = [14 * mm, 18 * mm]
    remain = text_width - sum(col_w)
    col_w += [remain * 0.30, remain * 0.30, remain * 0.40]

    def _p(s: str) -> Paragraph:
        s = (s or "")
        s = s.replace("<br>", "<br/>").replace("<br />", "<br/>")
        s = s.replace("\n", "<br/>")
        return Paragraph(s, styles["Body"])

    table_para = [table_data[0]] + [[_p(x) for x in r] for r in table_data[1:]]
    tbl = Table(table_para, colWidths=col_w, repeatRows=1)

    zebra = colors.Color(0.95, 0.95, 0.98)
    header_bg = colors.Color(0.88, 0.90, 0.95)
    grid = colors.Color(0.75, 0.78, 0.85)

    st_cmds = [
        ("BACKGROUND", (0, 0), (-1, 0), header_bg),
        ("ALIGN", (0, 0), (1, -1), "CENTER"),
        ("VALIGN", (0, 0), (-1, -1), "TOP"),
        ("FONTNAME", (0, 0), (-1, -1), font_name),
        ("FONTSIZE", (0, 0), (-1, -1), 9.5),
        ("LEFTPADDING", (0, 0), (-1, -1), 5),
        ("RIGHTPADDING", (0, 0), (-1, -1), 5),
        ("TOPPADDING", (0, 0), (-1, -1), 4),
        ("BOTTOMPADDING", (0, 0), (-1, -1), 4),
        ("GRID", (0, 0), (-1, -1), 0.3, grid),
    ]
    for i in range(1, len(table_para)):
        if i % 2 == 1:
            st_cmds.append(("BACKGROUND", (0, i), (-1, i), zebra))
    tbl.setStyle(TableStyle(st_cmds))

    story = []
    story.append(Paragraph("æ ¡æ­£æ–¹é‡ãƒ¬ãƒãƒ¼ãƒˆ", styles["TitleJP"]))

    meta_lines = [
        f"ç”Ÿæˆæ—¥æ™‚ï¼š{_dt.datetime.now():%Y-%m-%d %H:%M:%S}",
        f"ãƒ¢ãƒ‡ãƒ«ï¼š{model}",
        f"ãƒ¢ãƒ¼ãƒ‰ï¼š{mode}",
        f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼š{src_name or '-'}",
    ]
    if (extra_prompt or "").strip():
        meta_lines.insert(3, f"è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼š{extra_prompt.strip()}")

    # è¿½åŠ ï¼šã‚³ã‚¹ãƒˆ
    if usage_summary and (usd_jpy is not None):
        in_t = int(usage_summary.get("input_tokens", 0))
        out_t = int(usage_summary.get("output_tokens", 0))
        for ln in format_cost_lines(model=model, in_t=in_t, out_t=out_t, usd_jpy=float(usd_jpy)):
            meta_lines.append(ln)

    for ln in meta_lines:
        story.append(Paragraph(ln, styles["Meta"]))

    story.append(Paragraph("åŸæ–‡ï¼ˆè¡Œç•ªå·ã¤ãï¼‰", styles["H1"]))
    story.append(_make_original_table(original_numbered_preview or "(ç©º)"))
    story.append(Spacer(1, 6 * mm))

    story.append(Paragraph("æ ¡æ­£æ–¹é‡ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰", styles["H1"]))
    story.append(tbl)

    doc.build(story, onFirstPage=_page_number, onLaterPages=_page_number)
    pdf_bytes = buf.getvalue()
    buf.close()
    return pdf_bytes

# ------------------------------------------------------------
# è§£æï¼šOpenAI / Gemini åˆ†å²ï¼ˆusage ã‚‚è¿”ã™ï¼‰
# ------------------------------------------------------------
def analyze_issues(
    model: str,
    lines: List[str],
    lines_per_page: int,
    mode: str,
    extra: str
) -> tuple[str, dict]:
    """
    ãƒšãƒ¼ã‚¸å˜ä½ã§ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ Markdown è¡¨ã‚’å–å¾—ã—ã€
    ã¾ã¨ã‚ã¦ 1 å€‹ã®å¤§ããªè¡¨ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ 1 å›ã ã‘ï¼‰ã«çµ„ã¿ç›´ã—ã¦è¿”ã™ã€‚
    ã•ã‚‰ã« token usageï¼ˆinput/output/totalï¼‰ã‚‚è¿”ã™ã€‚
    """
    md_tables: List[str] = []
    total_pages = (len(lines) + lines_per_page - 1) // lines_per_page

    total_in_tokens = 0
    total_out_tokens = 0
    total_tokens = 0

    sys_inst_template = build_system_prompt(mode=mode, extra=extra)
    use_gemini = model.startswith("gemini")

    # Gemini åˆæœŸåŒ–ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰
    # if use_gemini:
    #     if not GEMINI_ENABLED:
    #         raise RuntimeError("GEMINI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ Gemini ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    #     try:
    #         import google as genai
    #     except Exception as e:
    #         raise RuntimeError("Gemini ã‚’ä½¿ã†ã«ã¯ `pip install google-generativeai` ãŒå¿…è¦ã§ã™ã€‚") from e
    #     genai.configure(api_key=GEMINI_API_KEY)
    #     gem = genai.GenerativeModel(model)

    # Gemini åˆæœŸåŒ–ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰: google-genai
    if use_gemini:
        if not GEMINI_ENABLED:
            raise RuntimeError("GEMINI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ Gemini ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        try:
            from google import genai
        except Exception as e:
            raise RuntimeError("Gemini ã‚’ä½¿ã†ã«ã¯ `pip install google-genai` ãŒå¿…è¦ã§ã™ã€‚") from e

        gem_client = genai.Client(api_key=GEMINI_API_KEY)
    else:
        client = openai_client()


    # --- ãƒšãƒ¼ã‚¸ã”ã¨ã«è§£æ ---
    for pg in range(total_pages):
        start = pg * lines_per_page
        end = min((pg + 1) * lines_per_page, len(lines))
        page_chunk = [f"[{(i + 1):04d}] {lines[i]}" for i in range(start, end)]
        page_text = "\n".join(page_chunk)

        if use_gemini:
            prompt = (
                f"{sys_inst_template}\n\n"
                f"æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã“ã®ãƒšãƒ¼ã‚¸ã®ã¿ï¼‰ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n---\n{page_text}\n\n"
                "å‡ºåŠ›ã¯å¿…ãš Markdown ã®è¡¨ï¼ˆ| è¡Œ | é‡è¦åº¦ | åŸæ–‡ | ä¿®æ­£æ¡ˆ | ç†ç”± |ï¼‰ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
            )

            resp = gem_client.models.generate_content(
                model=model,
                contents=prompt,
            )

            # ãƒ†ã‚­ã‚¹ãƒˆå–ã‚Šå‡ºã—ï¼ˆgoogle-genaiï¼‰
            out_text = (getattr(resp, "text", "") or "").strip()
            md_tables.append(out_text)

            # usageï¼ˆgoogle-genai ã¯ resp.usage_metadata ã‚’æŒã¤ã“ã¨ãŒå¤šã„ï¼‰
            u = getattr(resp, "usage_metadata", None)
            if u is not None:
                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã¯ç’°å¢ƒå·®ãŒã‚ã‚‹ã®ã§ get ã§å®‰å…¨ã«æ‹¾ã†
                # ï¼ˆprompt_token_count / candidates_token_count / total_token_count ãŒå…¸å‹ï¼‰
                in_t = int(getattr(u, "prompt_token_count", 0) or 0)
                out_t = int(getattr(u, "candidates_token_count", 0) or 0)
                tot_t = int(getattr(u, "total_token_count", 0) or (in_t + out_t))
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ¦‚ç®—ï¼‰
                in_t = estimate_tokens_from_text(prompt)
                out_t = estimate_tokens_from_text(out_text)
                tot_t = in_t + out_t

            total_in_tokens += in_t
            total_out_tokens += out_t
            total_tokens += tot_t




        else:
            resp = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": sys_inst_template},
                    {"role": "user", "content": f"æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã“ã®ãƒšãƒ¼ã‚¸ã®ã¿ï¼‰ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n---\n{page_text}"},
                ],
            )
            content = resp.choices[0].message.content.strip()
            md_tables.append(content)

            usage = getattr(resp, "usage", None)
            if usage is not None:
                in_t = int(getattr(usage, "prompt_tokens", 0) or 0)
                out_t = int(getattr(usage, "completion_tokens", 0) or 0)
                tot_t = int(getattr(usage, "total_tokens", 0) or (in_t + out_t))
            else:
                # å¿µã®ãŸã‚ï¼ˆæ¦‚ç®—ï¼‰
                in_t = estimate_tokens_from_text(sys_inst_template + "\n" + page_text)
                out_t = estimate_tokens_from_text(content)
                tot_t = in_t + out_t

            total_in_tokens += in_t
            total_out_tokens += out_t
            total_tokens += tot_t

    # --- ã¾ã¨ã‚ã¦ãƒ‘ãƒ¼ã‚¹ ---
    raw_md = "\n\n".join(md_tables)
    items = _parse_plan_md_tables(raw_md)

    # ãƒ˜ãƒƒãƒ€ãƒ¼ãã£ãã‚Šè¡Œã‚’é™¤å¤–
    def _is_header_like(row: Dict[str, str]) -> bool:
        def norm(s: str) -> str:
            return (s or "").strip().lower()
        return (
            norm(row.get("é ", "")) in {"é ", "page", "ãƒšãƒ¼ã‚¸"} and
            norm(row.get("è¡Œ", "")) in {"è¡Œ", "line"} and
            norm(row.get("é‡è¦åº¦", "")) in {"é‡è¦åº¦", "issue", "å•é¡Œç‚¹"} and
            norm(row.get("åŸæ–‡", "")) in {"åŸæ–‡", "original"} and
            norm(row.get("ä¿®æ­£æ¡ˆ", "")) in {"ä¿®æ­£æ¡ˆ", "suggestion", "ææ¡ˆ"} and
            norm(row.get("ç†ç”±", "")) in {"ç†ç”±", "reason", "æ ¹æ‹ "}
        )
    items = [row for row in items if not _is_header_like(row)]

    # Markdownè¡¨ å†æ§‹ç¯‰
    def esc_cell(s: str) -> str:
        s = (s or "").replace("|", r"\|")
        s = s.replace("\n", "<br/>")
        return s

    header = "| è¡Œ | é‡è¦åº¦ | åŸæ–‡ | ä¿®æ­£æ¡ˆ | ç†ç”± |"
    sep    = "| --- | --- | --- | --- | --- |"
    rows = [header, sep]
    for it in items:
        rows.append(
            "| {line} | {imp} | {orig} | {sugg} | {reason} |".format(
                line=esc_cell(it.get("è¡Œ", "")),
                imp=esc_cell(it.get("é‡è¦åº¦", "")),
                orig=esc_cell(it.get("åŸæ–‡", "")),
                sugg=esc_cell(it.get("ä¿®æ­£æ¡ˆ", "")),
                reason=esc_cell(it.get("ç†ç”±", "")),
            )
        )

    final_md = "\n".join(rows)
    usage_summary = {
        "input_tokens": int(total_in_tokens),
        "output_tokens": int(total_out_tokens),
        "total_tokens": int(total_tokens),
        "pages": int(total_pages),
    }
    return final_md, usage_summary

# ------------------------------------------------------------
# ç”»é¢ï¼ˆè§£æã®ã¿ï¼‰
# ------------------------------------------------------------
st.title("ğŸ“ æ–‡ç« ã®æ ¡æ­£ï¼ˆGeminiå¯¾å¿œç‰ˆï¼‰")
st.caption(
    "æ•°æ®µè½ç¨‹åº¦ã®æ–‡ç« ã‚’è²¼ã‚Šä»˜ã‘ã¦ï¼Œè§£æã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼è§£æã«ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼"
    "æ ¡æ­£ã«ã¯AIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã®ã§ï¼Œå€‹äººæƒ…å ±ã‚„æ©Ÿå¯†æ–‡æ›¸ã®å–ã‚Šæ‰±ã„ã«ã¯æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
)

st.write("""æœ¬æ–‡ã‚’å…¥åŠ›ã—ã¦ **â‘  è§£æ** ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€
/è¡Œ/ç†ç”±ã¤ãã®æ ¡æ­£æ–¹é‡ï¼ˆMarkdownè¡¨ï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
æ–‡ç« ã¯ï¼Œ **1,000è¡Œä»¥å†…** ã«åŒºåˆ‡ã£ã¦æ ¡æ­£ã‚’ã‹ã‘ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼é€šå¸¸æ ¡æ­£ï¼Œå³æ ¼æ ¡æ­£ï¼Œç°¡æ˜“æ ¡æ­£ã®ï¼“ç¨®é¡ãŒã‚ã‚Šã¾ã™ï¼
è§£æãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§æ ¡æ­£ã®ç¨‹åº¦ã‚’é¸æŠã§ãã¾ã™ï¼""")

st.write("""Wordã®å›³è¡¨ã‚’è²¼ã‚Šä»˜ã‘ãŸæ™‚ã¯ï¼Œè§£æãƒ¢ãƒ¼ãƒ‰ã§ **å›³è¡¨æ ¡æ­£** ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼""")

st.markdown(
    """
<div style='line-height:1.6'>
  <span style='color:red; font-size:18px; font-weight:bold;'>
    Wordãƒ•ã‚¡ã‚¤ãƒ«ã«æ ¡æ­£ã‚’ã‹ã‘ãŸã„
  </span>
  ã¨ãã¯ï¼Œã¾ãš <b>wordè§£æ</b> ã‚’è¡Œã„ï¼Œ <b>ä¸­é–“ãƒ†ã‚­ã‚¹ãƒˆ</b> ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼
  ãã®ä¸­é–“ãƒ†ã‚­ã‚¹ãƒˆã‚’ã“ã® <b>æ ¡æ­£</b> ã® <b>ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€ã‚¿ãƒ–</b> ã‚ˆã‚Šï¼Œ
  ï¼ˆé›²ã®ãƒãƒ¼ã‚¯ã®ä¸Šã«ï¼‰ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ï¼ã¾ãŸã¯ï¼Œ
  <b>ã€Œè²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆã€ã‚¿ãƒ–</b> ã«ãƒšãƒ¼ã‚¹ãƒˆã—ã¦ãã ã•ã„ï¼
  ãã®éš›ã« <b>è§£æãƒ¢ãƒ¼ãƒ‰</b> ã¯ 
  <span style='color:red; font-size:18px; font-weight:bold;'>è§£ææ–‡æ›¸æ ¡æ­£</span>
  ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼
  æ–‡ç« ã¯ï¼Œ<b>1,000è¡Œä»¥å†…</b> ã«ãªã‚‹ã‚ˆã†ã«åˆ†å‰²ã—ã¦æ ¡æ­£ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼
  <br>
  â€» å°†æ¥çš„ã«ã¯ï¼ŒWordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥æ ¡æ­£ã§ãã‚‹ã‚ˆã†ã«æ”¹å–„ã™ã‚‹äºˆå®šã§ã™ï¼
  <br><br>
</div>
    """,
    unsafe_allow_html=True
)

# ã“ã“ã§ã‚¿ãƒ–ä»˜ã expander ã‚’ã¾ã¨ã‚ã¦æç”»
render_proof_policy_logic_expander()

# ------------------------------------------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# ------------------------------------------------------------
with st.sidebar:
    st.header("è¨­å®š")

    st.radio(
        "ğŸ§  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
        MODEL_OPTIONS,
        key="chat_model_picker",
        format_func=_model_label,
        on_change=_on_change_chat_model,
    )

    if st.session_state.get("gemini_disabled_notice", False) and not GEMINI_ENABLED:
        st.warning("GEMINI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ Gemini ã¯é¸æŠã§ãã¾ã›ã‚“ã€‚ï¼ˆsecrets.toml ã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰")

    # å®Ÿéš›ã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºå®š
    st.session_state["chat_model"] = st.session_state.get("chat_model_picker", DEFAULT_MODEL)

    st.selectbox(
        "ğŸ›  è§£æãƒ¢ãƒ¼ãƒ‰",
        list(MODE_DEFS.keys()),
        key="proof_mode",
        help="\n\n".join([f"ãƒ»{k}: {v['desc']}" for k, v in MODE_DEFS.items()]),
    )

    lpp = st.number_input("ãƒšãƒ¼ã‚¸è¡Œæ•°ï¼ˆè¡¨ç¤ºç”¨ï¼‰", min_value=20, max_value=100, value=LINES_PER_PAGE, step=5)

    _DL_LABELS = {"pdf": "PDF (.pdf)", "word": "Word (.docx)"}
    dl_choice_key = st.radio(
        "ğŸ“¦ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å½¢å¼ï¼ˆè§£æãƒ¬ãƒãƒ¼ãƒˆï¼‰",
        options=list(_DL_LABELS.keys()),
        format_func=lambda k: _DL_LABELS[k],
        index=0,
        key="dl_format_radio",
    )

extra_prompt = render_policy_preview(mode=st.session_state["proof_mode"])
st.markdown("---")

# ------------------------------------------------------------
# å…¥åŠ›ï¼ˆãƒ•ã‚¡ã‚¤ãƒ« / è²¼ã‚Šä»˜ã‘ï¼‰
# ------------------------------------------------------------
tab_paste, tab_file = st.tabs(["ğŸ“ è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆ", "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰"])

src_text = ""
used_file_name = None

st.session_state.setdefault("pasted_text", "")

with tab_file:
    up = st.file_uploader(".docx / .txt / .pdf ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["docx", "txt", "pdf"])

    col_mode, col_btn = st.columns([1, 1])
    with col_mode:
        current_mode = st.session_state.get("proof_mode", DEFAULT_MODE)
        st.markdown(
            f"""
            <div style="
                padding:6px 10px;
                border-radius:6px;
                background-color:#ffe9c6;
                color:#8a4b0f;
                font-weight:bold;
                font-size:0.95rem;
                border:1px solid #f0b76a;
                white-space:nowrap;
                display:inline-block;
            ">
                ğŸ§­ è§£æãƒ¢ãƒ¼ãƒ‰ï¼š{current_mode}
            </div>
            """,
            unsafe_allow_html=True,
        )

    with col_btn:
        do_analyze_file = st.button(
            "â‘  è§£æï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ï¼‰",
            type="primary",
            use_container_width=True,
            disabled=not up,
            key="btn_analyze_file"
        )

    if up:
        used_file_name = up.name
        name = up.name.lower()
        if name.endswith(".pdf"):
            data = up.read()
            try:
                stats = extract_pdf_text(data)
            except RuntimeError as e:
                st.error(str(e))
                st.stop()

            st.subheader("ğŸ“„ PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            display_pdf_bytes(data, height=600)

            if int(stats.get("visible", 0)) < 20:
                st.warning("ã“ã®PDFã¯ç”»åƒPDFï¼ˆãƒ†ã‚­ã‚¹ãƒˆå±¤ãªã—ï¼‰ã¨åˆ¤å®šã—ã¾ã—ãŸã€‚OCRãƒ„ãƒ¼ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                st.stop()
            else:
                src_text = (stats.get("text") or "").strip()
        else:
            try:
                src_text = load_text_generic(up)
            except RuntimeError as e:
                st.error(str(e))
                st.stop()

with tab_paste:
    pasted = st.text_area(
        "ã“ã“ã«æœ¬æ–‡ã‚’è²¼ã‚Šä»˜ã‘",
        height=260,
        key="pasted_text",
        placeholder="ã“ã“ã«æœ¬æ–‡ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ï¼ˆæ”¹è¡Œã¯ä¿æŒã•ã‚Œã¾ã™ï¼‰ã€‚",
    )

    col_mode2, col_btn2 = st.columns([1, 1])
    with col_mode2:
        current_mode = st.session_state.get("proof_mode", DEFAULT_MODE)
        st.markdown(
            f"""
            <div style="
                padding:6px 10px;
                border-radius:6px;
                background-color:#ffe9c6;
                color:#8a4b0f;
                font-weight:bold;
                font-size:0.95rem;
                display:inline-block;
                border:1px solid #f0b76a;
                white-space:nowrap;
            ">
                ğŸ§­ è§£æãƒ¢ãƒ¼ãƒ‰ï¼š{current_mode}
            </div>
            """,
            unsafe_allow_html=True,
        )

    with col_btn2:
        do_analyze_paste = st.button(
            "â‘  è§£æï¼ˆè²¼ã‚Šä»˜ã‘ï¼‰",
            type="primary",
            use_container_width=True,
        )

    if do_analyze_paste:
        if not pasted.strip():
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")
            st.stop()

        src_text = load_text_from_paste(
            pasted,
            normalize=True,
            collapse_blanks=False,
            keep_blank_lines=1,
            trim_trailing=True,
        )
        used_file_name = "pasted_text.txt"

# ------------------------------------------------------------
# è§£æã®å®Ÿè¡Œ
# ------------------------------------------------------------
if src_text:
    lines = to_numbered_lines(src_text)

    st.subheader("ğŸ‘€ è¡Œç•ªå·ä»˜ããƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºï¼‰")
    st.caption(f"è¡¨ç¤ºä¸Šã®ãƒšãƒ¼ã‚¸è¡Œæ•°: {LINES_PER_PAGE} è¡Œ/ãƒšãƒ¼ã‚¸ï¼ˆæ“¬ä¼¼å‰²ã‚Šä»˜ã‘ï¼‰")
    st.text_area("åŸæ–‡ï¼ˆç•ªå·ä»˜ããƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰", value=render_preview_with_numbers(lines, LINES_PER_PAGE), height=260)

    want_analyze = (locals().get("do_analyze_file") or locals().get("do_analyze_paste"))
    if want_analyze:
        with st.spinner("è§£æä¸­ï¼ˆæ ¡æ­£æ–¹é‡ã‚’æŠ½å‡ºï¼‰â€¦"):
            plan_md, usage = analyze_issues(
                st.session_state["chat_model"],
                lines,
                LINES_PER_PAGE,
                mode=st.session_state["proof_mode"],
                extra=extra_prompt
            )

        st.success("è§£æãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸/è¡Œ/ç†ç”±ã¤ãã§æ–¹é‡ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

        ########################
        # â–¼â–¼ usage / cost è¡¨ç¤º â–¼â–¼
        ########################

        st.markdown(
            """
            <style>
            /* st.metric ã®æ•°å€¤ã‚’å°ã•ã */
            div[data-testid="stMetricValue"] {
                font-size: 1.1rem;   /* ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ˆã‚Šå°ã•ã */
                line-height: 1.3;
            }

            /* ãƒ©ãƒ™ãƒ«ï¼ˆInput tokens ãªã©ï¼‰ã‚‚å°‘ã—ã ã‘å°ã•ãã—ãŸã„å ´åˆ */
            div[data-testid="stMetricLabel"] {
                font-size: 0.8rem;
            }
            </style>
            """,
            unsafe_allow_html=True,
        )

        usd_jpy = get_usdjpy(DEFAULT_USDJPY)
        in_t = int(usage.get("input_tokens", 0))
        out_t = int(usage.get("output_tokens", 0))
        tot_t = int(usage.get("total_tokens", in_t + out_t))

        st.subheader("ğŸ’° API ä½¿ç”¨é‡ï¼ˆæ¦‚ç®—ï¼‰")

        c1, c2, c3, c4, c5 = st.columns(5)

        c1.metric("Input tokens", f"{in_t:,}")
        c2.metric("Output tokens", f"{out_t:,}")
        c3.metric("Total tokens", f"{tot_t:,}")

        usd = estimate_cost_usd(
            model=st.session_state["chat_model"],
            input_tokens=in_t,
            output_tokens=out_t,
        )

        if usd is None:
            c4.metric("Cost (USD)", "N/A")
            c5.metric("Cost (JPY)", "N/A")
        else:
            jpy = usd_to_jpy(usd, usd_jpy)
            c4.metric("Cost (USD)", f"${usd:,.6f}")
            c5.metric("Cost (JPY)", f"Â¥{jpy:,.2f}")

        # â–¼ å°ã•ã‚æ–‡å­—ï¼ˆèª¬æ˜ç”¨ï¼‰
        st.markdown(
            f"""
            <div style="font-size:0.85rem; color:#666;">
                ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼šUSD/JPY = {usd_jpy:.1f}ï¼ˆå‚è€ƒå€¤ï¼‰
            </div>
            """,
            unsafe_allow_html=True,
        )


        ########################
        # â–¼â–¼ æ ¡æ­£æ–¹é‡ è¡¨ç¤º      â–¼â–¼
        ########################

        st.subheader("ğŸ“‹ æ ¡æ­£æ–¹é‡ï¼ˆã¾ãšä½•ã‚’ã©ã†ç›´ã™ã‹ï¼‰")

        from html import escape

        def md_table_to_html(md: str) -> str:
            lines_ = [ln.strip() for ln in md.splitlines() if ln.strip()]
            rows: List[List[str]] = []

            for ln in lines_:
                if not ln.startswith("|"):
                    continue
                cells = [c.strip() for c in ln.strip("|").split("|")]
                rows.append(cells)

            if not rows:
                return "<p>ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰</p>"

            header = rows[0]
            body = rows[2:] if len(rows) > 2 else []

            col_html = """
                <colgroup>
                    <col style="width:10%">
                    <col style="width:10%">
                    <col style="width:20%">
                    <col style="width:20%">
                    <col style="width:40%">
                </colgroup>
            """

            html = "<table class='proof-table'>"
            html += col_html

            html += "<thead><tr>"
            for h in header:
                html += f"<th>{escape(h)}</th>"
            html += "</tr></thead>"

            html += "<tbody>"
            for r in body:
                html += "<tr>"
                for c in r:
                    html += f"<td>{c}</td>"
                html += "</tr>"
            html += "</tbody></table>"
            return html

        html_table = md_table_to_html(plan_md)

        st.markdown("""
        <style>
        .proof-table { width: 100%; border-collapse: collapse; }
        .proof-table th, .proof-table td { border: 1px solid #ccc; padding: 6px; vertical-align: top; }
        .proof-table th { background: #e8edf7; text-align: center; }
        </style>
        """, unsafe_allow_html=True)

        st.markdown(html_table, unsafe_allow_html=True)

        # â–¼â–¼ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆPDF or Wordï¼‰ â–¼â–¼
        st.markdown("### â¤µï¸ è§£æãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        numbered_preview = render_preview_with_numbers(lines, LINES_PER_PAGE)

        file_base = (used_file_name or "pasted_text").rsplit(".", 1)[0]
        mode_label = st.session_state.get("proof_mode", "").replace(" ", "")
        if mode_label:
            file_stub = f"æ ¡æ­£çµæœ_{file_base}_[{mode_label}]"
        else:
            file_stub = f"æ ¡æ­£çµæœ_{file_base}"

        if dl_choice_key == "pdf":
            pdf_bytes = build_policy_pdf_bytes(
                original_numbered_preview=numbered_preview,
                plan_md=plan_md,
                model=st.session_state["chat_model"],
                mode=st.session_state["proof_mode"],
                extra_prompt=extra_prompt,
                src_name=used_file_name or "pasted_text.txt",
                usage_summary={
                    "input_tokens": in_t,
                    "output_tokens": out_t,
                    "total_tokens": tot_t,
                },
                usd_jpy=usd_jpy,
            )
            if pdf_bytes:
                st.download_button(
                    "PDFï¼ˆ.pdfï¼‰ã¨ã—ã¦ä¿å­˜",
                    data=pdf_bytes,
                    file_name=f"{file_stub}.pdf",
                    mime="application/pdf",
                    use_container_width=True,
                    key=f"dl_pdf_{file_stub}",
                )
            else:
                st.warning("PDF ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚`pip install reportlab` ã‚’å®Ÿè¡Œã—ã€CIDãƒ•ã‚©ãƒ³ãƒˆï¼ˆHeiseiMin/HeiseiKakuGoï¼‰ãŒä½¿ãˆã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            data_docx, ext = build_policy_docx_bytes(
                original_numbered_preview=numbered_preview,
                plan_md=plan_md,
                model=st.session_state["chat_model"],
                mode=st.session_state["proof_mode"],
                extra_prompt=extra_prompt,
                src_name=used_file_name or "pasted_text.txt",
                usage_summary={
                    "input_tokens": in_t,
                    "output_tokens": out_t,
                    "total_tokens": tot_t,
                },
                usd_jpy=usd_jpy,
            )
            st.download_button(
                "Wordï¼ˆ.docxï¼‰ã¨ã—ã¦ä¿å­˜" if ext == ".docx" else "ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã¨ã—ã¦ä¿å­˜",
                data=data_docx,
                file_name=f"{file_stub}{ext}",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document" if ext == ".docx" else "text/plain",
                use_container_width=True,
                key=f"dl_word_{file_stub}",
            )
else:
    st.info("å…¥åŠ›ã‚¿ãƒ–ï¼ˆğŸ“/ğŸ“ï¼‰ã‹ã‚‰æœ¬æ–‡ã‚’æŒ‡å®šã—ã¦ã€â‘  è§£æã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
