# -*- coding: utf-8 -*-
# pages/19_AIãƒãƒ£ãƒƒãƒˆï¼ˆè¦ç´„æ©Ÿèƒ½ï¼‰.py
# ------------------------------------------------------------
# ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆ
#
# âœ… æ–°ãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹ ï¼ˆæ­£æœ¬ï¼‰ï¼š
# - page_session_heartbeat ã§ãƒ­ã‚°ã‚¤ãƒ³/heartbeat
# - busy_run ã§ ai_runs.db ã‚’å¿…ãšè¨˜éŒ²
# - å®Ÿè¡Œã‚µãƒãƒªï¼ˆé–‹å§‹/çµ‚äº†/çµŒéï¼‰ã¯ render_run_summary_compact ã«å§”è­²ã—ã¦è¡¨ç¤ºï¼ˆai_runs.db æ­£æœ¬ï¼‰
# - AIå‘¼ã³å‡ºã—ã¯ common_lib.ai.routing.call_text ã®ã¿ï¼ˆproviders ç›´å©ãç¦æ­¢ï¼‰
# - tokens/cost ã¯ã€Œè¿”ã£ã¦ããŸç¯„å›²ã€ã§ br.set_usage / br.set_cost ã«åæ˜ ï¼ˆæ¨è¨ˆã—ãªã„ï¼‰
# - cost è¡¨ç¤ºã¯ common_lib.ai.costs.uiï¼ˆè¨ˆç®—ã—ãªã„ï¼‰
#
# è¿½åŠ æ©Ÿèƒ½ï¼ˆå±¥æ­´ç¸®ç´„ï¼‰ï¼š
# - æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³è¡¨ç¤ºï¼ˆæ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
#   * 12,000è¶… â†’ ğŸŸ¡
#   * 15,000è¶… â†’ ğŸ”´
# - æ–¹å¼Aï¼šâœ‚ï¸ ç›´è¿‘Nä»¶ã«ã‚«ãƒƒãƒˆï¼ˆå±¥æ­´ãã®ã‚‚ã®ã‚’å‰Šé™¤ï¼‰N=20
# - æ–¹å¼Bï¼šğŸ§  ç›´è¿‘Kä»¶ã‚’æ®‹ã—ã¦ã€ãã‚Œä»¥å‰ï¼ˆéå»ï¼‹éå»è¦ç´„ï¼‰ã‚’1ã¤ã«å†è¦ç´„ K=12
#   * è¦ç´„ã¯ system ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å…ˆé ­1ä»¶ã«å›ºå®š
#
# UIæ–¹é‡ï¼š
# - use_container_width ã¯ä½¿ã‚ãªã„
# - st.form ã¯ä½¿ã‚ãªã„
# - st.button()/st.download_button() ã« width å¼•æ•°ã¯ä½¿ã‚ãªã„
# ------------------------------------------------------------

from __future__ import annotations

import json
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st

# ============================================================
# å±¥æ­´ç¸®ç´„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¤‰æ›´ã—ã‚„ã™ã„ï¼šã“ã“ã ã‘è§¦ã‚Œã°è‰¯ã„ï¼‰
#
# â–  ç›®çš„
# - ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒè‚¥å¤§åŒ–ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã«è¿‘ã¥ãã®ã‚’é˜²ã
# - ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã§ã€Œç‰©ç†ã‚«ãƒƒãƒˆã€ã¾ãŸã¯ã€Œè¦ç´„ç¸®ç´„ã€ã‚’é¸ã¹ã‚‹ã‚ˆã†ã«ã™ã‚‹
# - è­¦å‘Šè¡¨ç¤ºï¼ˆğŸŸ¡/ğŸ”´ï¼‰ã«ã‚ˆã‚Šã€é€ä¿¡å‰ã«å…¥åŠ›ã‚µã‚¤ã‚ºã‚’æŠŠæ¡ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
#
# â–  è¨­è¨ˆæ–¹é‡
# - æ•°å€¤ã¯ã™ã¹ã¦ã€ŒUIãƒ»æŒ™å‹•èª¿æ•´ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ã¨ã—ã¦ã“ã“ã«é›†ç´„
# - ãƒ­ã‚¸ãƒƒã‚¯å´ã«ã¯ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’åŸ‹ã‚è¾¼ã¾ãªã„
# - å¤‰æ›´æ™‚ã¯ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã®ã¿ä¿®æ­£ã™ã‚Œã°å…¨ä½“ã«åæ˜ ã•ã‚Œã‚‹
# ============================================================

# æ–¹å¼Aï¼šå±¥æ­´ã‚’ç‰©ç†çš„ã«å‰Šé™¤ã—ã¦ã€ç›´è¿‘ N ä»¶ã ã‘æ®‹ã™
# - è¡¨ç¤ºä¸Šã‚‚å®Œå…¨ã«æ¶ˆãˆã‚‹
# - ãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„åŠ¹æœãŒæœ€ã‚‚é«˜ã„ãŒã€éå»æ–‡è„ˆã¯å¤±ã‚ã‚Œã‚‹
#CUT_N = 20
CUT_N = 3

# æ–¹å¼Bï¼šç›´è¿‘ K ä»¶ã‚’æ®‹ã—ã€ãã‚Œä»¥å‰ã®å±¥æ­´ã‚’ 1 ä»¶ã® system è¦ç´„ã«ç½®ãæ›ãˆã‚‹
# - æ–‡è„ˆã¯ç¶­æŒã•ã‚Œã‚‹ãŒã€è¦ç´„åˆ†ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯å¸¸ã«å«ã¾ã‚Œã‚‹
# - KEEP_K ã¯ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç›´æ„Ÿçš„ã«è¦šãˆã¦ã„ã‚‰ã‚Œã‚‹ä¼šè©±é‡ã€ã‚’ç›®å®‰ã«è¨­å®š
# KEEP_K = 12
KEEP_K = 3

# æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆå…¥åŠ›ï¼šsystem + promptï¼‰ãŒã“ã®å€¤ã‚’è¶…ãˆãŸã‚‰è­¦å‘Šè¡¨ç¤ºï¼ˆğŸŸ¡ï¼‰
# - ã¾ã é€ä¿¡ã¯å¯èƒ½ã ãŒã€è¦ç´„ãƒ»ã‚«ãƒƒãƒˆã‚’æ¤œè¨ã™ã¹ãæ°´æº–
WARN_YELLOW = 12000

# æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆå…¥åŠ›ï¼šsystem + promptï¼‰ãŒã“ã®å€¤ã‚’è¶…ãˆãŸã‚‰å¼·ã„è­¦å‘Šï¼ˆğŸ”´ï¼‰
# - ãƒ¢ãƒ‡ãƒ«ä¸Šé™ã«è¿‘ã¥ã„ã¦ãŠã‚Šã€å¤±æ•—ãƒ»è‡ªå‹•åˆ‡ã‚Šè©°ã‚ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„
# - å±¥æ­´ç¸®ç´„ã‚’å¼·ãæ¨å¥¨ã™ã‚‹æ°´æº–
WARN_RED = 15000


# æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆæ—¥æœ¬èªç›®å®‰ï¼‰ï¼š1 token â‰’ 1.5 chars
TOK_PER_CHAR = 1 / 1.5

# ============================================================
# sys.pathï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹ ï¼šcommon_lib ã‚’ import ã§ãã‚‹ã‚ˆã†ã«ï¼‰
# - MONO_ROOT / PROJ_DIR / APP_DIR ã‚’ sys.path ã«å…¥ã‚Œã‚‹
# - PROJECTS_ROOT ã¯ MONO_ROOTï¼ˆå…¨ãƒšãƒ¼ã‚¸ã§æ„å‘³ã‚’æƒãˆã‚‹ï¼‰
# ============================================================
_THIS = Path(__file__).resolve()
APP_DIR = _THIS.parents[1]
PROJ_DIR = _THIS.parents[2]
MONO_ROOT = _THIS.parents[3]

# ------------------------------------------------------------
# MONO_ROOT å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ºãƒ¬äº‹æ•…ã®å†ç™ºé˜²æ­¢ï¼‰
# ------------------------------------------------------------
if not (MONO_ROOT / "common_lib").is_dir():
    raise RuntimeError(
        "MONO_ROOT ã®è§£é‡ˆãŒä¸æ­£ã§ã™ï¼ˆcommon_lib ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰ã€‚\n"
        f"  this_file : {_THIS}\n"
        f"  MONO_ROOT  : {MONO_ROOT}\n"
        "å¯¾å‡¦ï¼špages ã®éšå±¤ï¼ˆparents[3]ï¼‰å‰æãŒå´©ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    )

for p in (MONO_ROOT, PROJ_DIR, APP_DIR):
    if str(p) not in sys.path:
        sys.path.insert(0, str(p))

PROJECTS_ROOT = MONO_ROOT
APP_NAME = _THIS.parents[1].name
PAGE_NAME = _THIS.stem

# ============================================================
# Page
# ============================================================
st.set_page_config(
    page_title="ğŸ’¬ Text Studio / AIãƒãƒ£ãƒƒãƒˆï¼ˆè¦ç´„æ©Ÿèƒ½ï¼‰",
    page_icon="ğŸ’¬",
    layout="wide",
)

# ============================================================
# common_libï¼ˆæ­£æœ¬ï¼‰
# ============================================================
from common_lib.sessions.page_entry import page_session_heartbeat
from common_lib.ui.banner_lines import render_banner_line_by_key
from common_lib.busy import busy_run
from common_lib.ai.routing import call_text
from common_lib.ui import render_run_summary_compact
from common_lib.io import read_doc_context_from_bytes, read_doc_context_from_text

from common_lib.ai.usage_extract import extract_text_in_out_tokens
from common_lib.busy.apply_text_result import apply_text_result_to_busy

# ï¼ˆGeminiã®é¸æŠè‚¢ã‚’å‡ºã™ã‹ã©ã†ã‹ã¯UIéƒ½åˆãªã®ã§ã€æ—¢å­˜configã®åˆ¤å®šã¯æ®‹ã™ï¼‰
from config.config import has_gemini_api_key

from common_lib.ui.model_picker import render_text_model_picker
from common_lib.ai.models import TEXT_MODEL_CATALOG, DEFAULT_TEXT_MODEL_KEY
from functools import lru_cache

# ============================================================
# Banner + heartbeat
# ============================================================
render_banner_line_by_key("purple_light")

sub = page_session_heartbeat(
    st,
    PROJECTS_ROOT,
    app_name=APP_NAME,
    page_name=PAGE_NAME,
)

left, right = st.columns([2, 1])
with left:
    st.title("ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆè¦ç´„æ©Ÿèƒ½ä»˜ãï¼‰")
with right:
    st.success(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³ä¸­: **{sub}**")

st.caption(
    "æ–‡æ›¸ã‚’ä¼šè©±ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‰æï¼‰ã¨ã—ã¦ã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
    " æ–‡æ›¸ãŒãªãã¦ã‚‚é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆã¨ã—ã¦ä½¿ãˆã¾ã™ã€‚"
)

# ============================================================
# Session state
# ============================================================
def _ensure_state() -> None:
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []  # List[Dict[str,str]]
    if "chat_draft_key" not in st.session_state:
        st.session_state.chat_draft_key = 0
    if "doc_context" not in st.session_state:
        st.session_state.doc_context = None

    # ç›´è¿‘ã‚¿ãƒ¼ãƒ³ï¼ˆcost/usageè¡¨ç¤ºç”¨ï¼šæ¨è¨ˆã—ãªã„ï¼‰
    st.session_state.setdefault("chat_last_run_id", "")
    st.session_state.setdefault("chat_last_model", "")
    st.session_state.setdefault("chat_last_provider", "")
    st.session_state.setdefault("chat_last_in_tok", None)
    st.session_state.setdefault("chat_last_out_tok", None)
    st.session_state.setdefault("chat_last_cost_obj", None)
    st.session_state.setdefault("chat_last_note", "")

    # ç›´è¿‘ã‚¿ãƒ¼ãƒ³ï¼šæœ€å¾Œã«AIã¸é€ã£ãŸ system / promptï¼ˆå…¨æ–‡ãƒ»æ¤œè¨¼ç”¨ï¼‰
    st.session_state.setdefault("chat_last_system_text", "")
    st.session_state.setdefault("chat_last_prompt_text", "")

    # ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹ ï¼šprovider:model ã‚’ session_state ã§ä¿æŒï¼‰
    st.session_state.setdefault("chat_model_key", DEFAULT_TEXT_MODEL_KEY)
    # æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹ ï¼šsession_state æ­£æœ¬ï¼‰
    st.session_state.setdefault("chat_max_output_tokens", 8000)

_ensure_state()

# ============================================================
# Helpers
# ============================================================
def _get_doc_context_text() -> str:
    ctx = st.session_state.get("doc_context")
    if not ctx:
        return ""
    kind = (ctx.get("kind") or "").strip()
    text = (ctx.get("text") or "").strip()
    if not text:
        return ""
    max_chars = 15000
    used = text[:max_chars]
    return f"ã€ä¼šè©±ã®å‰ææ–‡æ›¸ï¼š{kind}ï¼ˆå…ˆé ­ã€œæœ€å¤§{max_chars}æ–‡å­—ï¼‰ã€‘\n{used}\n"

def _build_system_instructions(has_doc: bool) -> str:
    base = "ã‚ãªãŸã¯ä¸å¯§ãªæ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    if has_doc:
        base += (
            "\n\nä»¥ä¸‹ã®ã€å‰ææ–‡æ›¸ã€ã«åŸºã¥ãè³ªå•ã«ã¯æ–‡æ›¸ã«æ²¿ã£ã¦ç­”ãˆã€"
            "æ–‡æ›¸ã«ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšä¸æ˜ã¨è¨€ã£ã¦ãã ã•ã„ã€‚"
        )
    return base

def _parse_model_key(model_key: str) -> tuple[str, str]:
    if ":" not in model_key:
        return ("openai", model_key.strip())
    p, m = model_key.split(":", 1)
    return (p.strip(), m.strip())

@lru_cache(maxsize=1)
def _gemini_available() -> bool:
    try:
        from google import genai  # google-genai
        _ = genai
        return True
    except Exception:
        return False

def _build_prompt_from_history(latest_user_text: str) -> str:
    doc_text = _get_doc_context_text()

    lines: List[str] = []
    for m in st.session_state.chat_messages:
        role = (m.get("role") or "").strip()
        content = (m.get("content") or "").strip()
        if not content:
            continue
        if role == "user":
            lines.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {content}")
        elif role == "assistant":
            lines.append(f"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {content}")
        else:
            lines.append(f"{role}: {content}")

    history_block = "\n".join(lines).strip()

    parts: List[str] = []
    if doc_text:
        parts.append(doc_text)
    if history_block:
        parts.append("ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n" + history_block)
    parts.append("ã€ä»Šå›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã€‘\n" + latest_user_text)
    parts.append("ã€æŒ‡ç¤ºã€‘\nä¸å¯§ãªæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªã‚‰ç¢ºèªè³ªå•ã‚’æœ€å°é™ã«ã—ã¦ãã ã•ã„ã€‚")

    return "\n\n".join(parts).strip()

# ============================================================
# æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆç›®å®‰ï¼‰é–¢é€£ï¼ˆæ­£æœ¬ãƒ­ã‚¸ãƒƒã‚¯ï¼šæ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
# ============================================================
def _estimate_tokens_from_chars(chars: int) -> int:
    if chars <= 0:
        return 0
    return int(chars * TOK_PER_CHAR)

def _estimate_next_input_tokens(*, draft_text: str) -> Tuple[int, int]:
    """
    æ¬¡ã«AIã¸é€ã‚‹æƒ³å®šã®å…¥åŠ›ï¼ˆsystem+promptï¼‰ã®æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¿”ã™ã€‚
    Returns: (tokens_est, chars_total)
    """
    has_doc = bool(_get_doc_context_text().strip())
    sys_text = _build_system_instructions(has_doc)
    prm_text = _build_prompt_from_history(draft_text or "")
    total_chars = len(sys_text) + len(prm_text)
    return _estimate_tokens_from_chars(total_chars), total_chars

# ============================================================
# å±¥æ­´ç¸®ç´„ï¼ˆæ–¹å¼A / æ–¹å¼Bï¼‰
# ============================================================
def _cut_history_last_n(*, n: int) -> None:
    """
    æ–¹å¼Aï¼šå±¥æ­´ãã®ã‚‚ã®ã‚’ç›´è¿‘nä»¶ã«ã‚«ãƒƒãƒˆï¼ˆè¡¨ç¤ºã‚‚æ¶ˆãˆã‚‹ï¼‰
    """
    msgs = st.session_state.get("chat_messages", []) or []
    st.session_state.chat_messages = msgs[-n:]

def _summary_format_instruction() -> str:
    """
    è¦ç´„ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆå›ºå®šï¼‰
    """
    return (
        "ã€è¦ç´„å½¢å¼ã€‘\n"
        "ãƒ»è¦ç´„ï¼ˆ5ã€œ10è¡Œï¼‰\n"
        "ãƒ»æ±ºå®šäº‹é …\n"
        "ãƒ»æœªæ±ºäº‹é …\n"
        "ãƒ»ç”¨èª/å‰æï¼ˆé‡è¦ãªåˆ¶ç´„ã®ã¿ï¼‰\n"
        "ãƒ»æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆã‚ã‚Œã°ï¼‰\n"
    )

def _build_summary_prompt(*, old_msgs: List[Dict[str, str]]) -> str:
    """
    éå»ãƒ‘ãƒ¼ãƒˆã‚’è¦ç´„ã•ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç´¯ç©è¦ç´„å‰æï¼‰
    """
    history_text = "\n".join(
        f"{(m.get('role') or '').strip()}: {(m.get('content') or '').strip()}"
        for m in old_msgs
        if (m.get("content") or "").strip()
    ).strip()

    return (
        "ä»¥ä¸‹ã¯ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã§ã™ã€‚\n"
        "å¾Œç¶šã®ä¼šè©±ã§å¿…è¦ãªå‰æã¨ã—ã¦ã€æ¬¡ã®å½¢å¼ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
        "æ¨æ¸¬ã‚„æ–°è¦ã®æƒ…å ±è¿½åŠ ã¯ã›ãšã€ä¼šè©±ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹äº‹å®Ÿã®ã¿ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚\n\n"
        + _summary_format_instruction()
        + "\nã€ä¼šè©±å±¥æ­´ã€‘\n"
        + history_text
    ).strip()

def _summarize_history_keep_k(*, provider: str, model: str, keep_k: int) -> None:
    """
    æ–¹å¼Bï¼šç›´è¿‘Kä»¶ã‚’æ®‹ã—ã€ãã‚Œä»¥å‰ï¼ˆéå»ï¼‹éå»è¦ç´„ï¼‰ã‚’1ã¤ã«å†è¦ç´„ã—ã€
          systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å…ˆé ­1ä»¶ã«å›ºå®šã™ã‚‹ã€‚
    """
    msgs = st.session_state.get("chat_messages", []) or []
    if len(msgs) <= keep_k:
        raise RuntimeError("è¦ç´„ã™ã‚‹ã»ã©å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    old_msgs = msgs[:-keep_k]
    recent_msgs = msgs[-keep_k:]

    summary_prompt = _build_summary_prompt(old_msgs=old_msgs)

    with busy_run(
        projects_root=PROJECTS_ROOT,
        user_sub=str(sub),
        app_name=str(APP_NAME),
        page_name=str(PAGE_NAME),
        task_type="text",
        provider=str(provider),
        model=str(model),
        meta={
            "feature": "ai_chat",
            "action": "summarize_history",
            "kept_recent": int(keep_k),
            "old_msgs": int(len(old_msgs)),
            "recent_msgs": int(len(recent_msgs)),
            "summary_prompt_chars": int(len(summary_prompt)),
        },
    ) as br:
        res = call_text(
            provider=str(provider),
            model=str(model),
            prompt=str(summary_prompt),
            system=None,
            temperature=None,
            max_output_tokens=None,
            extra=None,
        )

        summary_text = (getattr(res, "text", "") or "").strip()

        pp = apply_text_result_to_busy(
            br=br,
            res=res,
            extract_text_in_out_tokens=extract_text_in_out_tokens,
            note_ok="ok",
            note_no_usage="no_usage",
            note_no_cost="no_cost",
        )

        br.add_finish_meta(note=str(pp.note or "ok"))

    if not summary_text:
        raise RuntimeError("è¦ç´„çµæœãŒç©ºã§ã—ãŸã€‚")

    st.session_state.chat_messages = (
        [{
            "role": "system",
            "content": "ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã®è¦ç´„ã€‘\n" + summary_text,
        }]
        + recent_msgs
    )

# ============================================================
# History helpersï¼ˆä¿å­˜/å¾©å…ƒï¼šæ­£æœ¬ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
# ============================================================
def _history_payload_v1(*, messages: List[Dict[str, str]]) -> Dict[str, Any]:
    mk_payload = str(st.session_state.get("chat_model_key") or DEFAULT_TEXT_MODEL_KEY)
    p_payload, m_payload = _parse_model_key(mk_payload)

    return {
        "schema": "chat_history_v1",
        "provider": p_payload,
        "model": m_payload,
        "doc_context": st.session_state.get("doc_context"),
        "messages": messages,
    }

def _history_as_text_v1(*, messages: List[Dict[str, str]]) -> str:
    lines: List[str] = []

    ctx = st.session_state.get("doc_context")
    if ctx and (ctx.get("text") or "").strip():
        kind = ctx.get("kind", "")
        text = ctx.get("text", "")
        head = text[:1000]
        lines.append(f"ã€å‰ææ–‡æ›¸: {kind} / ç´„ {len(text)} æ–‡å­— / å…ˆé ­1000æ–‡å­—ã€‘\n{head}")
        lines.append("")

    for m in messages:
        role = (m.get("role") or "").strip()
        content = (m.get("content") or "").rstrip()
        if not content:
            continue
        if role == "user":
            lines.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼:\n" + content)
        elif role == "assistant":
            lines.append("AI:\n" + content)
        else:
            lines.append(f"{role}:\n" + content)
        lines.append("")
    return "\n".join(lines).strip() + "\n"

def _validate_messages_v1(obj: Any) -> bool:
    if not isinstance(obj, list):
        return False
    for m in obj:
        if not isinstance(m, dict):
            return False
        if m.get("role") not in ("user", "assistant", "system"):
            return False
        if not isinstance(m.get("content", ""), str):
            return False
    return True

def _load_history_json_bytes(raw: bytes) -> Tuple[List[Dict[str, str]], Optional[Dict[str, Any]]]:
    loaded = json.loads(raw.decode("utf-8", errors="ignore"))

    restored_docctx = None
    msgs = None

    if isinstance(loaded, dict):
        restored_docctx = loaded.get("doc_context")
        if "messages" in loaded:
            msgs = loaded.get("messages")
    else:
        msgs = loaded

    if not _validate_messages_v1(msgs):
        raise RuntimeError("ã“ã®JSONã¯å±¥æ­´å½¢å¼ã¨ã—ã¦ä¸æ­£ã§ã™ï¼ˆmessagesã®æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰ã€‚")

    if isinstance(restored_docctx, dict):
        kind = restored_docctx.get("kind")
        text = restored_docctx.get("text")
        if not (isinstance(kind, str) and isinstance(text, str) and text.strip()):
            restored_docctx = None
    else:
        restored_docctx = None

    return msgs, restored_docctx

def _apply_restored_history(*, messages: List[Dict[str, str]], doc_context: Optional[Dict[str, Any]]) -> None:
    st.session_state.chat_messages = messages
    st.session_state.doc_context = doc_context

    st.session_state.chat_last_run_id = ""
    st.session_state.chat_last_model = ""
    st.session_state.chat_last_provider = ""
    st.session_state.chat_last_in_tok = None
    st.session_state.chat_last_out_tok = None
    st.session_state.chat_last_cost_obj = None
    st.session_state.chat_last_note = ""

    st.session_state.chat_draft_key = (st.session_state.get("chat_draft_key", 0) or 0) + 1

# ============================================================
# Sidebar: settings + history save/restore + å±¥æ­´ç¸®ç´„UI
# ============================================================
with st.sidebar:
    st.header("è¨­å®š")

    # ------------------------------------------------------------
    # ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æº–æ‹ ï¼šrender_text_model_pickerï¼‰
    # ------------------------------------------------------------
    gem_ok = bool(has_gemini_api_key()) and bool(_gemini_available())

    model_key = render_text_model_picker(
        title="ğŸ§  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
        catalog=TEXT_MODEL_CATALOG,
        session_key="chat_model_key",
        default_key=DEFAULT_TEXT_MODEL_KEY,
        page_name=PAGE_NAME,
        gemini_available=gem_ok,
    )

    provider, model = _parse_model_key(str(model_key or DEFAULT_TEXT_MODEL_KEY))

    max_output_tokens = st.number_input(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¸Šé™ï¼‰",
        min_value=256,
        max_value=20000,
        step=256,
        key="chat_max_output_tokens",
    )

    debug_mode = st.toggle("ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º", value=False)

    st.divider()

    # ------------------------------------------------------------
    # ä¼šè©±ãƒªã‚»ãƒƒãƒˆ / æ–‡æ›¸ã‚¯ãƒªã‚¢ï¼ˆç¸¦ä¸¦ã³ï¼‰
    # ------------------------------------------------------------
    if st.button("ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="btn_reset_chat"):
        st.session_state.pop("chat_messages", None)
        st.session_state.pop("chat_draft_key", None)
        st.session_state.pop("chat_last_run_id", None)
        st.session_state.pop("chat_last_model", None)
        st.session_state.pop("chat_last_provider", None)
        st.session_state.pop("chat_last_in_tok", None)
        st.session_state.pop("chat_last_out_tok", None)
        st.session_state.pop("chat_last_cost_obj", None)
        st.session_state.pop("chat_last_note", None)

        st.session_state.pop("chat_last_system_text", None)
        st.session_state.pop("chat_last_prompt_text", None)

        _ensure_state()
        st.rerun()

    if st.button("æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢", key="btn_clear_docctx"):
        st.session_state.pop("doc_context", None)
        st.session_state.doc_context = None
        st.rerun()

    # ------------------------------------------------------------
    # æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³è¡¨ç¤ºï¼ˆæ¬¡å›é€ä¿¡ã®å…¥åŠ›ï¼šsystem + promptï¼‰
    # ------------------------------------------------------------
    st.divider()
    st.subheader("å…¥åŠ›ã‚µã‚¤ã‚ºç›®å®‰ï¼ˆæ¦‚ç®—ï¼‰")

    draft_key_for_est = f"chat_draft_{st.session_state.get('chat_draft_key', 0)}"
    draft_now = str(st.session_state.get(draft_key_for_est, "") or "")
    est_tok, est_chars = _estimate_next_input_tokens(draft_text=draft_now)

    if est_tok >= WARN_RED:
        st.error(f"ğŸ”´ æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³: {est_tok:,} / chars: {est_chars:,}")
    elif est_tok >= WARN_YELLOW:
        st.warning(f"ğŸŸ¡ æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³: {est_tok:,} / chars: {est_chars:,}")
    else:
        st.success(f"ğŸŸ¢ æ¦‚ç®—ãƒˆãƒ¼ã‚¯ãƒ³: {est_tok:,} / chars: {est_chars:,}")

    st.caption("â€» æ–‡å­—æ•°ã‹ã‚‰ã®æ¦‚ç®—ã§ã™ï¼ˆç›®å®‰ï¼‰ã€‚")

    # ------------------------------------------------------------
    # å±¥æ­´ç¸®ç´„ï¼ˆ2æ–¹å¼ï¼‰
    # ------------------------------------------------------------
    st.divider()
    st.subheader("å±¥æ­´ã®ç¸®ç´„")

    if st.button(f"âœ‚ï¸ ç›´è¿‘ {CUT_N} ä»¶ã«ã‚«ãƒƒãƒˆ", key="btn_cut_history"):
        _cut_history_last_n(n=CUT_N)
        st.rerun()

    if st.button("ğŸ§  è¦ç´„ã—ã¦çŸ­ã", key="btn_summarize_history"):
        try:
            _summarize_history_keep_k(provider=str(provider), model=str(model), keep_k=KEEP_K)
            st.rerun()
        except Exception as e:
            st.error(str(e))

    # ============================================================
    # å±¥æ­´ï¼šãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ / ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆJSON / TXTï¼‰
    # ============================================================
    st.divider()
    st.subheader("å±¥æ­´ï¼ˆä¿å­˜/å¾©å…ƒï¼‰")

    messages = st.session_state.get("chat_messages", []) or []

    payload = _history_payload_v1(messages=messages)
    json_str = json.dumps(payload, ensure_ascii=False, indent=2)
    txt_str = _history_as_text_v1(messages=messages)

    st.download_button(
        "â¬‡ï¸ å±¥æ­´ã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=json_str.encode("utf-8"),
        file_name="chat_history.json",
        mime="application/json",
        disabled=(len(messages) == 0),
        key="dl_history_json",
    )

    st.download_button(
        "â¬‡ï¸ å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=txt_str.encode("utf-8"),
        file_name="chat_history.txt",
        mime="text/plain",
        disabled=(len(messages) == 0),
        key="dl_history_txt",
    )

    st.caption("â€» JSONã¯å¾©å…ƒç”¨ã®æ­£æœ¬ã€TXTã¯èª­ã¿ã‚„ã™ã„ãƒ­ã‚°ã§ã™ã€‚")

    up = st.file_uploader(
        "â¬†ï¸ å±¥æ­´JSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å¾©å…ƒ",
        type=["json"],
        key="upl_history_json",
        help="chat_history.jsonï¼ˆschema=chat_history_v1ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
    )

    restore_clicked = st.button(
        "âœ… ã“ã®JSONã§å±¥æ­´ã‚’å¾©å…ƒ",
        type="primary",
        disabled=(up is None),
        key="btn_restore_history",
        help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸJSONã‚’èª­ã¿è¾¼ã¿ã€å±¥æ­´ã‚’ç½®ãæ›ãˆã¾ã™ã€‚",
    )

    if restore_clicked:
        try:
            raw = up.read() if up is not None else b""
            if not raw:
                st.error("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸJSONãŒç©ºã§ã™ã€‚ã‚‚ã†ä¸€åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                st.stop()

            msgs, docctx = _load_history_json_bytes(raw)
            _apply_restored_history(messages=msgs, doc_context=docctx)

            doc_note = ""
            if docctx and (docctx.get("text") or "").strip():
                doc_note = f" / doc_context: {docctx.get('kind','')} / ç´„ {len(docctx.get('text',''))} æ–‡å­—"

            st.success(f"âœ… å±¥æ­´ã‚’å¾©å…ƒã—ã¾ã—ãŸï¼ˆ{len(msgs)}ä»¶ï¼‰ã€‚{doc_note}")
            st.rerun()

        except Exception as e:
            st.error(f"å±¥æ­´JSONã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ============================================================
# 1) æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰
# ============================================================
st.subheader("1ï¸âƒ£ æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰")
st.caption("ã“ã“ã§ã‚»ãƒƒãƒˆã—ãŸæ–‡æ›¸ã¯ã€ä¼šè©±ã®å‰æï¼ˆå‚è€ƒè³‡æ–™ï¼‰ã¨ã—ã¦æ¯ã‚¿ãƒ¼ãƒ³å‚ç…§ã•ã‚Œã¾ã™ã€‚")

tab_file, tab_text = st.tabs(["ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘"])

tmp_dc = None  # common_lib.io.DocContextï¼ˆto_dict ã‚’æŒã¤æƒ³å®šï¼‰

with tab_file:
    uploaded = st.file_uploader(
        "Word / ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown / PDF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰",
        type=["docx", "txt", "json", "md", "pdf"],
        key="ctx_file_uploader",
    )

    if uploaded is not None:
        try:
            tmp_dc = read_doc_context_from_bytes(
                file_name=uploaded.name,
                data=uploaded.read(),
                max_chars=15000,
            )
            st.success(f"âœ… èª­ã¿è¾¼ã¿OK: {uploaded.name}ï¼ˆ{len(tmp_dc.text):,} charsï¼‰")
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            tmp_dc = None

with tab_text:
    pasted = st.text_area(
        "ãƒ†ã‚­ã‚¹ãƒˆ / JSON / Markdown ã‚’ç›´æ¥è²¼ã‚Šä»˜ã‘ï¼ˆä»»æ„ï¼‰",
        height=180,
        placeholder="ã“ã“ã«è²¼ã‚Šä»˜ã‘ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ä¼šè©±ã®å‰ææ–‡æ›¸ã¨ã—ã¦ã‚»ãƒƒãƒˆã§ãã¾ã™ã€‚",
        key="ctx_text_paste",
    )
    if pasted.strip():
        try:
            tmp_dc = read_doc_context_from_text(
                raw_text=pasted,
                max_chars=15000,
                kind="è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆ",
            )
        except Exception as e:
            st.error(f"è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            tmp_dc = None

col_set, col_show = st.columns([1, 2])
with col_set:
    if st.button("ã“ã®æ–‡æ›¸ã‚’ä¼šè©±ã«ã‚»ãƒƒãƒˆ", disabled=(tmp_dc is None)):
        st.session_state.doc_context = tmp_dc.to_dict()
        st.success(f"âœ… æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼ˆ{tmp_dc.kind} / ç´„ {len(tmp_dc.text):,} æ–‡å­—ï¼‰")

with col_show:
    ctx = st.session_state.get("doc_context")
    if ctx and (ctx.get("text") or "").strip():
        kind = ctx.get("kind", "")
        text = ctx.get("text", "")
        st.info(f"ğŸ“Œ ç¾åœ¨ã®æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼š{kind}ï¼ˆç´„ {len(text):,} æ–‡å­—ï¼‰")

        meta = ctx.get("meta") if isinstance(ctx, dict) else None
        if isinstance(meta, dict):
            if bool(meta.get("truncated")):
                st.caption("â€» ã“ã®æ–‡æ›¸ã¯æœ€å¤§æ–‡å­—æ•°åˆ¶é™ã«ã‚ˆã‚Šé€”ä¸­ã§ã‚«ãƒƒãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚")

        with st.expander("æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­ï¼‰", expanded=False):
            preview = text[:1000] + ("\nâ€¦ï¼ˆçœç•¥ï¼‰" if len(text) > 1000 else "")
            st.code(preview, language="text")
    else:
        st.caption("ï¼ˆæ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯æœªè¨­å®šï¼‰")

st.divider()

# ============================================================
# 2) Chat UI
# ============================================================
st.subheader("2ï¸âƒ£ ãƒãƒ£ãƒƒãƒˆ")

for m in st.session_state.chat_messages:
    with st.chat_message(m.get("role", "assistant")):
        st.write(m.get("content", ""))

draft_key = f"chat_draft_{st.session_state.chat_draft_key}"
user_text = st.text_area(
    "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
    key=draft_key,
    height=90,
    placeholder="ã“ã“ã«å…¥åŠ›ã—ã¦ã€Œé€ä¿¡ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼ˆShift+Enterã§æ”¹è¡Œï¼‰ã€‚",
)

col_send, col_hint = st.columns([1, 4])
with col_send:
    send = st.button("é€ä¿¡", type="primary")
with col_hint:
    st.caption("â€» æ–‡æ›¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¦ã„ã‚‹å ´åˆã€ä¼šè©±ã®å‰æã¨ã—ã¦æ¯ã‚¿ãƒ¼ãƒ³å‚ç…§ã•ã‚Œã¾ã™ã€‚")

if debug_mode:
    st.caption("ãƒ‡ãƒãƒƒã‚°ã¯ã“ã®ä¸‹ã«å‡ºã¾ã™ï¼ˆé€ä¿¡å¾Œã®çµæœãªã©ï¼‰ã€‚")

# ============================================================
# Debug / Inspectï¼šæœ€å¾Œã«AIã¸é€ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå…¨æ–‡ï¼‰
# ============================================================
last_sys = str(st.session_state.get("chat_last_system_text") or "")
last_prm = str(st.session_state.get("chat_last_prompt_text") or "")

if last_sys.strip() or last_prm.strip():
    with st.expander("ğŸ§¾ æœ€å¾Œã«AIã¸é€ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå…¨æ–‡ï¼‰", expanded=False):
        full_text = (
            "=== SYSTEM ===\n"
            + (last_sys.strip() + "\n" if last_sys.strip() else "(none)\n")
            + "\n"
            + "=== PROMPT ===\n"
            + (last_prm.strip() + "\n" if last_prm.strip() else "(none)\n")
        )

        st.download_button(
            "â¬‡ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’ .txt ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=full_text.encode("utf-8"),
            file_name="last_prompt.txt",
            mime="text/plain",
            key="dl_last_prompt_txt",
        )

        st.text_area(
            "é€ä¿¡å†…å®¹ï¼ˆSYSTEM + PROMPTï¼‰",
            value=full_text,
            height=320,
            key="ta_last_prompt_full",
        )

if send:
    if not (user_text or "").strip():
        st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™ã€‚")
        st.stop()

    user_text = user_text.strip()

    st.session_state.chat_messages.append({"role": "user", "content": user_text})

    next_draft_key_value = st.session_state.chat_draft_key + 1

    prompt = _build_prompt_from_history(user_text)
    has_doc = bool(_get_doc_context_text().strip())
    system = _build_system_instructions(has_doc)

    st.session_state["chat_last_system_text"] = str(system or "")
    st.session_state["chat_last_prompt_text"] = str(prompt or "")

    st.session_state.chat_last_in_tok = None
    st.session_state.chat_last_out_tok = None
    st.session_state.chat_last_cost_obj = None

    mk = str(st.session_state.get("chat_model_key") or DEFAULT_TEXT_MODEL_KEY)
    provider, model = _parse_model_key(mk)

    st.session_state.chat_last_model = str(model)
    st.session_state.chat_last_provider = str(provider)

    try:
        with busy_run(
            projects_root=PROJECTS_ROOT,
            user_sub=str(sub),
            app_name=str(APP_NAME),
            page_name=str(PAGE_NAME),
            task_type="text",
            provider=str(provider),
            model=str(model),
            meta={
                "feature": "ai_chat",
                "action": "chat_turn",
                "has_doc_context": bool(has_doc),
                "history_turns": int(len(st.session_state.chat_messages)),
                "prompt_chars": int(len(prompt)),
            },
        ) as br:
            with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                res = call_text(
                    provider=str(provider),
                    model=str(model),
                    prompt=str(prompt),
                    system=str(system),
                    temperature=None,
                    max_output_tokens=int(st.session_state.get("chat_max_output_tokens") or 0),
                    extra=None,
                )

            answer = (getattr(res, "text", "") or "").strip()

            if not answer:
                st.error("å›ç­”ãŒç©ºã§ã—ãŸã€‚")
                br.add_finish_meta(note="empty")
                st.stop()

            pp = apply_text_result_to_busy(
                br=br,
                res=res,
                extract_text_in_out_tokens=extract_text_in_out_tokens,
                note_ok="ok",
                note_no_usage="no_usage",
                note_no_cost="no_cost",
            )

            st.session_state.chat_last_in_tok = pp.in_tokens
            st.session_state.chat_last_out_tok = pp.out_tokens
            st.session_state.chat_last_cost_obj = pp.cost_obj
            st.session_state.chat_last_note = str(pp.note or "")

            br.add_finish_meta(note=str(pp.note or "ok"))
            st.session_state.chat_last_run_id = br.run_id

    except Exception as e:
        st.error(f"AIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    st.session_state.chat_messages.append({"role": "assistant", "content": answer})

    st.session_state.chat_draft_key = next_draft_key_value
    st.rerun()

# ============================================================
# 3) ç›´è¿‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬â€œé¡”â€ï¼štokens / cost / runï¼‰
# ============================================================
last_run_id = str(st.session_state.get("chat_last_run_id") or "").strip()
last_model = str(st.session_state.get("chat_last_model") or "").strip()

in_tok = st.session_state.get("chat_last_in_tok")
out_tok = st.session_state.get("chat_last_out_tok")
cost_obj = st.session_state.get("chat_last_cost_obj")
note = str(st.session_state.get("chat_last_note") or "")

if not last_run_id:
    st.caption("ï¼ˆã¾ã å®Ÿè¡ŒãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
else:
    render_run_summary_compact(
        projects_root=PROJECTS_ROOT,
        run_id=last_run_id,
        model=last_model,
        in_tokens=(int(in_tok) if isinstance(in_tok, int) else None),
        out_tokens=(int(out_tok) if isinstance(out_tok, int) else None),
        cost=cost_obj,
        note=note,
        show_divider=True,
    )
