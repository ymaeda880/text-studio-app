# -*- coding: utf-8 -*-
# pages/43_é æŠ½å‡º.py
# å„PDFãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«èµ°æŸ»ã—ã€
#  ã€Œè¡Œå˜ç‹¬ã®é ãƒ©ãƒ™ãƒ«ã€ã‚’é«˜ã€…1ã¤æŠ½å‡º â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯ï¼ˆseq / chap / seriesï¼‰
#
# ä¾‹ï¼‰
#   - ç´”æ•°å­—: 12
#   - ç« -é : 2-1, 3-10-2
#   - ã‚·ãƒªãƒ¼ã‚ºèª+ç•ªå·: è³‡æ–™1, è³‡æ–™-1, è³‡æ–™ 1, åºï¼1, (è³‡æ–™)12, ï¼»åºï¼½-3
#
# â€» å›³ãƒ»è¡¨ã®æŠ½å‡ºæ©Ÿèƒ½ã¯æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Œå…¨ã«å‰Šé™¤ã—ã¦ã„ã¾ã™ã€‚

from __future__ import annotations
import re, io, tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None


# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ“„ é ãƒ©ãƒ™ãƒ«æŠ½å‡ºï¼ˆ1é =é«˜ã€…1ï¼‰+ é€£ç•ªãƒã‚§ãƒƒã‚¯", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ é ãƒ©ãƒ™ãƒ«æŠ½å‡ºï¼ˆ1é =é«˜ã€…1ï¼‰â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ æŠ½å‡ºãƒ»é€£ç•ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)

if not uploaded or not run:
    st.stop()

if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()


# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_text_per_page(pdf_path: Path) -> List[str]:
    """PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã—ã¦è¿”ã™ã€‚PyMuPDFå„ªå…ˆã€ãªã‘ã‚Œã°pdfplumberã€‚"""
    texts: List[str] = []
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        for p in doc:
            texts.append(p.get_text("text") or "")
    else:
        with pdfplumber.open(str(pdf_path)) as pdf:
            for p in pdf.pages:
                texts.append(p.extract_text() or "")
    return texts

with tempfile.TemporaryDirectory() as td:
    td = Path(td)
    pdf_path = td / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")


# =========================
# æ­£è¦åŒ–ãƒ»ãƒ©ãƒ™ãƒ«åˆ¤å®šã«ä½¿ã†åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
# =========================

# HY:
# å„ç¨®ã€Œãƒã‚¤ãƒ•ãƒ³ï¼ˆ-ï¼‰ã€ã‚„ã€Œé•·éŸ³ï¼ˆãƒ¼ï¼‰ã€ã‚’ã²ã¨ã¾ã¨ã‚ã«æ‰±ã†ã€‚
# ä¾‹: -, â€, â€’, â€“, â€”, â€•, âˆ’, ï¼, ãƒ¼
HY  = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D\u30FC]"

# NUM:
# åŠè§’ãƒ»å…¨è§’ã®æ•°å­—ã‚’ã¾ã¨ã‚ã¦èªè­˜ã€‚
NUM = r"[0-9ï¼-ï¼™]+"

# ALPHAJP:
# è‹±å­—ãƒ»ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ã‚’åŒ…æ‹¬ï¼ˆã‚·ãƒªãƒ¼ã‚ºèªã«åˆ©ç”¨ï¼‰ã€‚
ALPHAJP = r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]+"

# è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆâ€¦â€¦ãƒ»ï½¥ãƒ»ç­‰ï¼‰ã‚’å‰Šã‚‹ãŸã‚ã®å®šç¾©ã€‚
LEADER_CHARS_CLASS = r"[\.ï¼ãƒ»ï½¥â€¦â€§ï½¡]"
LEADERS_SPACED     = rf"(?:\s*{LEADER_CHARS_CLASS}\s*){{3,}}"


# =========================
# æ–‡å­—æ­£è¦åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def z2h_numhy(s: str) -> str:
    """
    å…¨è§’æ•°å­—/æ‹¬å¼§/è§’æ‹¬å¼§ã‚’åŠè§’åŒ–ã—ã€å„ç¨®ãƒã‚¤ãƒ•ãƒ³é¡ã‚’ '-' ã«çµ±ä¸€ã€‚
    """
    s = (s or "").replace("\u3000", " ")  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹â†’åŠè§’
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼»ï¼½ï½›ï½", "0123456789()[]{}"))
    return re.sub(HY, "-", s)

def normalize_strict(s: str) -> str:
    """
    è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼å‰Šé™¤ãƒ»ç©ºç™½åœ§ç¸®ãªã©ã®è¡Œæ­£è¦åŒ–ã€‚
    """
    s = z2h_numhy(s)
    s = re.sub(rf"\s*{LEADERS_SPACED}\s*$", "", s)  # æœ«å°¾ã®â€¦â€¦ãªã©ã‚’å‰Šé™¤
    s = re.sub(r"[ \t]+", " ", s)                   # é€£ç¶šç©ºç™½ã‚’1å€‹ã¸
    return s.strip()


# =========================
# é ãƒ©ãƒ™ãƒ«æ¤œå‡ºç”¨ã®æ­£è¦è¡¨ç¾
# =========================
def build_label_line_regex_mixed() -> re.Pattern:
    """
    è¡Œå˜ç‹¬ã§ç¾ã‚Œã‚‹é ãƒ©ãƒ™ãƒ«ï¼ˆæ•°å­— / ç« -é  / ã‚·ãƒªãƒ¼ã‚º+æ•°å­—ï¼‰ã‚’æ¤œå‡ºã€‚
    ä¾‹: "12", "2-1", "3-10-2", "è³‡æ–™1", "è³‡æ–™-1", "è³‡æ–™ 1", "åºï¼1", "(è³‡æ–™)12", "ï¼»åºï¼½-3"
        å…ˆé ­ã® "p." / "page" ã‚‚ä»»æ„ã§è¨±å®¹ã€‚
    """
    core_seq    = r"[0-9ï¼-ï¼™]{1,6}"                # 12
    core_chap   = rf"{NUM}(?:\s*{HY}\s*{NUM})+"     # 2-1, 3-10-2ï¼ˆç©ºç™½OKï¼‰
    series_word = rf"[ï¼ˆ(ï¼»\[]?{ALPHAJP}[ï¼‰)\]ï¼½]?"  # (è³‡æ–™) / ï¼»åºï¼½ ãªã©
    SEP_OPT     = rf"(?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?"  # ãƒã‚¤ãƒ•ãƒ³/ãƒ‰ãƒƒãƒˆ/ç©ºç™½/çœç•¥
    core_series = rf"{series_word}{SEP_OPT}{NUM}"
    core = rf"(?:{core_seq}|{core_chap}|{core_series})"

    return re.compile(
        rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$",
        re.MULTILINE
    )

LABEL_LINE_RE = build_label_line_regex_mixed()


# =========================
# 1ãƒšãƒ¼ã‚¸=é«˜ã€…1ãƒ©ãƒ™ãƒ«æŠ½å‡º
# =========================
def extract_single_page_label(page_text: str) -> Tuple[Optional[str], Optional[str]]:
    """
    1ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€è¡Œå˜ç‹¬ã®é ãƒ©ãƒ™ãƒ«ã‚’é«˜ã€…1ã¤æŠ½å‡ºã€‚
    æˆ»ã‚Šå€¤: (label or None, matched_line or None)
    """
    if not page_text:
        return None, None
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        s = normalize_strict(raw)
        if not s:
            continue
        m = LABEL_LINE_RE.match(s)
        if m:
            return z2h_numhy(m.group("label")), raw
    return None, None


# =========================
# é€£ç•ªãƒã‚§ãƒƒã‚¯ï¼ˆseq/chap/seriesï¼‰
# =========================
def _parse_label_kind(label: str) -> Tuple[str, Any]:
    """
    ãƒ©ãƒ™ãƒ«ã‚’ seq / chap / series / unknown ã«åˆ†é¡ã—ã€æ¯”è¼ƒç”¨ã®å€¤ã‚’è¿”ã™ã€‚
    """
    lab = z2h_numhy(label)
    lab_chap = re.sub(r"\s*-\s*", "-", lab)

    # ç´”æ•°å­—
    if re.fullmatch(r"[0-9]+", lab_chap):
        return "seq", int(lab_chap)

    # ç« -é ï¼ˆ2-1 / 3-10-2ï¼‰
    if re.fullmatch(r"[0-9]+(?:-[0-9]+)+", lab_chap):
        return "chap", [int(p) for p in lab_chap.split("-")]

    # ã‚·ãƒªãƒ¼ã‚ºèª + æ•°å­—
    series_pat = re.compile(
        rf"""^
        [ï¼ˆ(ï¼»\[]?           # é–‹ãã‚«ãƒƒã‚³ä»»æ„
        ({ALPHAJP})          # ã‚·ãƒªãƒ¼ã‚ºèª
        [ï¼‰)\]ï¼½]?           # é–‰ã˜ã‚«ãƒƒã‚³ä»»æ„
        (?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?  # åŒºåˆ‡ã‚Š or ç©ºç™½ or çœç•¥
        ([0-9]+)
        $""", re.X
    )
    m = series_pat.fullmatch(lab_chap)
    if m:
        return "series", (m.group(1), int(m.group(2)))

    return "unknown", None


def valid_and_reason_auto(label: str, prev_ok: Optional[str]) -> Tuple[bool, str]:
    """
    è¦‹ã¤ã‹ã£ãŸãƒ©ãƒ™ãƒ«åˆ—ã«å¯¾ã—ã¦é€£ç•ªå¦¥å½“æ€§ã‚’åˆ¤å®šã€‚
    """
    k, cur = _parse_label_kind(label)
    if k == "unknown":
        return False, "ä¸æ˜ãªãƒ©ãƒ™ãƒ«å½¢å¼"
    if prev_ok is None:
        return True, ""
    pk, prev = _parse_label_kind(prev_ok)
    if pk == "unknown":
        return True, ""
    if k != pk:
        return True, "å½¢å¼åˆ‡æ›¿"
    if k == "seq":
        return (cur == prev + 1, "" if cur == prev + 1 else "éé€£ç•ª")
    if k == "chap":
        c, p = (cur + [1, 1])[:2]; pc, pp = (prev + [1, 1])[:2]
        ok = (c == pc and p == pp + 1) or (c == pc + 1 and p == 1)
        return (ok, "" if ok else "éé€£ç•ª")
    if k == "series":
        s, n = cur; ps, pn = prev
        if s != ps:
            return True, "å½¢å¼åˆ‡æ›¿"
        return (n == pn + 1, "" if n == pn + 1 else "éé€£ç•ª")
    return True, ""


# =========================
# å®Ÿè¡Œï¼šé ãƒ©ãƒ™ãƒ«æŠ½å‡º â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯
# =========================
rows_page: List[Dict[str, Any]] = []
page_labels: List[Optional[str]] = []

for i, ptxt in enumerate(pages_text, start=1):
    label, matched = extract_single_page_label(ptxt)
    page_labels.append(label)
    rows_page.append({
        "pdf_page": i,
        "page_label": label if label is not None else "-",
        "matched_line": matched if matched is not None else "-",
        "has_label": label is not None,
    })

df_per_page = pd.DataFrame(rows_page)
st.subheader("ğŸ” å„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ï¼ˆ1é =é«˜ã€…1ï¼‰")
st.dataframe(df_per_page, use_container_width=True)

found_labels = [lab for lab in page_labels if lab]
rows_seq: List[Dict[str, Any]] = []
prev_ok: Optional[str] = None

for idx, lab in enumerate(found_labels, start=1):
    ok, reason = valid_and_reason_auto(lab, prev_ok)
    if ok:
        prev_ok = lab
    rows_seq.append({
        "order_in_found": idx,
        "label": lab,
        "valid": ok,
        "reason": "" if ok else reason
    })

df_seq = pd.DataFrame(rows_seq)
st.subheader("âœ… è¦‹ã¤ã‹ã£ãŸé ãƒ©ãƒ™ãƒ«åˆ—ã®é€£ç•ªãƒã‚§ãƒƒã‚¯")
st.dataframe(df_seq if not df_seq.empty else pd.DataFrame(), use_container_width=True)


# =========================
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# =========================
with st.sidebar:
    st.markdown("### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    if not df_per_page.empty:
        buf = io.StringIO(); df_per_page.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ per_page_labels.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="per_page_labels.csv",
                           mime="text/csv",
                           use_container_width=True)
    if not df_seq.empty:
        buf = io.StringIO(); df_seq.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ label_sequence_check.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="label_sequence_check.csv",
                           mime="text/csv",
                           use_container_width=True)


# =========================
# ãƒ‡ãƒãƒƒã‚°
# =========================
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug")
    st.code(f"LABEL_LINE_RE = {LABEL_LINE_RE.pattern}")
