# pages/44_å›³è¡¨æŠ½å‡º.py
# ç›®çš„ï¼š
#   PDFãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œå›³/è¡¨/å›³è¡¨ã€ã®
#   â‘  è¡Œå˜ç‹¬ã®è¦‹å‡ºã—ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰
#   â‘¡ æœ¬æ–‡ä¸­ã®å‚ç…§ï¼ˆè¡Œé€”ä¸­ã®è¨€åŠï¼‰
# ã‚’ â€œ50_æ­£è¦è¡¨ç¾ãƒ†ã‚¹ãƒˆâ€ ã¨åŒã˜åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ1)è¡Œé ­/2)ç›´å¾Œã®åŠ©è©/3)å¥ç‚¹ï¼‰ã§åˆ†é›¢æŠ½å‡ºã€‚
# ã•ã‚‰ã«å„PDFãƒšãƒ¼ã‚¸ã®ã€Œé ãƒ©ãƒ™ãƒ«ï¼ˆè¡Œå˜ç‹¬ã®ãƒšãƒ¼ã‚¸ç•ªå·/ç« -é /è³‡æ–™1ç­‰ï¼‰ã€ã‚‚æŠ½å‡ºã—ã€
# è¦‹å‡ºã—ãƒ»å‚ç…§ã®å‡ºåŠ›ã« page_label åˆ—ã¨ã—ã¦ä½µè¨˜ã™ã‚‹ã€‚

from __future__ import annotations
import io
import re
import tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ–¼ï¸ å›³è¡¨ æŠ½å‡ºï¼ˆè¡Œé ­/åŠ©è©/å¥ç‚¹ãƒ«ãƒ¼ãƒ« + é ãƒ©ãƒ™ãƒ«ï¼‰", page_icon="ğŸ–¼ï¸", layout="wide")
st.title("ğŸ–¼ï¸ å›³è¡¨ æŠ½å‡º â€” ã‚¿ã‚¤ãƒˆãƒ«/å‚ç…§ï¼ˆè¡Œé ­ãƒ»ç›´å¾ŒåŠ©è©ãƒ»å¥ç‚¹ãƒ«ãƒ¼ãƒ«ï¼‰ï¼‹ é ãƒ©ãƒ™ãƒ«ä½µè¨˜")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ è§£æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    ctx_chars  = st.slider("å‚ç…§ã®å‰å¾Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—æ•°", 10, 200, 40, 5)
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)

if not uploaded or not run:
    st.stop()

if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()

# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_text_per_page(pdf_path: Path) -> List[str]:
    """PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã—ã¦è¿”ã™ã€‚PyMuPDFå„ªå…ˆã€ãªã‘ã‚Œã°pdfplumberã€‚"""
    texts: List[str] = []
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        for p in doc:
            texts.append(p.get_text("text") or "")
    else:
        with pdfplumber.open(str(pdf_path)) as pdf:
            for p in pdf.pages:
                texts.append(p.extract_text() or "")
    return texts

with tempfile.TemporaryDirectory() as td:
    td = Path(td)
    pdf_path = td / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")

# =========================
# æ­£è¦åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå…±é€šï¼‰
# =========================
HY  = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D\u30FC]"  # å„ç¨®ãƒã‚¤ãƒ•ãƒ³/é•·éŸ³
NUM = r"[0-9ï¼-ï¼™]+"
ALPHAJP = r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]+"  # æ—¥æœ¬èªï¼‹è‹±å­—ï¼ˆã‚·ãƒªãƒ¼ã‚ºèªï¼‰

LEADER_CHARS_CLASS = r"[\.ï¼ãƒ»ï½¥â€¦â€§ï½¡]"
LEADERS_SPACED     = rf"(?:\s*{LEADER_CHARS_CLASS}\s*){{3,}}"

def z2h_numhy(s: str) -> str:
    """å…¨è§’æ•°å­—/è¨˜å·â†’åŠè§’ã€å„ç¨®ãƒã‚¤ãƒ•ãƒ³é¡â†’ '-' ã«çµ±ä¸€ã€‚"""
    s = (s or "").replace("\u3000", " ")
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼»ï¼½ï½›ï½", "0123456789()[]{}"))
    return re.sub(HY, "-", s)

def normalize_strict(s: str) -> str:
    """è¡Œå˜ä½ã®æ­£è¦åŒ–ï¼ˆãƒªãƒ¼ãƒ€ãƒ¼å‰Šé™¤ãƒ»ç©ºç™½åœ§ç¸®ï¼‰ã€‚"""
    s = z2h_numhy(s)
    s = re.sub(rf"\s*{LEADERS_SPACED}\s*$", "", s)  # è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼åˆ—ã‚’å‰Šé™¤
    s = re.sub(r"[ \t]+", " ", s)                   # é€£ç¶šç©ºç™½â†’1ã¤
    return s.strip()

# =========================
# é ãƒ©ãƒ™ãƒ« æŠ½å‡ºï¼ˆ1é =é«˜ã€…1ï¼‰
# =========================
def build_label_line_regex_mixed() -> re.Pattern:
    """
    è¡Œå˜ç‹¬ã§ç¾ã‚Œã‚‹é ãƒ©ãƒ™ãƒ«ï¼ˆæ•°å­— / ç« -é  / ã‚·ãƒªãƒ¼ã‚ºï¼‹ç•ªå·ï¼‰ã‚’æ¤œå‡ºã€‚
    ä¾‹: "12", "2-1", "3-10-2", "è³‡æ–™1", "(è³‡æ–™)12", "ï¼»åºï¼½-3", "p.12"
    """
    core_seq    = r"[0-9ï¼-ï¼™]{1,6}"                # 12
    core_chap   = rf"{NUM}(?:\s*{HY}\s*{NUM})+"     # 2-1, 3-10-2
    series_word = rf"[ï¼ˆ(ï¼»\[]?{ALPHAJP}[ï¼‰)\]ï¼½]?"  # (è³‡æ–™) / ï¼»åºï¼½
    SEP_OPT     = rf"(?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?"  # ãƒã‚¤ãƒ•ãƒ³/ãƒ‰ãƒƒãƒˆ/ç©ºç™½
    core_series = rf"{series_word}{SEP_OPT}{NUM}"
    core = rf"(?:{core_seq}|{core_chap}|{core_series})"
    return re.compile(rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$", re.MULTILINE)

LABEL_LINE_RE = build_label_line_regex_mixed()

def extract_single_page_label(page_text: str) -> Tuple[Optional[str], Optional[str]]:
    """1ãƒšãƒ¼ã‚¸ã‹ã‚‰è¡Œå˜ç‹¬ã®é ãƒ©ãƒ™ãƒ«ã‚’é«˜ã€…1ã¤æŠ½å‡ºã€‚æˆ»ã‚Šå€¤: (label or None, matched_line or None)"""
    if not page_text:
        return None, None
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        s = normalize_strict(raw)
        if not s:
            continue
        m = LABEL_LINE_RE.match(s)
        if m:
            return z2h_numhy(m.group("label")), raw
    return None, None

# =========================
# 50_æ­£è¦è¡¨ç¾ãƒ†ã‚¹ãƒˆ.py ç›¸å½“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
# =========================
DOT = r"[\.ï¼ãƒ»ï½¥]"         # åŠè§’ãƒ‰ãƒƒãƒˆãƒ»å…¨è§’ãƒ‰ãƒƒãƒˆãƒ»ä¸­é»’ãªã©
NUM_ZH = r"[0-9ï¼-ï¼™]+"     # åŠè§’/å…¨è§’ã®æ•°å­—
NUM_TOKEN = rf"""
(
    {NUM_ZH}                              # å…ˆé ­ã®æ•°å­—
    (?:\s*(?:{DOT}|{HY})\s*{NUM_ZH})*     # . ã‚„ - ã®é€£ç¶š
    |                                     # ã¾ãŸã¯
    [ï¼ˆ(]\s*{NUM_ZH}\s*[ï¼‰)]              # æ‹¬å¼§ã¤ãæ•°å­—
)
"""
EXTRACT_RE = re.compile(
    rf"(?P<kind>å›³è¡¨|å›³|è¡¨)\s*(?P<num>{NUM_TOKEN})",
    re.X
)

def canon_num(num: str) -> str:
    """å›³è¡¨ç•ªå·ã®æ­£è¦åŒ–ï¼šå…¨è§’â†’åŠè§’ã€ï¼ˆ1ï¼‰â†’1ã€å…¨è§’ãƒ‰ãƒƒãƒˆâ†’.ã€ç©ºç™½é™¤å»ã€‚"""
    s = num
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰", "0123456789()"))
    s = re.sub(DOT, ".", s)
    s = re.sub(HY, "-", s)
    s = re.sub(r"[()ï¼ˆï¼‰]", "", s)
    s = re.sub(r"\s*\.\s*", ".", s)
    s = re.sub(r"\s*-\s*", "-", s)
    s = re.sub(r"\s+", "", s)
    return s

def canon_label(kind: str, num: str) -> str:
    return f"{kind}{canon_num(num)}"

# ã€Œregexã€ãŒã‚ã‚Œã°ä½¿ã†ï¼ˆRE2äº’æ›ã®å¾Œæ–¹ãƒ»Unicodeæ‹¡å¼µãªã©ã®ä½™åœ°ï¼‰ï¼ãªã‘ã‚Œã°æ¨™æº–re
try:
    import regex as re2  # pip install regex
except Exception:
    re2 = re

PARTICLES_RE = re2.compile(r"(?:ã«|ã‚’|ã¯|ã¸|ã§|ã¨|ã®|ãªã©|ç­‰|ã¾ãŸã¯|åˆã¯|ãŠã‚ˆã³|åŠã³|ã‹ã¤)")

# =========================
# 1ãƒšãƒ¼ã‚¸å†…ï¼šå›³è¡¨ãƒ’ãƒƒãƒˆã® â€œã‚¿ã‚¤ãƒˆãƒ«/å‚ç…§â€ åˆ¤å®š
# =========================
def judge_hits_in_page(page_text: str, ctx: int) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    EXTRACT_RE ã§æ‹¾ãˆã‚‹å…¨ãƒ’ãƒƒãƒˆã‚’åˆ—æŒ™ã—ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§ã‚¿ã‚¤ãƒˆãƒ«/å‚ç…§ã‚’åˆ†é›¢ã€‚
      (1) å›³è¡¨ç•ªå·ãŒè¡Œé ­ã«ç„¡ã‘ã‚Œã°ã€Œå‚ç…§ã€
      (2) å›³è¡¨ç•ªå·ç›´å¾Œã« {ã«|ã‚’|ã¯|ã¸|ã§|ã¨|ã®|ãªã©|ç­‰|ã¾ãŸã¯|åˆã¯|ãŠã‚ˆã³|åŠã³|ã‹ã¤} ãŒç¶šã‘ã°ã€Œå‚ç…§ã€
      (3) è¡Œå†…ã«å¥ç‚¹ã€Œã€‚ã€ãŒã‚ã‚Œã°ã€Œå‚ç…§ã€
      (4) ãã‚Œä»¥å¤–ã¯ã€Œã‚¿ã‚¤ãƒˆãƒ«ã€
    ã‚¿ã‚¤ãƒˆãƒ«ã¯è¡Œæœ«æ®‹éƒ¨ã‚’â€œè¦‹å‡ºã—ã‚¿ã‚¤ãƒˆãƒ«â€ã¨ã—ã¦æ¡å–ã€‚
    å‚ç…§ã¯å‰å¾Œ ctx æ–‡å­—ã®æ–‡è„ˆã‚’è¿”ã™ã€‚
    """
    captions: List[Dict[str, Any]] = []
    refs: List[Dict[str, Any]] = []

    # æ”¹è¡Œä¿æŒæ–‡å­—åˆ—ã¨è¡Œã‚¹ãƒ‘ãƒ³
    full = page_text.replace("\r\n", "\n").replace("\r", "\n")
    lines_keep = full.splitlines(keepends=True)

    line_spans: List[Tuple[int, int, int, str]] = []  # (lineno, start, end, line_without_newline)
    pos = 0
    for i, seg in enumerate(lines_keep, 1):
        start = pos
        end   = pos + len(seg)
        line_spans.append((i, start, end, seg.rstrip("\r\n")))
        pos = end

    def locate_line(offset: int):
        for lineno, s, e, content in line_spans:
            if s <= offset < e:
                return lineno, s, e, content
        if line_spans:
            return line_spans[-1]
        return 1, 0, len(full), full

    for m in EXTRACT_RE.finditer(full):
        kind = m.group("kind")
        num  = m.group("num")
        raw  = m.group(0)

        lineno, line_start, line_end, line_txt = locate_line(m.start())
        # è¡Œé ­åˆ¤å®šï¼ˆå‰æ–¹ãŒç©ºç™½ã®ã¿ãªã‚‰è¡Œé ­æ‰±ã„ï¼‰
        is_line_head = (full[line_start:m.start()].strip() == "")

        # è¡Œå†…ç›¸å¯¾ä½ç½®
        rel_start = m.start() - line_start
        rel_end   = rel_start + len(raw)

        after_on_line = line_txt[rel_end:] if rel_end <= len(line_txt) else ""

        # (2) ç›´å¾ŒåŠ©è©/æ¥ç¶šèªï¼ˆç©ºç™½ã‚¹ã‚­ãƒƒãƒ—è¨±å®¹ï¼‰
        particle_follow = bool(re2.match(rf"\s*{PARTICLES_RE.pattern}", after_on_line))

        # (3) å¥ç‚¹ã®æœ‰ç„¡
        has_period = ("ã€‚" in line_txt)

        is_reference = (not is_line_head) or particle_follow or has_period

        if is_reference:
            # å‚ç…§ï¼šå‰å¾Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            left  = max(0, m.start() - ctx)
            right = min(len(full), m.end() + ctx)
            pre   = full[left:m.start()]
            post  = full[m.end():right]
            refs.append({
                "è¡Œç•ªå·": lineno,
                "å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ": raw.strip(),
                "å›³è¡¨ç¨®é¡": kind,
                "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
                "å›³è¡¨ã‚­ãƒ¼": canon_label(kind, num),
                "context": f"{pre}{post}",
                "hit": raw,
                "start": m.start(),
                "end": m.end(),
                "åˆ¤å®š": "å‚ç…§",
                "rule(ç†ç”±)": (
                    "è¡Œé ­ã§ãªã„â†’å‚ç…§" if not is_line_head else
                    ("ç›´å¾ŒãŒåŠ©è©/æ¥ç¶šèªâ†’å‚ç…§" if particle_follow else "è¡Œã«å¥ç‚¹ã‚ã‚Šâ†’å‚ç…§")
                ),
                "è¡Œãƒ†ã‚­ã‚¹ãƒˆ": line_txt,
            })
        else:
            # ã‚¿ã‚¤ãƒˆãƒ«ï¼šè¡Œæœ«æ®‹éƒ¨ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦æ¡å–ï¼ˆè¨˜å·ã‚„ç©ºç™½ã‚’é™¤å»ï¼‰
            title_tail = after_on_line
            # å…ˆé ­ã®åŒºåˆ‡ã‚Šè¨˜å·ãƒ»ç©ºç™½ã‚’è½ã¨ã™
            title = re.sub(r"^[\s:ï¼š.\-ï¼ã€ãƒ»]+", "", title_tail).strip()
            captions.append({
                "è¡Œç•ªå·": lineno,
                "å›³è¡¨ç¨®é¡": kind,
                "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
                "å›³è¡¨ã‚­ãƒ¼": canon_label(kind, num),
                "è¦‹å‡ºã—ã‚¿ã‚¤ãƒˆãƒ«": title,
                "matched_line": line_txt,
                "start": m.start(),
                "end": m.end(),
                "åˆ¤å®š": "ã‚¿ã‚¤ãƒˆãƒ«",
                "rule(ç†ç”±)": "ãã®ä»–â†’ã‚¿ã‚¤ãƒˆãƒ«",
            })

    return captions, refs

# =========================
# å…¨ãƒšãƒ¼ã‚¸èµ°æŸ»ï¼ˆé ãƒ©ãƒ™ãƒ« â†’ ã‚¿ã‚¤ãƒˆãƒ«/å‚ç…§ï¼‰
# =========================
# ã¾ãšå„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º
page_labels: List[Optional[str]] = []
per_page_rows: List[Dict[str, Any]] = []
for i, ptxt in enumerate(pages_text, start=1):
    label, matched = extract_single_page_label(ptxt)
    page_labels.append(label)
    per_page_rows.append({
        "pdf_page": i,
        "page_label": label if label else "-",
        "matched_line": matched if matched else "-",
        "has_label": label is not None,
    })
df_per_page_labels = pd.DataFrame(per_page_rows)

# æ¬¡ã« â€œ50ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯â€ ã§ã‚¿ã‚¤ãƒˆãƒ«/å‚ç…§ã‚’æŠ½å‡ºã—ã€page_label ã‚’ä½µè¨˜
caption_rows: List[Dict[str, Any]] = []
ref_rows:     List[Dict[str, Any]] = []

for i, ptxt in enumerate(pages_text, start=1):
    page_label = page_labels[i-1] if i-1 < len(page_labels) and page_labels[i-1] else "-"
    captions, refs = judge_hits_in_page(ptxt, ctx=ctx_chars)

    for h in captions:
        caption_rows.append({
            "pdf_page": i,
            "page_label": page_label,
            **h
        })
    for r in refs:
        ref_rows.append({
            "pdf_page": i,
            "page_label": page_label,
            **r
        })

df_captions = pd.DataFrame(caption_rows)
df_refs     = pd.DataFrame(ref_rows)

# =========================
# è¡¨ç¤º
# =========================
st.subheader("ğŸ“‘ å„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ï¼ˆ1é =é«˜ã€…1ï¼‰")
st.dataframe(df_per_page_labels if not df_per_page_labels.empty else pd.DataFrame(), use_container_width=True)

st.subheader("ğŸ–¼ï¸ è¡Œå˜ç‹¬ã® å›³/è¡¨/å›³è¡¨ è¦‹å‡ºã—ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
st.dataframe(df_captions if not df_captions.empty else pd.DataFrame(), use_container_width=True)

st.subheader("ğŸ”— æœ¬æ–‡ä¸­ã® å›³/è¡¨/å›³è¡¨ å‚ç…§ï¼ˆæ–‡è„ˆã¤ãï¼‰")
st.dataframe(df_refs if not df_refs.empty else pd.DataFrame(), use_container_width=True)

# =========================
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# =========================
with st.sidebar:
    st.markdown("### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    if not df_per_page_labels.empty:
        buf = io.StringIO(); df_per_page_labels.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ per_page_labels.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="per_page_labels.csv",
                           mime="text/csv",
                           use_container_width=True)
    if not df_captions.empty:
        buf = io.StringIO(); df_captions.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ figure_table_captions.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="figure_table_captions.csv",
                           mime="text/csv",
                           use_container_width=True)
    if not df_refs.empty:
        buf = io.StringIO(); df_refs.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ figure_table_references.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="figure_table_references.csv",
                           mime="text/csv",
                           use_container_width=True)

# =========================
# ãƒ‡ãƒãƒƒã‚°
# =========================
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug")
    st.code(f"LABEL_LINE_RE = {LABEL_LINE_RE.pattern}")
    st.code(f"EXTRACT_RE    = {EXTRACT_RE.pattern}")
    st.caption("åˆ¤å®šãƒ«ãƒ¼ãƒ«: è¡Œé ­ã§ãªã„/ç›´å¾Œã«åŠ©è©/è¡Œå†…ã€ã€‚ã€â†’å‚ç…§ã€ãã®ä»–â†’ã‚¿ã‚¤ãƒˆãƒ«")

try:
    import pdfplumber
except Exception:
    pdfplumber = None


# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ–¼ï¸ å›³è¡¨ æŠ½å‡ºï¼ˆè¦‹å‡ºã—/å‚ç…§ åˆ†é›¢ + é ãƒ©ãƒ™ãƒ«ä½µè¨˜ï¼‰", page_icon="ğŸ–¼ï¸", layout="wide")
st.title("ğŸ–¼ï¸ å›³è¡¨ æŠ½å‡º â€” è¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰ï¼å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰ï¼‹ é ãƒ©ãƒ™ãƒ«")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ è§£æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    ctx_chars  = st.slider("å‚ç…§ã®å‰å¾Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—æ•°", 10, 200, 40, 5)
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)

if not uploaded or not run:
    st.stop()

if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()


# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_text_per_page(pdf_path: Path) -> List[str]:
    """PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã—ã¦è¿”ã™ã€‚PyMuPDFå„ªå…ˆã€ãªã‘ã‚Œã°pdfplumberã€‚"""
    texts: List[str] = []
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        for p in doc:
            texts.append(p.get_text("text") or "")
    else:
        with pdfplumber.open(str(pdf_path)) as pdf:
            for p in pdf.pages:
                texts.append(p.extract_text() or "")
    return texts

with tempfile.TemporaryDirectory() as td:
    td = Path(td)
    pdf_path = td / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")


# =========================
# æ­£è¦åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå…±é€šï¼‰
# =========================
# å„ç¨®ãƒã‚¤ãƒ•ãƒ³/é•·éŸ³ã‚’ã¾ã¨ã‚ã‚‹ã‚¯ãƒ©ã‚¹
HY  = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D\u30FC]"
# æ•°å­—ï¼ˆåŠè§’/å…¨è§’ï¼‰
NUM = r"[0-9ï¼-ï¼™]+"
# æ—¥æœ¬èªï¼‹è‹±å­—ï¼ˆã‚·ãƒªãƒ¼ã‚ºèªã«ä½¿ã†ï¼‰
ALPHAJP = r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]+"

# è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆâ€¦â€¦ãƒ»ï½¥ãƒ»ç­‰ï¼‰
LEADER_CHARS_CLASS = r"[\.ï¼ãƒ»ï½¥â€¦â€§ï½¡]"
LEADERS_SPACED     = rf"(?:\s*{LEADER_CHARS_CLASS}\s*){{3,}}"

def z2h_numhy(s: str) -> str:
    """å…¨è§’æ•°å­—/è¨˜å·â†’åŠè§’ã€å„ç¨®ãƒã‚¤ãƒ•ãƒ³é¡â†’ '-' ã«çµ±ä¸€ã€‚"""
    s = (s or "").replace("\u3000", " ")
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼»ï¼½ï½›ï½", "0123456789()[]{}"))
    return re.sub(HY, "-", s)

def normalize_strict(s: str) -> str:
    """è¡Œå˜ä½ã®æ­£è¦åŒ–ï¼ˆãƒªãƒ¼ãƒ€ãƒ¼å‰Šé™¤ãƒ»ç©ºç™½åœ§ç¸®ï¼‰ã€‚"""
    s = z2h_numhy(s)
    s = re.sub(rf"\s*{LEADERS_SPACED}\s*$", "", s)  # è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼åˆ—ã‚’å‰Šé™¤
    s = re.sub(r"[ \t]+", " ", s)                   # é€£ç¶šç©ºç™½ã‚’1ã¤ã«
    return s.strip()


# =========================
# é ãƒ©ãƒ™ãƒ« æŠ½å‡ºï¼ˆ1é =é«˜ã€…1ï¼‰
# =========================
def build_label_line_regex_mixed() -> re.Pattern:
    """
    è¡Œå˜ç‹¬ã§ç¾ã‚Œã‚‹é ãƒ©ãƒ™ãƒ«ï¼ˆæ•°å­— / ç« -é  / ã‚·ãƒªãƒ¼ã‚ºï¼‹ç•ªå·ï¼‰ã‚’æ¤œå‡ºã™ã‚‹æ­£è¦è¡¨ç¾ã€‚
      ä¾‹: "12", "2-1", "3-10-2", "è³‡æ–™1", "è³‡æ–™-1", "è³‡æ–™ 1", "åºï¼1", "(è³‡æ–™)12", "ï¼»åºï¼½-3"
      å…ˆé ­ã® "p." / "page" ã‚‚ä»»æ„ã§è¨±å®¹ã€‚
    """
    core_seq    = r"[0-9ï¼-ï¼™]{1,6}"                # 12
    core_chap   = rf"{NUM}(?:\s*{HY}\s*{NUM})+"     # 2-1, 3-10-2ï¼ˆç©ºç™½OKï¼‰
    series_word = rf"[ï¼ˆ(ï¼»\[]?{ALPHAJP}[ï¼‰)\]ï¼½]?"  # (è³‡æ–™) / ï¼»åºï¼½ ãªã©
    SEP_OPT     = rf"(?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?"  # ãƒã‚¤ãƒ•ãƒ³/ãƒ‰ãƒƒãƒˆ/ç©ºç™½/çœç•¥
    core_series = rf"{series_word}{SEP_OPT}{NUM}"
    core = rf"(?:{core_seq}|{core_chap}|{core_series})"
    return re.compile(rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$", re.MULTILINE)

LABEL_LINE_RE = build_label_line_regex_mixed()

def extract_single_page_label(page_text: str) -> Tuple[Optional[str], Optional[str]]:
    """
    1ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€è¡Œå˜ç‹¬ã®é ãƒ©ãƒ™ãƒ«ã‚’é«˜ã€…1ã¤æŠ½å‡ºã€‚
    æˆ»ã‚Šå€¤: (label or None, matched_line or None)
    """
    if not page_text:
        return None, None
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        s = normalize_strict(raw)
        if not s:
            continue
        m = LABEL_LINE_RE.match(s)
        if m:
            return z2h_numhy(m.group("label")), raw
    return None, None


# =========================
# å›³/è¡¨/å›³è¡¨ ã®æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
# =========================
DOT = r"[\.ï¼ãƒ»ï½¥]"
NUM_ZH = r"[0-9ï¼-ï¼™]+"

# å›³è¡¨ç•ªå·ãƒˆãƒ¼ã‚¯ãƒ³ï¼š
#  ä¾‹ï¼‰3.1-2 / ï¼“ï¼ï¼‘ï¼ï¼’ / 3ãƒ»1-2 / ï¼ˆï¼‘ï¼‰ ç­‰ã®æºã‚Œã‚’å¸å
# ã‚ˆã‚Šå …ç‰¢ãªå›³è¡¨ç•ªå·ãƒˆãƒ¼ã‚¯ãƒ³ï¼š
# ä¾‹: 3.1-1 / 3-2 / 2.1.3-4 / ï¼ˆ1ï¼‰ãªã©ã‚’ã™ã¹ã¦æ‹¾ã†
NUM_TOKEN = rf"""
(
    {NUM_ZH}                                     # å…ˆé ­ã®æ•°å­—
    (?:\s*(?:{DOT}|{HY})\s*{NUM_ZH})*            # . ã‚„ - ã«ã‚ˆã‚‹åŒºåˆ‡ã‚Šã‚’è¤‡æ•°è¨±å®¹
    |                                            # ã¾ãŸã¯
    [ï¼ˆ(]\s*{NUM_ZH}\s*[ï¼‰)]                     # æ‹¬å¼§ã¤ãæ•°å­—
)
"""


# è¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰ã‚’æ‹¾ã†ï¼š
#   ã€Œå›³/è¡¨/å›³è¡¨ + ç•ªå·ã€ã®ç›´å¾Œã«åŠ©è©ã‚„èª­ç‚¹ãªã©ãŒç¶šãè¡Œã¯ â€œæœ¬æ–‡å‚ç…§â€ ã¨ã¿ãªã—ã¦é™¤å¤–ã€‚
#   åŒºåˆ‡ã‚Šï¼ˆ:ï¼š.-ã€ï¼‰ï¼‹ã‚¿ã‚¤ãƒˆãƒ« ã‚‚OKï¼ˆã‚¿ã‚¤ãƒˆãƒ«ç„¡ã—ã§ã‚‚OKï¼‰ã€‚

# è¿½åŠ ï¼šç•ªå·ã®â€œç¶šãâ€ãŒæ®‹ã£ã¦ã„ãªã„ã“ã¨ã‚’è¦æ±‚ã™ã‚‹å…ˆèª­ã¿
AFTER_NUM_CONT_BLOCK = rf"(?!\s*(?:{DOT}|{HY})\s*{NUM_ZH})"

# è¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰
HEADING_RE = re.compile(
    rf"""^
        \s*(?P<kind>å›³è¡¨|å›³|è¡¨)
        \s*(?P<num>{NUM_TOKEN}){AFTER_NUM_CONT_BLOCK}   # â† ã“ã“ãŒãƒã‚¤ãƒ³ãƒˆ
        (?!                          # è¦‹å‡ºã—ã§ã¯ãªã„ï¼ˆå‚ç…§ã£ã½ã„ï¼‰ç¶šãã‚’ç¦æ­¢
            [ ã€€ã€,ï¼ã€‚]*
            (?:ã«|ã‚’|ã¯|ã¸|ã§|ã¨ã—ã¦|
               ã«ç¤ºã™|ã«ç¤ºã—ãŸ|ã«ãŠã‘ã‚‹|ã«é–¢ã™ã‚‹|
               ã«å¯¾ã™ã‚‹|ã«ã‚ˆã‚‹|ã®|ç­‰)\b
        )
        \s*(?:[:ï¼š.\-ï¼ã€]\s*(?P<title>.+))?\s*$
    """,
    re.X
)

# å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰ã‚’æ‹¾ã†ï¼š
#   è¦‹å‡ºã—è¡Œã«å«ã¾ã‚Œã‚‹å‡ºç¾ã¯å¾Œã§ span é™¤å¤–ã™ã‚‹ã€‚
REF_RE = re.compile(
    rf"(?P<kind>å›³è¡¨|å›³|è¡¨)\s*(?P<num>{NUM_TOKEN})(?![0-9])",
    re.X
)

def canon_num(num: str) -> str:
    """å›³è¡¨ç•ªå·ã®æ­£è¦åŒ–ï¼šå…¨è§’â†’åŠè§’ã€ï¼ˆ1ï¼‰â†’1ã€å…¨è§’ãƒ‰ãƒƒãƒˆâ†’., ä¸­é»’â†’.ã€ç©ºç™½é™¤å»ã€‚"""
    s = z2h_numhy(num)
    s = re.sub(r"[()ï¼ˆï¼‰]", "", s)       # ï¼ˆ1ï¼‰â†’1
    s = re.sub(DOT, ".", s)             # ï¼ãƒ» â†’ .
    s = re.sub(r"\s*\.\s*", ".", s)
    s = re.sub(r"\s*-\s*", "-", s)
    s = re.sub(r"\s+", "", s)
    return s

def canon_label(kind: str, num: str) -> str:
    """å›³è¡¨ã‚­ãƒ¼ï¼ˆä¾‹: 'å›³3.1-2'ï¼‰ã‚’æ­£è¦åŒ–ã—ã¦ç”Ÿæˆã€‚"""
    return f"{kind}{canon_num(num)}"


# =========================
# è¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰æŠ½å‡º
# =========================
def extract_headings_from_page(page_text: str) -> List[Dict[str, Any]]:
    """1ãƒšãƒ¼ã‚¸ã®ä¸­ã‹ã‚‰ã€è¡Œå˜ç‹¬ã®è¦‹å‡ºã—ã‚’æŠ½å‡ºã€‚"""
    out: List[Dict[str, Any]] = []
    lines = page_text.replace("\r\n","\n").replace("\r","\n").split("\n")
    for raw in lines:
        s = normalize_strict(raw)
        if not s:
            continue
        m = HEADING_RE.match(s)
        if not m:
            continue
        kind = m.group("kind")
        num  = m.group("num")
        title= (m.group("title") or "").strip()
        out.append({
            "å›³è¡¨ç¨®é¡": kind,
            "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
            "å›³è¡¨ã‚­ãƒ¼": canon_label(kind, num),
            "è¦‹å‡ºã—ã‚¿ã‚¤ãƒˆãƒ«": title,
            "matched_line": raw,
        })
    return out

def collect_heading_line_spans(page_text: str) -> List[Tuple[int,int]]:
    """è¦‹å‡ºã—è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆç¯„å›²ï¼ˆstart,endï¼‰ã‚’ãƒšãƒ¼ã‚¸å†…ã‚ªãƒ•ã‚»ãƒƒãƒˆã§è¿”ã™ã€‚"""
    spans: List[Tuple[int,int]] = []
    pos = 0
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        line = raw
        s = normalize_strict(line)
        start = pos
        end   = pos + len(line) + 1  # +æ”¹è¡Œ
        if s and HEADING_RE.match(s):
            spans.append((start, end))
        pos = end
    return spans


# =========================
# å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰æŠ½å‡ºï¼ˆè¦‹å‡ºã—è¡Œã¯é™¤å¤–ï¼‰
# =========================
def extract_refs_from_page(page_text: str, ctx: int, heading_spans: List[Tuple[int,int]]) -> List[Dict[str, Any]]:
    """æœ¬æ–‡ä¸­ã®å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰ã‚’æŠ½å‡ºã€‚è¦‹å‡ºã—è¡Œã«å«ã¾ã‚Œã‚‹å‡ºç¾ã¯é™¤å¤–ã€‚"""
    out: List[Dict[str, Any]] = []
    text = page_text.replace("\r\n","\n").replace("\r","\n")

    for m in REF_RE.finditer(text):
        a, b = m.span()
        # è¦‹å‡ºã—è¡Œã®ç¯„å›²å†…ã«ã‚ã‚‹å‡ºç¾ã¯å‚ç…§ã‹ã‚‰é™¤å¤–
        skip = False
        for s, e in heading_spans:
            if a >= s and a < e:
                skip = True
                break
        if skip:
            continue

        kind = m.group("kind")
        num  = m.group("num")
        key  = canon_label(kind, num)

        left  = max(0, a - ctx)
        right = min(len(text), b + ctx)
        pre   = text[left:a]
        hit   = text[a:b]
        post  = text[b:right]

        out.append({
            "å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ": m.group(0),
            "å›³è¡¨ç¨®é¡": kind,
            "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
            "å›³è¡¨ã‚­ãƒ¼": key,
            "context": f"{pre}{post}",  # ãƒ’ãƒƒãƒˆä»¥å¤–ã®å‰å¾Œæ–‡è„ˆ
            "hit": hit,                 # ãƒãƒƒãƒç®‡æ‰€ãã®ã‚‚ã®
            "start": a,
            "end": b,
        })
    return out


# =========================
# å…¨ãƒšãƒ¼ã‚¸èµ°æŸ»ï¼ˆé ãƒ©ãƒ™ãƒ« â†’ è¦‹å‡ºã—/å‚ç…§ï¼‰
# =========================
# ã¾ãšå„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º
page_labels: List[Optional[str]] = []
per_page_rows: List[Dict[str, Any]] = []
for i, ptxt in enumerate(pages_text, start=1):
    label, matched = extract_single_page_label(ptxt)
    page_labels.append(label)
    per_page_rows.append({
        "pdf_page": i,
        "page_label": label if label else "-",
        "matched_line": matched if matched else "-",
        "has_label": label is not None,
    })
df_per_page_labels = pd.DataFrame(per_page_rows)

# æ¬¡ã«å›³è¡¨ è¦‹å‡ºã—/å‚ç…§ã‚’æŠ½å‡ºã—ã€page_label ã‚’ä½µè¨˜
caption_rows: List[Dict[str, Any]] = []
ref_rows:     List[Dict[str, Any]] = []

for i, ptxt in enumerate(pages_text, start=1):
    page_label = page_labels[i-1] if i-1 < len(page_labels) and page_labels[i-1] else "-"
    # è¦‹å‡ºã—
    heads = extract_headings_from_page(ptxt)
    for h in heads:
        caption_rows.append({
            "pdf_page": i,
            "page_label": page_label,  # ä½µè¨˜
            **h
        })
    # å‚ç…§ï¼ˆè¦‹å‡ºã—è¡Œã¯é™¤å¤–ã—ã¦æ‹¾ã†ï¼‰
    spans = collect_heading_line_spans(ptxt)
    refs = extract_refs_from_page(ptxt, ctx=ctx_chars, heading_spans=spans)
    for r in refs:
        ref_rows.append({
            "pdf_page": i,
            "page_label": page_label,  # ä½µè¨˜
            **r
        })

df_captions = pd.DataFrame(caption_rows)
df_refs     = pd.DataFrame(ref_rows)

st.subheader("ğŸ“‘ å„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ï¼ˆ1é =é«˜ã€…1ï¼‰")
st.dataframe(df_per_page_labels if not df_per_page_labels.empty else pd.DataFrame(), use_container_width=True)

st.subheader("ğŸ–¼ï¸ è¡Œå˜ç‹¬ã® å›³/è¡¨/å›³è¡¨ è¦‹å‡ºã—ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
st.dataframe(df_captions if not df_captions.empty else pd.DataFrame(), use_container_width=True)

st.subheader("ğŸ”— æœ¬æ–‡ä¸­ã® å›³/è¡¨/å›³è¡¨ å‚ç…§ï¼ˆæ–‡è„ˆã¤ãï¼‰")
st.dataframe(df_refs if not df_refs.empty else pd.DataFrame(), use_container_width=True)


# =========================
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# =========================
with st.sidebar:
    st.markdown("### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    if not df_per_page_labels.empty:
        buf = io.StringIO(); df_per_page_labels.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ per_page_labels.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="per_page_labels.csv",
                           mime="text/csv",
                           use_container_width=True)
    if not df_captions.empty:
        buf = io.StringIO(); df_captions.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ figure_table_captions.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="figure_table_captions.csv",
                           mime="text/csv",
                           use_container_width=True)
    if not df_refs.empty:
        buf = io.StringIO(); df_refs.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ figure_table_references.csv",
                           data=buf.getvalue().encode("utf-8-sig"),
                           file_name="figure_table_references.csv",
                           mime="text/csv",
                           use_container_width=True)


# =========================
# ãƒ‡ãƒãƒƒã‚°
# =========================
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug")
    st.code(f"LABEL_LINE_RE = {LABEL_LINE_RE.pattern}")
    st.code(f"HEADING_RE    = {HEADING_RE.pattern}")
    st.code(f"REF_RE        = {REF_RE.pattern}")
