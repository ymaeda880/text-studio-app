# -*- coding: utf-8 -*-
# pages/43_é æŠ½å‡º.py â€” å˜ç‹¬è¡Œã®ç‰ˆé¢ãƒ©ãƒ™ãƒ«ã§æŠ½å‡ºé ã‚’ä½œæˆã—ã€é€£ç•ªæ¤œè¨¼ï¼‹å…ƒPDFãƒšãƒ¼ã‚¸ã‚‚è¡¨ç¤º
from __future__ import annotations
import re, io, tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ“ƒ é æŠ½å‡ºï¼‹é€£ç•ªæ¤œè¨¼ï¼ˆPDFãƒšãƒ¼ã‚¸ä»˜ãï¼‰", page_icon="ğŸ“ƒ", layout="wide")
st.title("ğŸ“ƒ é æŠ½å‡ºï¼ˆå˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«ã§åŒºåˆ‡ã‚Šï¼‰ï¼‹ é€£ç•ªæ¤œè¨¼ ï¼‹ å…ƒPDFãƒšãƒ¼ã‚¸è¡¨ç¤º")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ æŠ½å‡ºãƒ»æ¤œè¨¼ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)

if not uploaded or not run:
    st.stop()

if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()

# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_text_per_page(pdf_path: Path) -> List[str]:
    texts: List[str] = []
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        for p in doc:
            texts.append(p.get_text("text") or "")
    else:
        with pdfplumber.open(str(pdf_path)) as pdf:
            for p in pdf.pages:
                texts.append(p.extract_text() or "")
    return texts

with tempfile.TemporaryDirectory() as td:
    td = Path(td)
    pdf_path = td / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")




# =========================
# æ­£è¦åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
HY = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D]"   # å„ç¨®ãƒã‚¤ãƒ•ãƒ³
ALPHAJP = r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]+"               # è‹±å­—/ã‹ãª/æ¼¢å­—

# ãƒªãƒ¼ãƒ€ãƒ¼ç³»ï¼ˆâ€¦â€¦ã‚„ãƒ»ã‚„ãƒ‰ãƒƒãƒˆã®é€£ãªã‚Šï¼‰
LEADER_CHARS_CLASS = r"[\.ï¼ãƒ»ï½¥â€¦â€§ï½¡]"
LEADERS_SPACED = rf"(?:\s*{LEADER_CHARS_CLASS}\s*){{3,}}"

def z2h_numhy(s: str) -> str:
    s = (s or "").replace("\u3000", " ")
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼»ï¼½ï½›ï½", "0123456789()[]{}"))
    return re.sub(HY, "-", s)

def normalize_strict(s: str) -> str:
    s = z2h_numhy(s)
    s = re.sub(rf"\s*{LEADERS_SPACED}\s*$", "", s)  # è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼åˆ—é™¤å»
    s = re.sub(r"[ \t]+", " ", s)                   # é€£ç¶šç©ºç™½ã‚’1ã¤ã¸
    return s.strip()

# =========================
# å˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«ã§æœ¬æ–‡ã‚’åˆ†å‰²ï¼ˆæŠ½å‡ºãƒšãƒ¼ã‚¸ã‚’ä½œã‚‹ï¼‰
#  + å…ƒPDFãƒšãƒ¼ã‚¸ç•ªå·ã®æ¨å®š
# =========================
# ãƒã‚¤ãƒ³ãƒˆï¼šã€Œè¡Œé ­ï½è¡Œæœ«ãŒãƒ©ãƒ™ãƒ«ã ã‘ã€ã«é™å®šã—ã¦ã„ã‚‹ãŸã‚ã€æœ¬æ–‡ã®é€”ä¸­ã«å‡ºã¦ãã‚‹ â€œâ—‹-â—‹â€ ãªã©ãŒèª¤æ¤œå‡ºã•ã‚Œãªã„
def build_label_line_regex_mixed() -> re.Pattern:
    # è¨±å®¹ã™ã‚‹è¡Œå˜ç‹¬ãƒ©ãƒ™ãƒ«ï¼š
    #  (1) é€£ç•ª: 12
    #  (2) ç« -ãƒšãƒ¼ã‚¸: 1-2, 3-10-2
    #  (3) ã‚·ãƒªãƒ¼ã‚º-æ•°å­—: åº-1, è³‡-2, ä»˜-3, A-10 ç­‰
    core_seq    = r"[0-9ï¼-ï¼™]{1,6}"
    core_chap   = rf"[0-9ï¼-ï¼™]+(?:{HY}[0-9ï¼-ï¼™]+)+"
    core_series = rf"{ALPHAJP}{HY}[0-9ï¼-ï¼™]+"
    core = rf"(?:{core_seq}|{core_chap}|{core_series})"
    return re.compile(rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$", re.MULTILINE)

LABEL_LINE_RE = build_label_line_regex_mixed()

# ãƒšãƒ¼ã‚¸å¢ƒç•Œãƒãƒ¼ã‚«ãƒ¼ï¼ˆå…ƒPDFãƒšãƒ¼ã‚¸ nï¼‰
PAGE_MARK_FMT = "\n<<<PAGE:{n}>>>\n"
PAGE_MARK_RE  = re.compile(r"\n<<<PAGE:(\d+)>>>\n")

def join_with_page_marks(pages: List[str]) -> str:
    buf = []
    for i, t in enumerate(pages, start=1):
        buf.append(PAGE_MARK_FMT.format(n=i))
        buf.append(t if t else "")
    return "".join(buf)

def pages_in_slice(txt: str, start: int, end: int) -> List[int]:
    """txt[start:end] ã«å«ã¾ã‚Œã‚‹ PAGE_MARK ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æŠ½å‡º"""
    sub = txt[start:end]
    return [int(m.group(1)) for m in PAGE_MARK_RE.finditer(sub)]

def split_segments_by_label_with_pdfpages(pages_text: List[str]) -> List[Dict[str, Any]]:
    """
    ãƒšãƒ¼ã‚¸å¢ƒç•Œãƒãƒ¼ã‚«ãƒ¼ä»˜ãã§çµåˆ â†’ è¡Œå˜ç‹¬ãƒ©ãƒ™ãƒ«ã§åŒºåˆ‡ã‚Šã€‚
    å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«:
      - page_labelï¼ˆç‰ˆé¢ãƒ©ãƒ™ãƒ«ï¼‰
      - bodyï¼ˆæœ¬æ–‡ã€‚ãƒãƒ¼ã‚«ãƒ¼é™¤å»å¾Œï¼‰
      - pdf_pagesï¼ˆå…ƒPDFã®ãƒšãƒ¼ã‚¸ç¯„å›²ï¼š [start, ..., end]ï¼‰
      - pdf_page_start / pdf_page_end
    ã‚’ä»˜ä¸ã€‚
    """
    all_text_marked = join_with_page_marks(pages_text)
    txt = normalize_strict(all_text_marked.replace("\r\n", "\n").replace("\r", "\n"))

    matches = list(LABEL_LINE_RE.finditer(txt))
    if not matches:
        return []

    def next_nonempty_pos(pos: int) -> int:
        n = pos
        while n < len(txt) and txt[n] == "\n":
            n += 1
        return n

    segs: List[Dict[str, Any]] = []
    for i, m in enumerate(matches):
        label = z2h_numhy(m.group("label"))
        start = next_nonempty_pos(m.end())
        end   = matches[i+1].start() if i+1 < len(matches) else len(txt)
        raw   = txt[start:end].lstrip("\n ")
        # ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å«ã¾ã‚Œã‚‹å…ƒPDFãƒšãƒ¼ã‚¸ã‚’å–å¾—
        pdfs  = pages_in_slice(txt, start, end)
        pdfs  = sorted(set(pdfs))
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã«ãƒãƒ¼ã‚«ãƒ¼ã‚’é™¤å»
        body  = PAGE_MARK_RE.sub("", raw)
        segs.append({
            "page_label": label,
            "body": body,
            "pdf_pages": pdfs,
            "pdf_page_start": (min(pdfs) if pdfs else None),
            "pdf_page_end":   (max(pdfs) if pdfs else None),
        })
    return segs

segments = split_segments_by_label_with_pdfpages(pages_text)



# ==== PDFèª­ã¿è¾¼ã¿ãŒçµ‚ã‚ã£ãŸç›´å¾Œã«è¿½åŠ  ====
# st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")

# === çµåˆå¾Œãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒ ===
if "joined_text" not in st.session_state:
    st.session_state.joined_text = join_with_page_marks(pages_text)

# === expanderã§ç¢ºèªã¨DL ===
with st.expander("ğŸ“„ çµåˆå¾Œãƒ†ã‚­ã‚¹ãƒˆï¼ˆç¢ºèªãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰", expanded=False):
    st.text_area(
        "çµåˆæ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ˆé ­éƒ¨åˆ†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰",
        st.session_state.joined_text[:3000],
        height=250
    )
    st.download_button(
        "ğŸ“¥ çµåˆãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=st.session_state.joined_text.encode("utf-8"),
        file_name="joined_pages_with_marks.txt",
        mime="text/plain",
        use_container_width=True,
    )


# =========================
# è¡¨ç¤ºï¼ˆæ¦‚è¦³ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
# =========================
st.subheader("æŠ½å‡ºãƒšãƒ¼ã‚¸ï¼ˆå˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«ã§åŒºåˆ‡ã‚Šï¼‰â€” æ¦‚è¦³")
if not segments:
    st.warning("å˜ç‹¬è¡Œã®ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãšã€æŠ½å‡ºãƒšãƒ¼ã‚¸ãŒä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    def fmt_pdf_range(s, e):
        if s is None:
            return "-"
        return str(s) if s == e else f"{s}â€“{e}"
    df_segments_overview = pd.DataFrame([{
        "page_label": s["page_label"],
        "pdf_pages": ",".join(map(str, s["pdf_pages"])) if s["pdf_pages"] else "-",
        "pdf_page_range": fmt_pdf_range(s["pdf_page_start"], s["pdf_page_end"]),
        "char_count": len(s["body"]),
        "preview": s["body"][:120].replace("\n"," ") + ("â€¦" if len(s["body"])>120 else "")
    } for s in segments])
    st.dataframe(df_segments_overview, use_container_width=True)

# =========================
# ãƒ©ãƒ™ãƒ«å¦¥å½“æ€§ï¼ˆé€£ç•ªãƒã‚§ãƒƒã‚¯ï¼‰
# =========================
st.subheader("ğŸ“‘ ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«æ¤œè¨¼ï¼ˆé€£ç•ªãƒã‚§ãƒƒã‚¯ï¼‰")

def _parse_label_kind(label: str) -> Tuple[str, Any]:
    lab = z2h_numhy(label)
    if re.fullmatch(r"[0-9]+", lab):
        return "seq", int(lab)
    parts = lab.split("-")
    if len(parts) >= 2 and all(p.isdigit() for p in parts):
        return "chap", [int(p) for p in parts]
    m = re.fullmatch(rf"({ALPHAJP})-([0-9]+)", lab)
    if m:
        return "series", (m.group(1), int(m.group(2)))
    return "unknown", None

def valid_and_reason_auto(label: str, prev_ok: Optional[str]) -> Tuple[bool, str]:
    k, cur = _parse_label_kind(label)
    if k == "unknown":
        return False, "ä¸æ˜ãªãƒ©ãƒ™ãƒ«å½¢å¼"
    if prev_ok is None:
        return True, ""
    pk, prev = _parse_label_kind(prev_ok)
    if pk == "unknown":
        return True, ""
    if k != pk:
        return True, "å½¢å¼åˆ‡æ›¿"
    if k == "seq":
        return (cur == prev + 1, "" if cur == prev + 1 else "éé€£ç•ª")
    if k == "chap":
        c, p = (cur + [1, 1])[:2]; pc, pp = (prev + [1, 1])[:2]
        ok = (c == pc and p == pp + 1) or (c == pc + 1 and p == 1)
        return (ok, "" if ok else "éé€£ç•ª")
    if k == "series":
        s, n = cur; ps, pn = prev
        if s != ps:
            return True, "å½¢å¼åˆ‡æ›¿"
        return (n == pn + 1, "" if n == pn + 1 else "éé€£ç•ª")
    return True, ""

rows_check: List[Dict[str, Any]] = []
prev_ok: Optional[str] = None
for s in segments:
    ok, reason = valid_and_reason_auto(s["page_label"], prev_ok)
    if ok:
        prev_ok = s["page_label"]
    rows_check.append({
        "page_label": s["page_label"],
        "pdf_page_range": (f"{s['pdf_page_start']}â€“{s['pdf_page_end']}" 
                           if s["pdf_page_start"] is not None else "-"),
        "valid": ok,
        "reason": "" if ok else reason,
        "char_count": len(s["body"]),
        "preview": s["body"][:100].replace("\n"," ") + ("â€¦" if len(s["body"])>100 else "")
    })

df_check = pd.DataFrame(rows_check)
st.dataframe(df_check, use_container_width=True)

# ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼ˆä»»æ„ï¼‰
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug")
    st.write({
        "segments_all": len(segments),
        "first_page_label": segments[0]["page_label"] if segments else None,
        "last_page_label": segments[-1]["page_label"] if segments else None,
        "first_pdf_range": (segments[0]["pdf_page_start"], segments[0]["pdf_page_end"]) if segments else None,
        "last_pdf_range":  (segments[-1]["pdf_page_start"], segments[-1]["pdf_page_end"]) if segments else None,
    })
