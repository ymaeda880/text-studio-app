# pages/20_æ ¡æ­£.py â€” è§£æï¼ˆæ ¡æ­£æ–¹é‡ï¼šãƒšãƒ¼ã‚¸/è¡Œ/ç†ç”±ï¼‰â†’ æœ¬æ ¡æ­£
from __future__ import annotations
from io import BytesIO
from typing import List, Tuple
import streamlit as st
from openai import OpenAI

st.set_page_config(page_title="Text Studio / æ ¡æ­£", page_icon="ğŸ“", layout="wide")

MODEL_OPTIONS = ["gpt-5-mini", "gpt-5-nano"]
DEFAULT_MODEL = "gpt-5-mini"

# 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®è¡Œæ•°ï¼ˆ.txt/.docx ã‚’æ®µè½â†’è¡Œã«ã—ãŸä¸Šã§æ“¬ä¼¼ãƒšãƒ¼ã‚¸åˆ†å‰²ï¼‰
LINES_PER_PAGE = 40

if "chat_model" not in st.session_state:
    st.session_state["chat_model"] = DEFAULT_MODEL

with st.sidebar:
    st.header("è¨­å®š")
    st.radio(
        "ğŸ§  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
        MODEL_OPTIONS,
        index=MODEL_OPTIONS.index(st.session_state["chat_model"]),
        key="chat_model",
    )
    keep_formatting = st.checkbox("æ”¹è¡Œãƒ»æ®µè½ã‚’ä¿æŒï¼ˆæœ¬æ ¡æ­£æ™‚ï¼‰", value=True)
    show_report = st.checkbox("æœ¬æ ¡æ­£å¾Œã«ã€ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆè¦ç´„ã€ã‚‚ä»˜ä¸", value=False)
    lpp = st.number_input("ãƒšãƒ¼ã‚¸è¡Œæ•°ï¼ˆè¡¨ç¤ºç”¨ï¼‰", min_value=20, max_value=100, value=LINES_PER_PAGE, step=5)

st.title("ğŸ“ æ ¡æ­£ â€” è§£æï¼ˆãƒšãƒ¼ã‚¸/è¡Œ/ç†ç”±ï¼‰ â†’ æœ¬æ ¡æ­£")

st.write("Wordï¼ˆ.docxï¼‰ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚æœ€åˆã«ã€è§£æã€ãƒœã‚¿ãƒ³ã§**æ ¡æ­£æ–¹é‡**ã‚’ä¸€è¦§è¡¨ç¤ºã—ã¾ã™ã€‚")


# ====== ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ======
def read_txt(file) -> str:
    data = file.read()
    for enc in ("utf-8", "utf-16", "shift_jis", "cp932"):
        try:
            return data.decode(enc)
        except Exception:
            continue
    return data.decode("utf-8", errors="ignore")


def read_docx(file) -> str:
    from docx import Document
    bio = BytesIO(file.read())
    doc = Document(bio)
    texts = [p.text for p in doc.paragraphs]
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                texts.append(cell.text)
    return "\n".join(texts).strip()


def load_text(uploaded_file) -> str:
    name = uploaded_file.name.lower()
    if name.endswith(".txt"):
        return read_txt(uploaded_file)
    elif name.endswith(".docx"):
        return read_docx(uploaded_file)
    else:
        st.error("å¯¾å¿œå½¢å¼ã¯ .txt ã¾ãŸã¯ .docx ã§ã™ã€‚")
        st.stop()


# ====== è¡Œç•ªå·ãƒ»ãƒšãƒ¼ã‚¸ç•ªå·ã®ä»˜ä¸ ======
def to_numbered_lines(raw: str) -> List[str]:
    """
    åŸæ–‡ã‚’è¡Œå˜ä½ã«åˆ†è§£ã—ã€ç©ºè¡Œã‚‚ä¿æŒã€‚ã“ã“ã§ã¯ã™ã§ã« \n åŒºåˆ‡ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã€‚
    """
    lines = raw.replace("\r\n", "\n").replace("\r", "\n").split("\n")
    return lines


def page_and_line(idx: int, lines_per_page: int) -> Tuple[int, int]:
    """
    0å§‹ã¾ã‚Šã®è¡Œindex -> (ãƒšãƒ¼ã‚¸ç•ªå·1å§‹ã¾ã‚Š, è¡Œç•ªå·1å§‹ã¾ã‚Š)
    """
    page = idx // lines_per_page + 1
    line_in_page = idx % lines_per_page + 1
    return page, line_in_page


def render_preview_with_numbers(lines: List[str], lines_per_page: int) -> str:
    """
    ç”»é¢ç”¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ[p:è¡Œ] prefixï¼‰ã‚’ä»˜ã‘ãŸãƒ†ã‚­ã‚¹ãƒˆã€‚
    ä¾‹: [1:01] æœ€åˆã®è¡Œ
    """
    out = []
    for i, t in enumerate(lines):
        p, ln = page_and_line(i, lines_per_page)
        out.append(f"[{p}:{ln:02d}] {t}")
    return "\n".join(out)


# ====== OpenAI å‘¼ã³å‡ºã— ======
def openai_client() -> OpenAI:
    return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


def analyze_issues(model: str, lines: List[str], lines_per_page: int) -> str:
    """
    æ ¡æ­£æ–¹é‡ï¼ˆä½•ã‚’/ã©ã†ç›´ã™ã‹/ç†ç”±ï¼‰ã‚’ Markdownè¡¨ã§è¿”ã™ã€‚
    å¤§ãã„æ–‡æ›¸ã¯ã€Œãƒšãƒ¼ã‚¸å˜ä½ã€ã§åˆ†å‰²ã—ã¦é€æ¬¡è§£æã€‚
    å‡ºåŠ›åˆ—ï¼š| Page | Line | Issue | Original | Suggestion | Reason |
    """
    client = openai_client()
    md_tables: List[str] = []

    total_pages = (len(lines) + lines_per_page - 1) // lines_per_page
    for pg in range(total_pages):
        start = pg * lines_per_page
        end = min((pg + 1) * lines_per_page, len(lines))
        # è©²å½“ãƒšãƒ¼ã‚¸ã®è¡Œã®ã¿ã‚’ã€[p:è¡Œ]ä»˜ãã§æ¸¡ã™
        page_chunk = []
        for i in range(start, end):
            p, ln = page_and_line(i, lines_per_page)
            page_chunk.append(f"[{p}:{ln:02d}] {lines[i]}")
        page_text = "\n".join(page_chunk)

        sys_inst = (
            "ã‚ãªãŸã¯å³å¯†ãªæ—¥æœ¬èªæ ¡æ­£ãƒªãƒ¼ãƒ€ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ç•ªå·ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã€"
            "ã€ä½•ã‚’ã©ã®ã‚ˆã†ã«ç›´ã™ã¹ãã‹ã€ã‚’ã€å…·ä½“çš„ãªç†ç”±ã¨ã¨ã‚‚ã«ä¸€è¦§åŒ–ã—ã¦ãã ã•ã„ã€‚"
            "è¡Œé ­ã® [page:line] ã‚’å¿…ãšå‚ç…§ã—ã¦ä½ç½®ã‚’ç¤ºã—ã€éåº¦ãªæ„è¨³ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
            "åŠ©è©ï¼ˆã¦ã«ãŠã¯ï¼‰ã€ä¸»è¿°ä¸€è‡´ã€å†—é•·ã€é‡è¤‡ã€èªé †ã€èª¤å­—è„±å­—ã€ç”¨èªèª¤ç”¨ã€æ–‡ä½“ã®ä¸çµ±ä¸€ã«ç‰¹ã«æ³¨æ„ã€‚"
            "å‡ºåŠ›ã¯ **Markdownã®è¡¨** ã§ã€åˆ—ã¯æ¬¡ã®é †ï¼šPage | Line | Issue | Original | Suggestion | Reasonã€‚"
            "Original ã¯è©²å½“ç®‡æ‰€ã®çŸ­ã„æŠœç²‹ï¼ˆæœ€å¤§20å­—ï¼‰ã«ç•™ã‚ã¦ãã ã•ã„ã€‚"
        )
        user_msg = f"æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã“ã®ãƒšãƒ¼ã‚¸ã®ã¿ï¼‰ã‚’è§£æã—ã¦ãã ã•ã„ï¼š\n---\n{page_text}"

        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": sys_inst},
                {"role": "user", "content": user_msg},
            ],
        )
        md_tables.append(resp.choices[0].message.content.strip())

    # ãƒšãƒ¼ã‚¸ã”ã¨ã«å°è¦‹å‡ºã—ã‚’ä»˜ã‘ã¦é€£çµ
    out = []
    for i, tbl in enumerate(md_tables, 1):
        out.append(f"#### Page {i}\n\n{tbl}\n")
    return "\n".join(out)


def proofread(model: str, content: str, keep_layout: bool, want_report: bool) -> str:
    """
    æœ¬æ ¡æ­£ã€‚é•·æ–‡ã¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆç´„6000å­—ï¼‰ã—çµåˆã€‚
    """
    client = openai_client()
    CHUNK = 6000
    chunks = [content[i:i+CHUNK] for i in range(0, len(content), CHUNK)] or [content]

    fixed_parts = []
    for chunk in chunks:
        sys_inst = (
            "ã‚ãªãŸã¯å³å¯†ãªæ—¥æœ¬èªæ ¡æ­£è€…ã§ã™ã€‚ä»¥ä¸‹ã‚’å¾¹åº•ã—ã¦ãã ã•ã„ï¼š\n"
            "- ã¦ã«ãŠã¯ã€åŠ©è©ã€ä¸»è¿°ä¸€è‡´ã€èª¤å­—è„±å­—ã€è¡¨è¨˜ã‚†ã‚Œã‚’ä¿®æ­£\n"
            "- ç”¨èªèª¤ç”¨ã®æ˜¯æ­£ãƒ»èªé †ã®è‡ªç„¶åŒ–ï¼ˆæ„å‘³ã¯å¤‰ãˆãªã„ï¼‰\n"
            + ("- æ”¹è¡Œãƒ»æ®µè½ã¯å¯èƒ½ãªé™ã‚Šç¶­æŒ\n" if keep_layout else "")
            + "- å‡ºåŠ›ã¯æ ¡æ­£å¾Œã®æœ¬æ–‡ã®ã¿ï¼ˆå‰ç½®ãä¸è¦ï¼‰"
        )
        user_msg = f"æ¬¡ã®æœ¬æ–‡ã‚’æ ¡æ­£ã—ã¦ãã ã•ã„ï¼š\n---\n{chunk}"

        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": sys_inst},
                {"role": "user", "content": user_msg},
            ],
        )
        fixed_parts.append(resp.choices[0].message.content.strip())

    fixed_text = ("\n\n" if keep_layout else "\n").join(fixed_parts).strip()

    if want_report:
        rep_inst = (
            "æ¬¡ã®åŸæ–‡ã¨æ ¡æ­£å¾Œæœ¬æ–‡ã®å·®åˆ†è¦³ç‚¹ã§ã€ä¸»ãªä¿®æ­£ãƒã‚¤ãƒ³ãƒˆã‚’æœ€å¤§8é …ç›®ã§ç®‡æ¡æ›¸ãã«ã€‚\n"
            "ä¾‹ï¼šåŠ©è©/æ´»ç”¨ã€èªé †ã€å†—é•·/é‡è¤‡ã€èª¤å­—è„±å­—ã€æ–‡ä½“çµ±ä¸€ã€ç”¨èªèª¤ç”¨ãªã©ã€‚"
        )
        rep_user = f"åŸæ–‡:\n{content[:4000]}\n\næ ¡æ­£å¾Œ:\n{fixed_text[:4000]}"
        rep = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": rep_inst},
                {"role": "user", "content": rep_user},
            ],
        )
        fixed_text += f"\n\n---\nã€ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼ˆè¦ç´„ï¼‰ã€‘\n{rep.choices[0].message.content.strip()}"

    return fixed_text


# ====== UI ======
col_u, col_btn1, col_btn2 = st.columns([3, 1, 1])
with col_u:
    up = st.file_uploader(".docx / .txt ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["docx", "txt"])
with col_btn1:
    do_analyze = st.button("â‘  è§£æï¼ˆæ ¡æ­£æ–¹é‡ã‚’è¡¨ç¤ºï¼‰", type="secondary", use_container_width=True, disabled=not up)
with col_btn2:
    do_fix = st.button("â‘¡ æœ¬æ ¡æ­£ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True, disabled=not up)

if up:
    src_text = load_text(up)
    if not src_text.strip():
        st.warning("ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    # è¡Œç•ªå·ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    lines = to_numbered_lines(src_text)
    st.subheader("ğŸ‘€ è¡Œç•ªå·ä»˜ããƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.caption(f"è¡¨ç¤ºä¸Šã®ãƒšãƒ¼ã‚¸è¡Œæ•°: {lpp} è¡Œ/ãƒšãƒ¼ã‚¸ï¼ˆæ“¬ä¼¼å‰²ã‚Šä»˜ã‘ï¼‰")
    st.text_area("åŸæ–‡ï¼ˆç•ªå·ä»˜ããƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰", value=render_preview_with_numbers(lines, lpp), height=260)

    if do_analyze:
        with st.spinner("è§£æä¸­ï¼ˆæ ¡æ­£æ–¹é‡ã‚’æŠ½å‡ºï¼‰â€¦"):
            plan_md = analyze_issues(st.session_state["chat_model"], lines, lpp)
        st.success("è§£æãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸/è¡Œ/ç†ç”±ã¤ãã§æ–¹é‡ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        st.subheader("ğŸ“‹ æ ¡æ­£æ–¹é‡ï¼ˆã¾ãšä½•ã‚’ã©ã†ç›´ã™ã‹ï¼‰")
        st.markdown(plan_md, unsafe_allow_html=False)

    if do_fix:
        with st.spinner("æœ¬æ ¡æ­£ã®å®Ÿè¡Œä¸­â€¦"):
            result = proofread(
                model=st.session_state["chat_model"],
                content=src_text,
                keep_layout=keep_formatting,
                want_report=show_report,
            )
        st.success("æ ¡æ­£å®Œäº†ï¼ä¸‹ã®çµæœã‚’ã‚³ãƒ”ãƒ¼/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
        st.subheader("ğŸ§¾ æ ¡æ­£çµæœ")
        st.text_area("æ ¡æ­£çµæœ", value=result, height=420)
        st.download_button(
            "æ ¡æ­£çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.txt)",
            data=result.encode("utf-8"),
            file_name=f"proofread_{up.name.rsplit('.', 1)[0]}.txt",
            mime="text/plain",
        )
else:
    st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã‚“ã§ã€â‘  è§£æã€â†’ã€â‘¡ æœ¬æ ¡æ­£ã€ã®é †ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
