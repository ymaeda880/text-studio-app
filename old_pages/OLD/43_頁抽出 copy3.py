# -*- coding: utf-8 -*-
# pages/44_é ãƒ©ãƒ™ãƒ«æŠ½å‡º_1é 1ãƒ©ãƒ™ãƒ«.py
# å„PDFãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«èµ°æŸ»ã—ã€
#  1) ã€Œè¡Œå˜ç‹¬ã®é ãƒ©ãƒ™ãƒ«ã€â€¦ é«˜ã€…1ã¤æŠ½å‡º â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯
#  2) ã€Œè¡Œå˜ç‹¬ã® å›³/è¡¨/å›³è¡¨ è¦‹å‡ºã—ã€â€¦ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä¸€è¦§
#  3) ã€Œè¡Œé€”ä¸­ã® å›³/è¡¨/å›³è¡¨ å‚ç…§ã€â€¦ æ–‡è„ˆã¤ãå‚ç…§ä¸€è¦§
#
# â€» å‚ç…§ã¯è¦‹å‡ºã—è¡Œã¨ã¯åˆ†é›¢ã—ã€è¦‹å‡ºã—è¡Œã«å«ã¾ã‚Œã‚‹å‡ºç¾ã¯å‚ç…§å´ã‹ã‚‰é™¤å¤–

from __future__ import annotations
import re, io, tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ“„ é ãƒ©ãƒ™ãƒ« + å›³è¡¨è¦‹å‡ºã—/å‚ç…§ æŠ½å‡º", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ é ãƒ©ãƒ™ãƒ«ï¼ˆ1é =é«˜ã€…1ï¼‰â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯ â†’ å›³è¡¨ è¦‹å‡ºã—/å‚ç…§ï¼ˆåˆ†é›¢ï¼‰")

uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])
run = st.button("â–¶ è§£æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)

with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    show_debug = st.checkbox("å†…éƒ¨æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã‚’è¡¨ç¤º", value=False)
    ctx_chars  = st.slider("å‚ç…§ã®å‰å¾Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—æ•°", 10, 200, 40, 5)

if not uploaded or not run:
    st.stop()

if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()

# =========================
# PDF â†’ ãƒšãƒ¼ã‚¸åˆ¥ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_text_per_page(pdf_path: Path) -> List[str]:
    texts: List[str] = []
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        for p in doc:
            texts.append(p.get_text("text") or "")
    else:
        with pdfplumber.open(str(pdf_path)) as pdf:
            for p in pdf.pages:
                texts.append(p.extract_text() or "")
    return texts

with tempfile.TemporaryDirectory() as td:
    td = Path(td)
    pdf_path = td / "input.pdf"
    pdf_path.write_bytes(uploaded.getvalue())
    pages_text: List[str] = pdf_to_text_per_page(pdf_path)

st.success(f"PDF èª­ã¿è¾¼ã¿å®Œäº†ï¼šãƒšãƒ¼ã‚¸æ•° {len(pages_text)}")

# =========================
# æ­£è¦åŒ–ãƒ»ãƒ©ãƒ™ãƒ«åˆ¤å®šï¼ˆé ãƒ©ãƒ™ãƒ«ç”¨ï¼‰
# =========================
# =========================
# æ­£è¦åŒ–ãƒ»ãƒ©ãƒ™ãƒ«åˆ¤å®šã«ä½¿ã†åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
# =========================

# HY:
# å„ç¨®ã€Œãƒã‚¤ãƒ•ãƒ³ï¼ˆ-ï¼‰ã€ã‚„ã€Œé•·éŸ³ï¼ˆãƒ¼ï¼‰ã€ã‚’ã²ã¨ã¾ã¨ã‚ã«æ‰±ã†ã€‚
# æ–‡æ›¸ã«ã‚ˆã£ã¦ã¯ã€æ™®é€šã®ãƒã‚¤ãƒ•ãƒ³(-)ä»¥å¤–ã«ä»¥ä¸‹ã®ã‚ˆã†ãªé¡ä¼¼è¨˜å·ãŒæ··ã–ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€
# å…¨ã¦ã‚’1ã¤ã®å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã§å¸åã—ã¦ãŠãï¼š
#   \u2010 ã€œ \u2015  : Unicodeã®ç•°ä½“ãƒã‚¤ãƒ•ãƒ³ï¼ˆâ€-â€’â€“â€”â€•ï¼‰
#   \u2212            : æ•°å­¦ç”¨ãƒã‚¤ãƒŠã‚¹è¨˜å·ï¼ˆâˆ’ï¼‰
#   \uFF0D            : å…¨è§’ãƒã‚¤ãƒ•ãƒ³ï¼ˆï¼ï¼‰
#   \u30FC            : é•·éŸ³è¨˜å·ï¼ˆãƒ¼ï¼‰
HY  = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D\u30FC]"  # å„ç¨®ãƒã‚¤ãƒ•ãƒ³/é•·éŸ³

# NUM:
# åŠè§’ãƒ»å…¨è§’ã®æ•°å­—ï¼ˆ0ã€œ9, ï¼ã€œï¼™ï¼‰ã‚’ã¾ã¨ã‚ã¦èªè­˜ã™ã‚‹ã€‚
# ä¾‹: "3", "ï¼‘ï¼’ï¼“" ã®ã©ã¡ã‚‰ã‚‚ä¸€è‡´ã™ã‚‹ã€‚
NUM = r"[0-9ï¼-ï¼™]+"

# ALPHAJP:
# è‹±å­—ï¼ˆAã€œZ, aã€œzï¼‰ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã‚’ã™ã¹ã¦å«ã‚€ã€‚
# ã‚·ãƒªãƒ¼ã‚ºåãƒ»ç« åãƒ»è³‡æ–™åãªã©ï¼ˆä¾‹: "è³‡æ–™", "åº", "Appendix", "è¡¨" ãªã©ï¼‰ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã€‚
ALPHAJP = r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]+"

# LEADER_CHARS_CLASS:
# ã€Œãƒªãƒ¼ãƒ€ãƒ¼ç·šï¼ˆâ€¦â€¦ã‚„ãƒ»ï½¥ãƒ»ãªã©ï¼‰ã€ã®æ§‹æˆæ–‡å­—ã‚’å®šç¾©ã€‚
# è¡Œã®æœ«å°¾ã«ã€Œâ€¦â€¦ã€ã€Œãƒ» ãƒ» ãƒ»ã€ãªã©ãŒä¸¦ã¶å ´åˆã€ãã‚Œã¯è£…é£¾ã‚„åŒºåˆ‡ã‚Šã§ã‚ã‚Šã€
# ãƒ©ãƒ™ãƒ«ã‚„ç•ªå·ã®ä¸€éƒ¨ã§ã¯ãªã„ã®ã§å‰Šé™¤å¯¾è±¡ã«ã™ã‚‹ãŸã‚ã€‚
LEADER_CHARS_CLASS = r"[\.ï¼ãƒ»ï½¥â€¦â€§ï½¡]"

# LEADERS_SPACED:
# ä¸Šè¨˜ã®ãƒªãƒ¼ãƒ€ãƒ¼æ–‡å­—ãŒ3å€‹ä»¥ä¸Šé€£ç¶šã—ã¦ã„ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©ã€‚
# ä¾‹: "ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»", "â€¦ â€¦ â€¦", "ï¼ï¼ï¼" ãªã©ã«ä¸€è‡´ã€‚
# normalize_strict() å†…ã§ã€ã“ã®éƒ¨åˆ†ã‚’è¡Œæœ«ã‹ã‚‰é™¤å»ã—ã¦ã„ã‚‹ã€‚
LEADERS_SPACED = rf"(?:\s*{LEADER_CHARS_CLASS}\s*){{3,}}"


# ========================================
# æ–‡å­—æ­£è¦åŒ–ãƒ»ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
# ========================================

def z2h_numhy(s: str) -> str:
    """
    å…¨è§’æ–‡å­—ã‚„ç‰¹æ®Šãƒã‚¤ãƒ•ãƒ³ã‚’æ­£è¦åŒ–ã—ã¦ã€çµ±ä¸€çš„ãªå½¢å¼ã«å¤‰æ›ã™ã‚‹é–¢æ•°ã€‚

    å‡¦ç†å†…å®¹ï¼š
      1. å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆ\u3000ï¼‰ã‚’åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ›ã€‚
      2. å…¨è§’æ•°å­—ãƒ»æ‹¬å¼§ãƒ»è§’æ‹¬å¼§ãªã©ã‚’åŠè§’ã«å¤‰æ›ã€‚
      3. å„ç¨®ãƒã‚¤ãƒ•ãƒ³é¡ï¼ˆâˆ’, â€”, â€•, ãƒ¼ ãªã©ï¼‰ã‚’åŠè§’ãƒã‚¤ãƒ•ãƒ³ï¼ˆ-ï¼‰ã«çµ±ä¸€ã€‚

    å¼•æ•°:
        s (str): å…¥åŠ›æ–‡å­—åˆ—
    æˆ»ã‚Šå€¤:
        æ­£è¦åŒ–æ¸ˆã¿æ–‡å­—åˆ—ï¼ˆstrï¼‰
    """
    s = (s or "").replace("\u3000", " ")  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹â†’åŠè§’ã‚¹ãƒšãƒ¼ã‚¹
    # å…¨è§’æ•°å­—ãƒ»è¨˜å·ã‚’åŠè§’ã«å¤‰æ›
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼»ï¼½ï½›ï½", "0123456789()[]{}"))
    # å…¨ã¦ã®ç•°ä½“ãƒã‚¤ãƒ•ãƒ³ã‚’ "-" ã«çµ±ä¸€
    return re.sub(HY, "-", s)


def normalize_strict(s: str) -> str:
    """
    è¡Œå˜ä½ã§æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ã—ã€è¦‹å‡ºã—ã‚„ãƒ©ãƒ™ãƒ«æ¤œå‡ºã«ä¸è¦ãªãƒã‚¤ã‚ºã‚’å‰Šé™¤ã™ã‚‹ã€‚

    å‡¦ç†å†…å®¹ï¼š
      1. z2h_numhy() ã§å…¨è§’â†’åŠè§’ãƒ»ãƒã‚¤ãƒ•ãƒ³çµ±ä¸€ã€‚
      2. è¡Œæœ«ã«ä¸¦ã¶ã€Œãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆâ€¦â€¦ã‚„ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ï¼‰ã€ã‚’å‰Šé™¤ã€‚
      3. é€£ç¶šã™ã‚‹ç©ºç™½ãƒ»ã‚¿ãƒ–ã‚’1ã¤ã«åœ§ç¸®ã€‚
      4. å‰å¾Œã®ä½™ç™½ã‚’strip()ã§å‰Šé™¤ã€‚

    ä¾‹:
        "ï¼“ï¼ï¼‘ã€€â€¦â€¦" â†’ "3.1"
        "è³‡æ–™ã€€ï¼‘ã€€ã€€" â†’ "è³‡æ–™ 1"

    å¼•æ•°:
        s (str): è¡Œãƒ†ã‚­ã‚¹ãƒˆ
    æˆ»ã‚Šå€¤:
        æ­£è¦åŒ–æ¸ˆã¿æ–‡å­—åˆ—ï¼ˆstrï¼‰
    """
    s = z2h_numhy(s)
    s = re.sub(rf"\s*{LEADERS_SPACED}\s*$", "", s)  # è¡Œæœ«ã®ãƒªãƒ¼ãƒ€ãƒ¼åˆ—ã‚’å‰Šé™¤
    s = re.sub(r"[ \t]+", " ", s)                   # ç©ºç™½ãƒ»ã‚¿ãƒ–ã‚’1å€‹ã«åœ§ç¸®
    return s.strip()                                # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»


def build_label_line_regex_mixed() -> re.Pattern:
    """
    ã€Œè¡Œå˜ç‹¬ã§ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ã¨è¦‹ãªã›ã‚‹ã€ãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’æ¤œå‡ºã™ã‚‹æ­£è¦è¡¨ç¾ã‚’ç”Ÿæˆã€‚

    å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³ä¾‹ï¼š
        - æ•°å­—ã®ã¿              â†’ "12", "ï¼“"
        - ç« ï¼‹ãƒšãƒ¼ã‚¸å½¢å¼         â†’ "2-1", "3-10-2", "ï¼”ï¼ï¼“"
        - ã‚·ãƒªãƒ¼ã‚ºï¼‹ç•ªå·         â†’ "è³‡æ–™1", "è³‡æ–™-1", "è³‡æ–™ 1", "åºï¼1", "(è³‡æ–™)12", "ï¼»åºï¼½-3"
        - "page 1", "p.2" ãªã©ã‚‚å…ˆé ­ã«ã‚ã‚‹å ´åˆã‚’è¨±å¯

    æ­£è¦è¡¨ç¾ã®è¨­è¨ˆæ„å›³ï¼š
      - è¡Œå…¨ä½“ãŒãƒ©ãƒ™ãƒ«ã¨ã—ã¦ç‹¬ç«‹ã—ã¦ã„ã‚‹ï¼ˆä»–ã®æ–‡è„ˆãŒãªã„ï¼‰ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã€
        ^ ã¨ $ ã§å…¨ä½“ã‚’å›²ã¿ã€MULTILINE ãƒ•ãƒ©ã‚°ã§è¤‡æ•°è¡Œã«å¯¾å¿œã€‚
      - å„ã‚·ãƒªãƒ¼ã‚ºã®èªï¼ˆè³‡æ–™, åº, A, Appendix ãªã©ï¼‰ã¯æ—¥æœ¬èªãƒ»è‹±å­—æ··åœ¨ã«å¯¾å¿œã€‚
      - ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒ‰ãƒƒãƒˆãƒ»ç©ºç™½ãªã©ã®åŒºåˆ‡ã‚Šã‚’æŸ”è»Ÿã«è¨±å®¹ã€‚
      - ç©ºç™½ã ã‘ã§çµã°ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ï¼ˆ"è³‡æ–™ 1"ï¼‰ã‚‚å«ã‚ã‚‹ã€‚

    æˆ»ã‚Šå€¤:
        ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«æ¤œå‡ºç”¨ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿æ­£è¦è¡¨ç¾ï¼ˆre.Patternï¼‰
    """

    # ã€å˜ç´”ãªæ•°å€¤ãƒšãƒ¼ã‚¸ã€‘ ä¾‹: "1", "12", "ï¼“"
    core_seq = r"[0-9ï¼-ï¼™]{1,6}"

    # ã€ç« -ãƒšãƒ¼ã‚¸å½¢å¼ã€‘ ä¾‹: "2-1", "3-10-2", "ï¼”ï¼ï¼“"
    # ç©ºç™½ãƒ»ç•°ä½“ãƒã‚¤ãƒ•ãƒ³ã‚‚æŸ”è»Ÿã«è¨±å®¹
    core_chap = rf"{NUM}(?:\s*{HY}\s*{NUM})+"

    # ã€ã‚·ãƒªãƒ¼ã‚ºä»˜ãå½¢å¼ã€‘ ä¾‹: "è³‡æ–™1", "è³‡æ–™-1", "è³‡æ–™ 1", "åºï¼1", "(è³‡æ–™)12", "ï¼»åºï¼½-3"
    # ãƒ»( )ï¼» ï¼½ ãªã©ã®æ‹¬å¼§ä»˜ãã‚‚è¨±å®¹
    # ãƒ»åŒºåˆ‡ã‚Šã¯ãƒã‚¤ãƒ•ãƒ³/ãƒ‰ãƒƒãƒˆ/ç©ºç™½ã‚’è¨±å¯ï¼ˆã¾ãŸã¯çœç•¥ï¼‰
    series_word = rf"[ï¼ˆ(ï¼»\[]?{ALPHAJP}[ï¼‰)\]ï¼½]?"   # ã‚·ãƒªãƒ¼ã‚ºèªï¼ˆæ—¥æœ¬èªãƒ»è‹±å­—ï¼‰ï¼‹æ‹¬å¼§ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    SEP_OPT     = rf"(?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?"  # åŒºåˆ‡ã‚Šï¼šãƒã‚¤ãƒ•ãƒ³ or ãƒ‰ãƒƒãƒˆ or ç©ºç™½
    core_series = rf"{series_word}{SEP_OPT}{NUM}"

    # ä¸Šè¨˜3ç¨®ã‚’ã¾ã¨ã‚ãŸãƒ‘ã‚¿ãƒ¼ãƒ³
    core = rf"(?:{core_seq}|{core_chap}|{core_series})"

    # ^ ã¨ $ ã§ã€Œè¡Œå˜ç‹¬ã€ã‚’ä¿è¨¼ã€‚page/p. æ¥é ­è¾ã‚‚è¨±å®¹ã€‚
    return re.compile(
        rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$",
        re.MULTILINE
    )


# ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«æ¤œå‡ºç”¨ã®æ­£è¦è¡¨ç¾ã‚’ç”Ÿæˆã—ã¦ä¿æŒ
LABEL_LINE_RE = build_label_line_regex_mixed()


# =========================
# 1ãƒšãƒ¼ã‚¸=é«˜ã€…1ãƒ©ãƒ™ãƒ«æŠ½å‡ºï¼ˆé ãƒ©ãƒ™ãƒ«ï¼‰
# =========================
def extract_single_page_label(page_text: str) -> Tuple[Optional[str], Optional[str]]:
    if not page_text:
        return None, None
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        s = normalize_strict(raw)
        if not s:
            continue
        m = LABEL_LINE_RE.match(s)
        if m:
            return z2h_numhy(m.group("label")), raw
    return None, None

# =========================
# é€£ç•ªãƒã‚§ãƒƒã‚¯ï¼ˆseq/chap/seriesï¼‰
# =========================
def _parse_label_kind(label: str) -> Tuple[str, Any]:
    lab = z2h_numhy(label)
    lab_chap = re.sub(r"\s*-\s*", "-", lab)
    if re.fullmatch(r"[0-9]+", lab_chap):
        return "seq", int(lab_chap)
    if re.fullmatch(r"[0-9]+(?:-[0-9]+)+", lab_chap):
        return "chap", [int(p) for p in lab_chap.split("-")]
    series_pat = re.compile(
        rf"""^
        [ï¼ˆ(ï¼»\[]?           # é–‹ãã‚«ãƒƒã‚³ï¼ˆä»»æ„ï¼‰
        ({ALPHAJP})          # ã‚·ãƒªãƒ¼ã‚ºèª
        [ï¼‰)\]ï¼½]?           # é–‰ã˜ã‚«ãƒƒã‚³ï¼ˆä»»æ„ï¼‰
        (?:\s*(?:{HY}|[\.ï¼ãƒ»ï½¥])\s*|\s+)?  # åŒºåˆ‡ã‚Š or ç©ºç™½ or çœç•¥
        ([0-9]+)
        $""", re.X
    )
    m = series_pat.fullmatch(lab_chap)
    if m:
        return "series", (m.group(1), int(m.group(2)))
    return "unknown", None

def valid_and_reason_auto(label: str, prev_ok: Optional[str]) -> Tuple[bool, str]:
    k, cur = _parse_label_kind(label)
    if k == "unknown":
        return False, "ä¸æ˜ãªãƒ©ãƒ™ãƒ«å½¢å¼"
    if prev_ok is None:
        return True, ""
    pk, prev = _parse_label_kind(prev_ok)
    if pk == "unknown":
        return True, ""
    if k != pk:
        return True, "å½¢å¼åˆ‡æ›¿"
    if k == "seq":
        return (cur == prev + 1, "" if cur == prev + 1 else "éé€£ç•ª")
    if k == "chap":
        c, p = (cur + [1, 1])[:2]; pc, pp = (prev + [1, 1])[:2]
        ok = (c == pc and p == pp + 1) or (c == pc + 1 and p == 1)
        return (ok, "" if ok else "éé€£ç•ª")
    if k == "series":
        s, n = cur; ps, pn = prev
        if s != ps:
            return True, "å½¢å¼åˆ‡æ›¿"
        return (n == pn + 1, "" if n == pn + 1 else "éé€£ç•ª")
    return True, ""

# =========================
# å®Ÿè¡Œï¼šé ãƒ©ãƒ™ãƒ«æŠ½å‡º â†’ é€£ç•ªãƒã‚§ãƒƒã‚¯
# =========================
rows_page: List[Dict[str, Any]] = []
page_labels: List[Optional[str]] = []
for i, ptxt in enumerate(pages_text, start=1):
    label, matched = extract_single_page_label(ptxt)
    page_labels.append(label)
    rows_page.append({
        "pdf_page": i,
        "page_label": label if label is not None else "-",
        "matched_line": matched if matched is not None else "-",
        "has_label": label is not None,
    })

df_per_page = pd.DataFrame(rows_page)
st.subheader("ğŸ” å„ãƒšãƒ¼ã‚¸ã®é ãƒ©ãƒ™ãƒ«ï¼ˆ1é =é«˜ã€…1ï¼‰")
st.dataframe(df_per_page, use_container_width=True)

found_labels = [lab for lab in page_labels if lab]
rows_seq: List[Dict[str, Any]] = []
prev_ok: Optional[str] = None
for idx, lab in enumerate(found_labels, start=1):
    ok, reason = valid_and_reason_auto(lab, prev_ok)
    if ok:
        prev_ok = lab
    rows_seq.append({
        "order_in_found": idx,
        "label": lab,
        "valid": ok,
        "reason": "" if ok else reason
    })
df_seq = pd.DataFrame(rows_seq)
st.subheader("âœ… è¦‹ã¤ã‹ã£ãŸé ãƒ©ãƒ™ãƒ«åˆ—ã®é€£ç•ªãƒã‚§ãƒƒã‚¯")
st.dataframe(df_seq if not df_seq.empty else pd.DataFrame(), use_container_width=True)

# =========================
# å›³/è¡¨/å›³è¡¨ ã®è¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰ã¨ å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰ã‚’åˆ†é›¢æŠ½å‡º
# =========================
DOT = r"[\.ï¼ãƒ»ï½¥]"
NUM_ZH = r"[0-9ï¼-ï¼™]+"

# å›³è¡¨ç•ªå·ãƒˆãƒ¼ã‚¯ãƒ³
NUM_TOKEN = rf"""
(?:{NUM_ZH}(?:\s*{DOT}\s*{NUM_ZH})*(?:\s*-\s*{NUM_ZH})* | [ï¼ˆ(]\s*{NUM_ZH}\s*[ï¼‰)])
"""

# è¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰:
#  - ã€Œå›³/è¡¨/å›³è¡¨ + ç•ªå·ã€ã®ç›´å¾Œã«åŠ©è©ãƒ»èª­ç‚¹ç­‰ãŒç¶šãè¡Œã¯é™¤å¤–ï¼ˆâ‰’æœ¬æ–‡å‚ç…§ï¼‰
#  - åŒºåˆ‡ã‚Šï¼ˆ:ï¼š.-ã€ï¼‰ã®å¾Œã«ä»»æ„ã‚¿ã‚¤ãƒˆãƒ«ã€ã¾ãŸã¯è¡Œæœ«ã§ã‚‚OK
HEADING_RE = re.compile(
    rf"""^
        \s*(?P<kind>å›³è¡¨|å›³|è¡¨)
        \s*(?P<num>{NUM_TOKEN})
        (?!                          # â† è¦‹å‡ºã—ã§ã¯ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
            [ ã€€ã€,ï¼ã€‚]*             # ç©ºç™½ãƒ»å…¨è§’ç©ºç™½ãƒ»èª­ç‚¹ãªã©
            (?:ã«|ã‚’|ã¯|ã¸|ã§|ã¨ã—ã¦|
               ã«ç¤ºã™|ã«ç¤ºã—ãŸ|ã«ãŠã‘ã‚‹|ã«é–¢ã™ã‚‹|
               ã«å¯¾ã™ã‚‹|ã«ã‚ˆã‚‹|ã®|ç­‰)\b
        )
        \s*(?:[:ï¼š.\-ï¼ã€]\s*(?P<title>.+))?\s*$
    """,
    re.X
)

# å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰: å›³/è¡¨/å›³è¡¨ + ç•ªå·ï¼ˆè¦‹å‡ºã—è¡Œã¯å¾Œã§é™¤å¤–ï¼‰
REF_RE = re.compile(
    rf"(?P<kind>å›³è¡¨|å›³|è¡¨)\s*(?P<num>{NUM_TOKEN})(?![0-9])",
    re.X
)

def canon_num(num: str) -> str:
    s = z2h_numhy(num)
    s = re.sub(r"[()ï¼ˆï¼‰]", "", s)       # ï¼ˆ1ï¼‰â†’1
    s = re.sub(DOT, ".", s)             # ï¼ãƒ» â†’ .
    s = re.sub(r"\s*\.\s*", ".", s)
    s = re.sub(r"\s*-\s*", "-", s)
    s = re.sub(r"\s+", "", s)
    return s

def canon_label(kind: str, num: str) -> str:
    return f"{kind}{canon_num(num)}"

def extract_headings_from_page(page_text: str) -> List[Dict[str, Any]]:
    """è¡Œå˜ç‹¬ã®è¦‹å‡ºã—ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã ã‘ã‚’æŠ½å‡º"""
    out: List[Dict[str, Any]] = []
    lines = page_text.replace("\r\n","\n").replace("\r","\n").split("\n")
    for raw in lines:
        s = normalize_strict(raw)
        if not s:
            continue
        m = HEADING_RE.match(s)
        if not m:
            continue
        kind = m.group("kind")
        num  = m.group("num")
        title= (m.group("title") or "").strip()
        out.append({
            "å›³è¡¨ç¨®é¡": kind,
            "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
            "å›³è¡¨ã‚­ãƒ¼": canon_label(kind, num),
            "è¦‹å‡ºã—ã‚¿ã‚¤ãƒˆãƒ«": title,
            "matched_line": raw,
        })
    return out

def collect_heading_line_spans(page_text: str) -> List[Tuple[int,int]]:
    """è¦‹å‡ºã—è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆç¯„å›²ï¼ˆstart,endï¼‰ã‚’ãƒšãƒ¼ã‚¸å†…ã‚ªãƒ•ã‚»ãƒƒãƒˆã§è¿”ã™"""
    spans: List[Tuple[int,int]] = []
    pos = 0
    for raw in page_text.replace("\r\n","\n").replace("\r","\n").split("\n"):
        line = raw
        s = normalize_strict(line)
        start = pos
        end   = pos + len(line) + 1  # +æ”¹è¡Œ
        if s and HEADING_RE.match(s):
            spans.append((start, end))
        pos = end
    return spans

def extract_refs_from_page(page_text: str, ctx: int, heading_spans: List[Tuple[int,int]]) -> List[Dict[str, Any]]:
    """è¦‹å‡ºã—è¡Œã‚’é™¤å¤–ã—ã¦ã€æœ¬æ–‡ä¸­ã®å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰ã‚’æŠ½å‡ºã€‚å‰å¾Œctxæ–‡å­—ã®æ–‡è„ˆã¤ãã€‚"""
    out: List[Dict[str, Any]] = []
    text = page_text.replace("\r\n","\n").replace("\r","\n")
    for m in REF_RE.finditer(text):
        a, b = m.span()
        # è¦‹å‡ºã—è¡Œã«å«ã¾ã‚Œã¦ã„ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
        skip = False
        for s, e in heading_spans:
            if a >= s and a < e:
                skip = True
                break
        if skip:
            continue

        kind = m.group("kind")
        num  = m.group("num")
        key  = canon_label(kind, num)

        left  = max(0, a - ctx)
        right = min(len(text), b + ctx)
        pre   = text[left:a]
        hit   = text[a:b]
        post  = text[b:right]
        # context ã«ã¯å‰å¾Œã‚’å…¥ã‚Œã€ãƒ’ãƒƒãƒˆæ–‡å­—åˆ—ã¯åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ä¿æŒ
        context = f"{pre}{post}"
        out.append({
            "å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ": m.group(0),
            "å›³è¡¨ç¨®é¡": kind,
            "å›³è¡¨ç•ªå·": f"{kind}{z2h_numhy(num)}",
            "å›³è¡¨ã‚­ãƒ¼": key,
            "context": context,
            "hit": hit,
            "start": a,
            "end": b,
        })
    return out

# ===== å…¨ãƒšãƒ¼ã‚¸ã‚’èµ°æŸ»ï¼šè¦‹å‡ºã—ï¼ˆè¡Œå˜ç‹¬ï¼‰ã¨å‚ç…§ï¼ˆè¡Œé€”ä¸­ï¼‰ã‚’åˆ†é›¢ =====
caption_rows: List[Dict[str, Any]] = []
ref_rows: List[Dict[str, Any]] = []

for i, ptxt in enumerate(pages_text, start=1):
    page_label = page_labels[i-1] if i-1 < len(page_labels) and page_labels[i-1] else "-"
    # è¦‹å‡ºã—
    heads = extract_headings_from_page(ptxt)
    for h in heads:
        caption_rows.append({
            "pdf_page": i,
            "page_label": page_label,
            **h
        })
    # å‚ç…§ï¼ˆè¦‹å‡ºã—è¡Œã¯é™¤å¤–ã—ã¦æ‹¾ã†ï¼‰
    spans = collect_heading_line_spans(ptxt)
    refs = extract_refs_from_page(ptxt, ctx=ctx_chars, heading_spans=spans)
    for r in refs:
        ref_rows.append({
            "pdf_page": i,
            "page_label": page_label,
            **r
        })

df_captions = pd.DataFrame(caption_rows)
df_refs     = pd.DataFrame(ref_rows)

st.subheader("ğŸ–¼ï¸ è¡Œå˜ç‹¬ã® å›³/è¡¨/å›³è¡¨ è¦‹å‡ºã—ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
st.dataframe(df_captions if not df_captions.empty else pd.DataFrame(), use_container_width=True)

st.subheader("ğŸ”— æœ¬æ–‡ä¸­ã® å›³/è¡¨/å›³è¡¨ å‚ç…§ï¼ˆæ–‡è„ˆã¤ãï¼‰")
st.dataframe(df_refs if not df_refs.empty else pd.DataFrame(), use_container_width=True)

# =========================
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# =========================
with st.sidebar:
    st.markdown("### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    if not df_per_page.empty:
        buf = io.StringIO(); df_per_page.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ per_page_labels.csv", data=buf.getvalue().encode("utf-8-sig"),
                           file_name="per_page_labels.csv", mime="text/csv", use_container_width=True)
    if not df_seq.empty:
        buf = io.StringIO(); df_seq.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ label_sequence_check.csv", data=buf.getvalue().encode("utf-8-sig"),
                           file_name="label_sequence_check.csv", mime="text/csv", use_container_width=True)
    if not df_captions.empty:
        buf = io.StringIO(); df_captions.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ figure_table_captions.csv", data=buf.getvalue().encode("utf-8-sig"),
                           file_name="figure_table_captions.csv", mime="text/csv", use_container_width=True)
    if not df_refs.empty:
        buf = io.StringIO(); df_refs.to_csv(buf, index=False)
        st.download_button("ğŸ“¥ figure_table_references.csv", data=buf.getvalue().encode("utf-8-sig"),
                           file_name="figure_table_references.csv", mime="text/csv", use_container_width=True)

# =========================
# ãƒ‡ãƒãƒƒã‚°
# =========================
if show_debug:
    st.divider()
    st.markdown("### ğŸ§ª Debug")
    st.code(f"LABEL_LINE_RE = {LABEL_LINE_RE.pattern}")
    st.code(f"HEADING_RE = {HEADING_RE.pattern}\nREF_RE = {REF_RE.pattern}")
