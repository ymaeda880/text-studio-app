# -*- coding: utf-8 -*-
# pages/25_ç›®æ¬¡ãƒã‚§ãƒƒã‚¯_GPT.py  â€” PDFå°‚ç”¨ãƒ»å˜ç‹¬è¡Œãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«æŠ½å‡º â†’ ç›®æ¬¡ãƒã‚§ãƒƒã‚¯ï¼ˆGPTï¼‰
from __future__ import annotations
import io, os, re, tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ¡ã‚¤ãƒ³UI
# =========================
st.set_page_config(page_title="ğŸ“„ ç›´åˆ—ãƒ†ã‚­ã‚¹ãƒˆæ³•ï¼šé ç•ªå·æŠ½å‡ºï¼ˆPDFå°‚ç”¨ï¼‰", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ ç›´åˆ—ãƒ†ã‚­ã‚¹ãƒˆæ³•ï¼šé ç•ªå·æŠ½å‡ºï¼ˆå˜ç‹¬è¡Œã®ã¿ï¼PDFå°‚ç”¨ï¼‰")
st.caption("â€» æŠ½å‡ºã¯ **â€œå˜ç‹¬è¡Œã«ãƒšãƒ¼ã‚¸ç•ªå·ã ã‘ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹è¡Œâ€** ã‚’åŒºåˆ‡ã‚Šã¨ã—ã¦ä½¿ã„ã¾ã™ã€‚æœ¬æ–‡ã«æ··ã–ã‚‹æ•°å­—ã¯ç„¡è¦–ã—ã¾ã™ã€‚")

# â”€â”€ ãƒ¡ã‚¤ãƒ³å´UIï¼ˆPDFã®ã¿ï¼‰
uploaded = st.file_uploader("PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])

c1, c2, c3 = st.columns([1.3, 1.2, 1.5])
with c1:
    scheme = st.radio("ãƒšãƒ¼ã‚¸æ–¹å¼", ["(1) 1, 2, 3, 4, â€¦", "(2) 1-1, 1-2, 2-1, 2-2, â€¦"], index=1, horizontal=True)
with c2:
    join_pages = st.checkbox("å…¨ãƒšãƒ¼ã‚¸é€£çµã§æŠ½å‡ºï¼ˆæ¨å¥¨ï¼‰", value=True)
with c3:
    run = st.button("â–¶ å‡¦ç†é–‹å§‹", type="primary", use_container_width=True)

# â”€â”€ ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šGPTã«æ¸¡ã™æœ¬æ–‡ã®ä¸Šé™æ–‡å­—æ•°ï¼ˆ0ã§å…¨æ–‡ï¼‰
with st.sidebar:
    excerpt_chars = st.number_input(
        "GPTã¸æ¸¡ã™æœ¬æ–‡ã®ä¸Šé™æ–‡å­—æ•°ï¼ˆ0ã§å…¨æ–‡ï¼‰",
        min_value=0, max_value=20000, value=800, step=100,
        help="å„ãƒšãƒ¼ã‚¸æœ¬æ–‡ã®å…ˆé ­ã‹ã‚‰ä½•æ–‡å­—ã¾ã§ã‚’GPTã«æ¸¡ã™ã‹ã€‚0ã§å…¨æ–‡ã€‚"
    )

if not uploaded or not run:
    st.stop()
if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()

# =========================
# PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ
# =========================
def pdf_to_fulltext(pdf_path: Path, join_pages: bool) -> str:
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        pages = [(p.get_text("text") or "") for p in doc]
        return ("\n".join(pages)) if join_pages else ("\n\n---PAGE-BREAK---\n\n".join(pages))
    with pdfplumber.open(str(pdf_path)) as pdf:
        pages = [(p.extract_text() or "") for p in pdf.pages]
        return ("\n".join(pages)) if join_pages else ("\n\n---PAGE-BREAK---\n\n".join(pages))

with st.spinner("PDF ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­â€¦"):
    with tempfile.TemporaryDirectory() as td:
        td = Path(td)
        pdf_path = td / "input.pdf"
        pdf_path.write_bytes(uploaded.getvalue())
        fulltext = pdf_to_fulltext(pdf_path, join_pages=join_pages)
st.success("ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†ï¼ˆå…¥åŠ›: pdfï¼‰")

# =========================
# å˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«æ¤œå‡ºï¼ˆæ–¹å¼åˆ¥ï¼‰ï¼‹ å¹´ã£ã½ã„é™¤å¤– + é€£ç•ªãƒã‚§ãƒƒã‚¯
# =========================
HY = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D]"  # å„ç¨®ãƒã‚¤ãƒ•ãƒ³
def z2h_numhy(s: str) -> str:
    s = s.replace("\u3000", " ")
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789"))
    return re.sub(HY, "-", s)

def build_label_line_regex(scheme: str) -> re.Pattern:
    if scheme.startswith("(1)"):
        core = r"[0-9ï¼-ï¼™]{1,6}"               # é€£ç•ª
    else:
        core = rf"[0-9ï¼-ï¼™]+(?:{HY}[0-9ï¼-ï¼™]+)+"  # ç« -ãƒšãƒ¼ã‚¸ï¼ˆè¤‡åˆå¯ï¼‰
    return re.compile(rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$", re.MULTILINE)

LABEL_LINE_RE = build_label_line_regex(scheme)

def valid_and_reason(label: str, scheme: str, prev_ok: Optional[str]) -> Tuple[bool, str]:
    """
    ãƒ©ãƒ™ãƒ«ã‚’ã€Œãƒšãƒ¼ã‚¸ã¨ã—ã¦æ¡ç”¨ã™ã‚‹ã‹ã€ã‚’åˆ¤å®šã€‚
    - æ–¹å¼(2)ï¼šå…ˆé ­ãŒ >=100ï¼ˆä¾‹: 2018-3ï¼‰ã¯ â€œå¹´ã£ã½ã„â€ ã¨ã—ã¦ä¸æ¡ç”¨
    - é€£ç•ªãƒã‚§ãƒƒã‚¯ï¼šå‰ã®ã€Œæ¡ç”¨ãƒ©ãƒ™ãƒ«ã€ã¨ã®é€£ç¶šæ€§ã‚’ç¢ºèª
      * (1) n ãŒ prev+1 ãªã‚‰æ¡ç”¨ã€‚prev ãŒç„¡ã„æœ€åˆã¯æ¡ç”¨ã€‚
      * (2) chap-page å½¢å¼ï¼š (c,p) ãŒ (c, prev_p+1) ã‹ (c+1, 1) ãªã‚‰æ¡ç”¨
    - é€£ç¶šã§ãªã„å ´åˆã¯ä¸æ¡ç”¨ã«ã—ã€ç†ç”±ã‚’è¿”ã™ï¼ˆè¡¨ã«ã¯æ®‹ã™ï¼‰
    """
    if scheme.startswith("(1)"):
        try:
            n = int(label)
        except Exception:
            return False, "é€£ç•ªå½¢å¼ã§æ•°å€¤åŒ–ã§ããªã„"
        if prev_ok is None:
            return True, ""
        try:
            prev = int(prev_ok)
        except Exception:
            return True, ""
        if n == prev + 1:
            return True, ""
        else:
            return False, "éé€£ç•ªï¼ˆé€£ç¶šã—ã¦ã„ãªã„ï¼‰"
    else:
        parts = label.split("-")
        if not (len(parts) >= 2 and all(p.isdigit() for p in parts)):
            return False, "ç« -ãƒšãƒ¼ã‚¸å½¢å¼ã§ãªã„"
        chap = int(parts[0])
        if chap >= 100:
            return False, "å¹´ã£ã½ã„ç« ç•ªå·ï¼ˆä¾‹: 2018-3ï¼‰"
        page_n = int(parts[1])
        if prev_ok is None:
            return True, ""
        pparts = prev_ok.split("-")
        if not (len(pparts) >= 2 and all(p.isdigit() for p in pparts)):
            return True, ""
        pchap, ppage = int(pparts[0]), int(pparts[1])
        if (chap == pchap and page_n == ppage + 1) or (chap == pchap + 1 and page_n == 1):
            return True, ""
        else:
            return False, "éé€£ç•ªï¼ˆé€£ç¶šã—ã¦ã„ãªã„ï¼‰"

def split_by_singleline_labels(fulltext: str, scheme: str) -> List[Dict[str, Any]]:
    """
    å˜ç‹¬è¡Œã®ãƒ©ãƒ™ãƒ«ã ã‘ã§åŒºåˆ‡ã‚‹ã€‚
    - ç„¡åŠ¹/éé€£ç•ªã¯ is_page=False, reason ã«ç†ç”±ã‚’å…¥ã‚Œã¦è¡¨ã«ã¯æ®‹ã™
    - is_page=True ã®ã‚‚ã®ã ã‘ã‚’ã€Œå¾Œå·¥ç¨‹ã«ä½¿ç”¨ã€ã§ãã‚‹
    """
    if not fulltext:
        return []
    txt = z2h_numhy(fulltext.replace("\r\n", "\n").replace("\r", "\n"))

    matches = list(LABEL_LINE_RE.finditer(txt))
    if not matches:
        return []

    rows: List[Dict[str, Any]] = []

    def next_nonempty_pos(pos: int) -> int:
        n = pos
        while n < len(txt) and txt[n] == "\n":
            n += 1
        return n

    prev_ok_label: Optional[str] = None
    for i, m in enumerate(matches):
        label = z2h_numhy(m.group("label"))
        start = next_nonempty_pos(m.end())
        end = matches[i+1].start() if i+1 < len(matches) else len(txt)
        body = txt[start:end].lstrip("\n ")

        ok, reason = valid_and_reason(label, scheme, prev_ok_label)
        if ok:
            prev_ok_label = label

        rows.append({
            "page_label": label,
            "is_page": ok,
            "reason": "" if ok else reason,
            "char_count": len(body),
            "preview": body[:160].replace("\n", " ") + ("â€¦" if len(body) > 160 else ""),
            "body": body,  # â† GPTã«æ¸¡ã™ãŸã‚å…¨æ–‡ä¿æŒ
        })
    return rows

# =========================
# å®Ÿè¡Œ & è¡¨ç¤º
# =========================
rows = split_by_singleline_labels(fulltext, scheme)
df = pd.DataFrame(rows)

st.subheader("æŠ½å‡ºçµæœï¼ˆå…¨ä»¶ï¼‰")
st.write(f"æ–¹å¼: **{scheme}**ã€€/ã€€æ¤œå‡ºãƒ©ãƒ™ãƒ«æ•°ï¼š**{len(df)}**")
if len(df):
    st.dataframe(df.drop(columns=["body"]), use_container_width=True)  # bodyã¯é‡ã„ã®ã§è¡¨ã‹ã‚‰ã¯éš ã™
else:
    st.warning("å˜ç‹¬è¡Œã®ãƒšãƒ¼ã‚¸ç•ªå·ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# å¾Œå·¥ç¨‹ã§ä½¿ã†å¯¾è±¡ï¼ˆis_page=True ã®ã¿ï¼‰
df_pages = df[df["is_page"] == True].reset_index(drop=True)
st.subheader("å¾Œå·¥ç¨‹ã«ä½¿ç”¨ã™ã‚‹ãƒšãƒ¼ã‚¸ï¼ˆis_page=Trueï¼‰")
st.write(f"æœ‰åŠ¹ãƒšãƒ¼ã‚¸æ•°ï¼š**{len(df_pages)}**")
if len(df_pages):
    st.dataframe(df_pages.drop(columns=["body"]), use_container_width=True)

# è­¦å‘Šã¾ã¨ã‚
df_warn = df[df["is_page"] == False][["page_label", "reason"]].reset_index(drop=True)
if len(df_warn):
    st.subheader("âš ï¸ è­¦å‘Šï¼ˆãƒšãƒ¼ã‚¸ã¨ã—ã¦ä¸æ¡ç”¨ï¼‰")
    st.dataframe(df_warn, use_container_width=True)
    st.caption("ä¾‹ï¼š3-8 ã®æ¬¡ã« 2018-3 ã®ã‚ˆã†ãª â€œå¹´ã£ã½ã„â€ ãƒ©ãƒ™ãƒ«ã¯ä¸æ¡ç”¨ã¨ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ®‹ã—ã€å¾Œå·¥ç¨‹ã‹ã‚‰é™¤å¤–ã—ã¦ã„ã¾ã™ã€‚")

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
buf_all = io.StringIO(); df.drop(columns=["body"]).to_csv(buf_all, index=False)
st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå…¨ä»¶ï¼‰", data=buf_all.getvalue().encode("utf-8-sig"),
                   file_name="page_segments_all.csv", mime="text/csv")
buf_ok = io.StringIO(); df_pages.drop(columns=["body"]).to_csv(buf_ok, index=False)
st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆis_page=True ã®ã¿ï¼‰", data=buf_ok.getvalue().encode("utf-8-sig"),
                   file_name="page_segments_valid_only.csv", mime="text/csv")

# =========================
# GPT API ã«ã‚ˆã‚‹ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ï¼ˆPDFå°‚ç”¨ï¼‰
# =========================
from openai import OpenAI

st.header("ğŸ“‘ ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ï¼ˆGPTãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰")

# ---- API ã‚­ãƒ¼ç¢ºèª ----
api_key = st.secrets.get("OPENAI_API_KEY", None) or os.getenv("OPENAI_API_KEY")
if not api_key:
    st.warning("OPENAI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ã€GPT ã«ã‚ˆã‚‹ç›®æ¬¡æ¤œè¨¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚ .streamlit/secrets.toml ã‹ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
else:
    client = OpenAI(api_key=api_key)

    HY = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D]"
    LEADERS = r"[\.ï¼ãƒ»â€¦]+"

    def z2h_numhy2(s: str) -> str:
        s = (s or "").replace("\u3000", " ")
        s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789"))
        return re.sub(HY, "-", s)

    def build_label_tail_regex(scheme: str) -> re.Pattern:
        if scheme.startswith("(1)"):
            tail = r"(?P<label>[0-9ï¼-ï¼™]{1,6})"
        else:
            tail = rf"(?P<label>[0-9ï¼-ï¼™]+(?:{HY}[0-9ï¼-ï¼™]+)+)"
        pat = rf"""
            ^(?P<head>.*?)                               # å·¦å´æœ¬æ–‡
            (?:\s*{LEADERS}\s*|\s{{2,}})?                # ãƒ‰ãƒƒãƒˆãƒªãƒ¼ãƒ€ãƒ¼ or é€£ç¶šç©ºç™½
            {tail}\s*$                                   # è¡Œæœ«ã«ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«
        """
        return re.compile(pat, re.X)

    LABEL_TAIL_RE = build_label_tail_regex(scheme)

    def extract_toc_lines_for_gpt(fulltext: str, limit: int = 250) -> List[str]:
        """
        GPT ã«æ¸¡ã™ TOC è¡Œï¼šè¡Œé ­ãŒã€ç¬¬ã€oræ•°å­—ã§å§‹ã¾ã‚Šã€
        ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã«æ—¥æœ¬èªãªã©ã®æ–‡å­—ã‚’å«ã‚€è¡Œã®ã¿æ¡ç”¨ã€‚
        æ•°å­—ãƒ»è¨˜å·ãƒ»ç©ºç™½ã ã‘ã®è¡Œã¯é™¤å¤–ã€‚
        """
        lines = [l.rstrip() for l in fulltext.replace("\r\n","\n").replace("\r","\n").split("\n")]
        head_ok = re.compile(r"^(ç¬¬|[0-9ï¼-ï¼™])")
        text_char = re.compile(r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]")
        out: List[str] = []

        for ln in lines:
            s = ln.strip()
            if not s:
                continue
            if not head_ok.match(s):
                continue
            if not text_char.search(s):
                continue

            m = LABEL_TAIL_RE.match(s)
            if not m:
                continue

            head = re.sub(rf"\s*{LEADERS}\s*$", "", m.group("head")).strip()
            label = z2h_numhy2(m.group("label"))

            if len(head) <= 1:
                continue

            out.append(f"{head} ::: {label}")
            if len(out) >= limit:
                break

        return out

    toc_lines = extract_toc_lines_for_gpt(fulltext)
    if not toc_lines:
        st.info("GPT ã«æ¸¡ã™ç›®æ¬¡å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.markdown("### æŠ½å‡ºã•ã‚ŒãŸç›®æ¬¡å€™è£œï¼ˆä¸Šä½ï¼‰")
        st.code("\n".join(toc_lines[:60]))

        # ---- GPT ã¸æŠ•ã’ã‚‹å…¥åŠ›ã‚’æº–å‚™ ----
        try:
            valid_labels_series = df_pages["page_label"].astype(str)
        except Exception:
            valid_labels_series = df["page_label"].astype(str) if "page_label" in df.columns else pd.Series([], dtype=str)

        VALID_MAX = 800
        TOC_MAX   = 250
        valid_labels_list = valid_labels_series.tolist()[:VALID_MAX]
        toc_for_prompt     = toc_lines[:TOC_MAX]

        # æœ¬æ–‡ã®åˆ‡ã‚Šå‡ºã—é–¢æ•°ï¼ˆ0ãªã‚‰å…¨æ–‡ï¼‰
        def _slice_body(text: str) -> str:
            if excerpt_chars and excerpt_chars > 0:
                return text[:excerpt_chars]
            return text

        # ãƒšãƒ¼ã‚¸åˆ¥æœ¬æ–‡ï¼ˆæŠœç²‹/å…¨æ–‡ï¼‰ã‚’çµ„ã¿ç«‹ã¦
        page_text_block = "\n".join([
            f"{r['page_label']}:\n{_slice_body(r['body'])}"
            for _, r in df_pages.iterrows()
        ])

        system_prompt = (
            "ã‚ãªãŸã¯PDFãƒ¬ãƒãƒ¼ãƒˆã®æ ¡æ­£æ‹…å½“ã§ã™ã€‚"
            "å„ãƒšãƒ¼ã‚¸æœ¬æ–‡ï¼ˆæŠœç²‹ã¾ãŸã¯å…¨æ–‡ï¼‰ã¨ã€ç›®æ¬¡å€™è£œï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼‰ã‚’ç…§åˆã—ã€"
            "å„ç›®æ¬¡è¡Œã®ãƒšãƒ¼ã‚¸ç•ªå·ãŒå®Ÿéš›ã«å­˜åœ¨ã—æ•´åˆã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            "çŸ­ãç®‡æ¡æ›¸ãã§ã€ä»¥ä¸‹ã®åˆ†é¡ã§å‡ºã—ã¦ãã ã•ã„ï¼š\n"
            "ãƒ»OKï¼ˆãƒšãƒ¼ã‚¸ãŒå­˜åœ¨ã—æ•´åˆï¼‰\n"
            "ãƒ»ã‚ºãƒ¬ï¼ˆãƒšãƒ¼ã‚¸ã¯å­˜åœ¨ã™ã‚‹ãŒç« ã‚„é †åºã®æ•´åˆãŒå¼±ã„ï¼‰\n"
            "ãƒ»ä¸æ˜ï¼ˆãƒšãƒ¼ã‚¸ãŒæœªæ¤œå‡ºï¼æœ¬æ–‡å´ã§è¦‹å½“ãŸã‚‰ãªã„ï¼‰\n"
            "æœ€å¾Œã«ã€å…¨ä½“ã®ã¾ã¨ã‚ã¨æ”¹å–„ææ¡ˆã‚’ä¸€è¨€ã§ã€‚"
        )
        scheme_hint = "ç« -ãƒšãƒ¼ã‚¸æ–¹å¼ï¼ˆä¾‹: 3-60ï¼‰ã€‚ç« ã¯ãƒã‚¤ãƒ•ãƒ³å·¦å´ã€‚" if scheme.startswith("(2)") else "é€£ç•ªæ–¹å¼ï¼ˆä¾‹: 1,2,3, ...ï¼‰ã€‚"

        user_prompt = (
            f"ã€æ–¹å¼ã€‘{scheme_hint}\n"
            f"ã€æœ¬æ–‡ï¼ˆãƒšãƒ¼ã‚¸åˆ¥ã€‚å„ãƒšãƒ¼ã‚¸ã®å…ˆé ­{excerpt_chars}æ–‡å­—ã‚’ä½¿ç”¨ã€‚0ãªã‚‰å…¨æ–‡ï¼‰ã€‘\n"
            f"{page_text_block}\n\n"
            "ã€ç›®æ¬¡å€™è£œï¼ˆå·¦ï¼šã‚¿ã‚¤ãƒˆãƒ«ã€å³ï¼šãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼‰ã€‘\n"
            + "\n".join(toc_for_prompt) + "\n\n"
            "ã€æŠ½å‡ºæ¸ˆã¿ã®å®Ÿãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼ˆis_page=True å„ªå…ˆï¼‰ã€‘\n"
            + ", ".join(valid_labels_list)
        )

        from openai import OpenAI
        with st.spinner("GPT ã«ã‚ˆã‚‹ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­â€¦"):
            resp = client.chat.completions.create(
                model="gpt-5-mini",  # temperature æŒ‡å®šä¸å¯
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            )

        gpt_answer = resp.choices[0].message.content.strip()
        st.success("GPT ã«ã‚ˆã‚‹æ¤œè¨¼çµæœ")
        st.text_area("ğŸ” GPTã®åˆ¤å®šãƒ»æŒ‡æ‘˜", gpt_answer, height=420)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
        md_buf = io.StringIO()
        md_buf.write("# ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ï¼ˆGPTçµæœï¼‰\n\n")
        md_buf.write("## ç›®æ¬¡å€™è£œï¼ˆå…ˆé ­ï¼‰\n")
        md_buf.write("```\n" + "\n".join(toc_for_prompt) + "\n```\n\n")
        md_buf.write("## æŠ½å‡ºãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼ˆæŠœç²‹ï¼‰\n")
        md_buf.write("```\n" + ", ".join(valid_labels_list[:200]) + "\n```\n\n")
        md_buf.write(f"## æœ¬æ–‡åˆ‡ã‚Šå‡ºã—é•·ï¼ˆ1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šï¼‰ï¼š{excerpt_chars} æ–‡å­—\n\n")
        md_buf.write("## GPTã®å›ç­”\n\n")
        md_buf.write(gpt_answer + "\n")
        st.download_button(
            "ğŸ“¥ GPTçµæœã‚’Markdownã§ä¿å­˜",
            data=md_buf.getvalue().encode("utf-8"),
            file_name="toc_check_gpt_result.md",
            mime="text/markdown",
        )
