# -*- coding: utf-8 -*-
# pages/45_ãƒ¬ãƒƒãƒ‰ãƒªã‚¹ãƒˆ_ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼.py
# _app/redlist/{fukusiima, MOE, prec, chiba} ã«ã‚ã‚‹ CSV / Excel ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦å…ˆé ­Nè¡Œã‚’è¡¨ç¤º

from __future__ import annotations
import io
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import streamlit as st
import pandas as pd

st.set_page_config(page_title="ğŸ“š ãƒ¬ãƒƒãƒ‰ãƒªã‚¹ãƒˆï¼ˆCSV/Excelï¼‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", page_icon="ğŸ“š", layout="wide")
st.title("ğŸ“š ãƒ¬ãƒƒãƒ‰ãƒªã‚¹ãƒˆï¼ˆCSV / Excelï¼‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
st.caption("_app/redlist ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­è¡Œã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¾ã™ã€‚")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¨­å®šï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("### ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    # pages/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã«ã‚¢ãƒ—ãƒªãŒã‚ã‚‹å‰æï¼špages/ ã®1ã¤ä¸ŠãŒã‚¢ãƒ—ãƒªãƒ«ãƒ¼ãƒˆ
    app_root_default = Path(__file__).resolve().parents[1]
    base_dir_str = st.text_input("ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", value=str(app_root_default / "data" / "redlist"))
    n_rows = st.number_input("è¡¨ç¤ºè¡Œæ•°ï¼ˆå…ˆé ­ï¼‰", min_value=5, max_value=100, value=10, step=5)
    show_sheet_all = st.checkbox("Excelã¯å…¨ã‚·ãƒ¼ãƒˆã‚’è¡¨ç¤ºï¼ˆæ—¢å®šã¯å…ˆé ­ã‚·ãƒ¼ãƒˆã®ã¿ï¼‰", value=False)
    st.markdown("---")
    st.caption("ãƒ•ã‚©ãƒ«ãƒ€å â†’ è¡¨ç¤ºåã®å¯¾å¿œ")
    st.write({
        "fukushima": "ç¦å³¶çœŒ",
        "MOE": "ç’°å¢ƒçœ",
        "prec": "ãƒ—ãƒ¬ãƒƒã‚¯",
        "chiba": "åƒè‘‰çœŒ",
    })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FOLDERS = [
    ("fukushima", "ç¦å³¶çœŒ"),
    ("MOE",       "ç’°å¢ƒçœ"),
    ("prec",      "ãƒ—ãƒ¬ãƒƒã‚¯"),
    ("chiba",     "åƒè‘‰çœŒ"),
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# èª­ã¿è¾¼ã¿ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CSV_EXTS  = {".csv"}
XLSX_EXTS = {".xlsx", ".xls"}

def _read_csv_head(path: Path, n: int) -> Optional[pd.DataFrame]:
    """CSVã‚’å…ˆé ­nè¡Œã ã‘èª­ã¿è¾¼ã‚€ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã€‚"""
    for enc in ("utf-8-sig", "cp932", "utf-8"):
        try:
            return pd.read_csv(path, nrows=n, encoding=enc)
        except Exception:
            continue
    try:
        # æœ€å¾Œã®æ‰‹æ®µï¼šerrors='ignore'
        return pd.read_csv(path, nrows=n, encoding="utf-8", errors="ignore")
    except Exception as e:
        st.warning(f"CSVèª­ã¿è¾¼ã¿å¤±æ•—: {path.name} ({e})")
        return None

def _read_excel_heads(path: Path, n: int, all_sheets: bool) -> List[Tuple[str, pd.DataFrame]]:
    """
    Excelã‚’å…ˆé ­nè¡Œèª­ã¿è¾¼ã‚€ã€‚
    æˆ»ã‚Šå€¤: [(sheet_name, df_head), ...]
    """
    out: List[Tuple[str, pd.DataFrame]] = []
    try:
        xls = pd.ExcelFile(path)
        sheets = xls.sheet_names
        targets = sheets if all_sheets else sheets[:1]
        for s in targets:
            try:
                df = pd.read_excel(path, sheet_name=s, nrows=n)
                out.append((s, df))
            except Exception as e:
                st.warning(f"Excelã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—: {path.name} [{s}] ({e})")
    except Exception as e:
        st.warning(f"Excelèª­ã¿è¾¼ã¿å¤±æ•—: {path.name} ({e})")
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
base_dir = Path(base_dir_str).expanduser().resolve()
if not base_dir.exists():
    st.error(f"ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_dir}")
    st.stop()

for folder, label in FOLDERS:
    target_dir = base_dir / folder
    st.header(f"ğŸ“ {label} â€” {folder}")
    st.caption(str(target_dir))

    if not target_dir.exists():
        st.warning(f"ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“: {target_dir}")
        continue

    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ—æŒ™
    files = sorted([p for p in target_dir.iterdir() if p.is_file() and p.suffix.lower() in (CSV_EXTS | XLSX_EXTS)],
                   key=lambda p: p.name)
    if not files:
        st.info("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ï¼ˆCSV/Excelï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        continue

    for f in files:
        ext = f.suffix.lower()
        st.markdown(f"#### ğŸ“„ {f.name}")

        if ext in CSV_EXTS:
            df = _read_csv_head(f, n_rows)
            if df is not None:
                st.dataframe(df, use_container_width=True)
            else:
                st.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        elif ext in XLSX_EXTS:
            heads = _read_excel_heads(f, n_rows, show_sheet_all)
            if not heads:
                st.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                for sheet_name, df in heads:
                    st.markdown(f"- **Sheet:** `{sheet_name}`")
                    st.dataframe(df, use_container_width=True)

        st.divider()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ï¼ˆç…§åˆå‡¦ç†ï¼‰prec ç¨®å Ã—ï¼ˆç’°å¢ƒçœ å’Œåï¼ç¦å³¶çœŒ å’Œåï¼‰
#   å‡ºåŠ›åˆ—ï¼šprecç¨®å, precç’°å¢ƒçœãƒ¬ãƒƒãƒ‰, precçœŒãƒ¬ãƒƒãƒ‰, ç’°å¢ƒçœã‚«ãƒ†ã‚´ãƒªãƒ¼, ç¦å³¶çœŒã‚«ãƒ†ã‚´ãƒªãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.header("ğŸ” ç…§åˆï¼ˆprecÃ—ç’°å¢ƒçœÃ—ç¦å³¶çœŒï¼‰")

# ä¾¿åˆ©ï¼šåˆ—åã®ã‚†ã‚‰ãã‚’å¸åã—ã¦æ¬²ã—ã„åˆ—ã‚’å–ã‚Šå‡ºã™ãƒ˜ãƒ«ãƒ‘
def pick_cols(df: pd.DataFrame, wanted: Dict[str, List[str]]) -> pd.DataFrame:
    """
    wanted = {"dst_col": ["å€™è£œ1", "å€™è£œ2", ...], ...}
    """
    cols = {}
    # æ­£è¦åŒ–ï¼ˆå…¨è§’ç©ºç™½â†’åŠè§’ã€å‰å¾Œç©ºç™½é™¤å»ï¼‰
    def _norm(s: str) -> str:
        return (str(s).replace("\u3000", " ").strip()).lower()

    norm_map = {_norm(c): c for c in df.columns}
    for dst, cands in wanted.items():
        found = None
        for c in cands:
            key = _norm(c)
            if key in norm_map:
                found = norm_map[key]
                break
        if found:
            cols[dst] = df[found]
        else:
            cols[dst] = pd.Series([None] * len(df))
            st.info(f"åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: æœŸå¾…åˆ— '{cands[0]}'ï¼ˆä»–å€™è£œ: {cands[1:]}ï¼‰")
    return pd.DataFrame(cols)

def _read_csv_any(path: Path) -> Optional[pd.DataFrame]:
    for enc in ("utf-8-sig", "cp932", "utf-8"):
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    try:
        return pd.read_csv(path, encoding="utf-8", errors="ignore")
    except Exception as e:
        st.warning(f"CSVèª­ã¿è¾¼ã¿å¤±æ•—: {path.name} ({e})")
        return None

def _read_excel_all(path: Path) -> List[pd.DataFrame]:
    out: List[pd.DataFrame] = []
    try:
        xls = pd.ExcelFile(path)
        for s in xls.sheet_names:
            try:
                out.append(pd.read_excel(path, sheet_name=s))
            except Exception as e:
                st.warning(f"Excelã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—: {path.name} [{s}] ({e})")
    except Exception as e:
        st.warning(f"Excelèª­ã¿è¾¼ã¿å¤±æ•—: {path.name} ({e})")
    return out

def _norm_name(s: Optional[str]) -> str:
    # åå‰ç…§åˆç”¨ã®è»½ã„æ­£è¦åŒ–ï¼šå…¨è§’ç©ºç™½â†’åŠè§’ã€å…¨è§’è‹±æ•°â†’åŠè§’ã€ä½™ç™½å‰Šé™¤
    if s is None:
        return ""
    t = str(s).replace("\u3000", " ").strip()
    # ä¸€éƒ¨ã®å…¨è§’â†’åŠè§’ï¼ˆè‹±æ•°ã®ã¿ï¼‰
    z = "ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
    h = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789"
    t = t.translate(str.maketrans(z, h))
    return t

# â‘  precï¼ˆExcelï¼‰â†’ ã€Œç¨®åã€ã€Œç’°å¢ƒçœãƒ¬ãƒƒãƒ‰ã€ã€ŒçœŒãƒ¬ãƒƒãƒ‰ã€
prec_dir = base_dir / "prec"
prec_frames: List[pd.DataFrame] = []
if prec_dir.exists():
    for p in sorted(prec_dir.iterdir()):
        if p.suffix.lower() in {".xlsx", ".xls"} and p.is_file():
            for df in _read_excel_all(p):
                sub = pick_cols(
                    df,
                    {
                        "precç¨®å": ["ç¨®å"],
                        "precç’°å¢ƒçœãƒ¬ãƒƒãƒ‰": ["ç’°å¢ƒçœãƒ¬ãƒƒãƒ‰"],
                        "precçœŒãƒ¬ãƒƒãƒ‰": ["çœŒãƒ¬ãƒƒãƒ‰"],
                    },
                )
                prec_frames.append(sub)
else:
    st.warning(f"prec ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prec_dir}")

prec_df = pd.concat(prec_frames, ignore_index=True) if prec_frames else pd.DataFrame(columns=["precç¨®å","precç’°å¢ƒçœãƒ¬ãƒƒãƒ‰","precçœŒãƒ¬ãƒƒãƒ‰"])
# å…ƒã®é †åºã‚’ä¿ã¤ãŸã‚ã®é€šã—ç•ªå·
prec_df["_ord"] = range(len(prec_df))

# â‘¡ ç’°å¢ƒçœï¼ˆCSVï¼‰â†’ ã€Œã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ã€Œå’Œåã€
moe_dir = base_dir / "MOE"
moe_frames: List[pd.DataFrame] = []
if moe_dir.exists():
    for p in sorted(moe_dir.iterdir()):
        if p.suffix.lower() == ".csv" and p.is_file():
            df = _read_csv_any(p)
            if df is not None:
                sub = pick_cols(df, {"ç’°å¢ƒçœã‚«ãƒ†ã‚´ãƒªãƒ¼": ["ã‚«ãƒ†ã‚´ãƒªãƒ¼"], "ç’°å¢ƒçœå’Œå": ["å’Œå"]})
                moe_frames.append(sub)
else:
    st.warning(f"MOE ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {moe_dir}")

moe_df = pd.concat(moe_frames, ignore_index=True) if moe_frames else pd.DataFrame(columns=["ç’°å¢ƒçœã‚«ãƒ†ã‚´ãƒªãƒ¼","ç’°å¢ƒçœå’Œå"])

# â‘¢ ç¦å³¶çœŒï¼ˆExcelï¼‰â†’ ã€Œå’Œåã€ã€Œãµãã—ã¾RL2024ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€
fuku_dir = base_dir / "fukushima"
fuku_frames: List[pd.DataFrame] = []
if fuku_dir.exists():
    for p in sorted(fuku_dir.iterdir()):
        if p.suffix.lower() in {".xlsx", ".xls"} and p.is_file():
            for df in _read_excel_all(p):
                sub = pick_cols(
                    df,
                    {
                        "ç¦å³¶çœŒå’Œå": ["å’Œå"],
                        "ç¦å³¶çœŒã‚«ãƒ†ã‚´ãƒªãƒ¼": ["ãµãã—ã¾RL2024ã‚«ãƒ†ã‚´ãƒªãƒ¼", "ç¦å³¶RL2024ã‚«ãƒ†ã‚´ãƒªãƒ¼", "RL2024ã‚«ãƒ†ã‚´ãƒªãƒ¼"],
                    },
                )
                fuku_frames.append(sub)
else:
    st.warning(f"fukushima ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fuku_dir}")

fuku_df = pd.concat(fuku_frames, ignore_index=True) if fuku_frames else pd.DataFrame(columns=["ç¦å³¶çœŒå’Œå","ç¦å³¶çœŒã‚«ãƒ†ã‚´ãƒªãƒ¼"])

# å‚ç…§ç”¨è¾æ›¸ï¼ˆã‚­ãƒ¼ = æ­£è¦åŒ–ã—ãŸå’Œåï¼‰
moe_map = { _norm_name(r["ç’°å¢ƒçœå’Œå"]): r["ç’°å¢ƒçœã‚«ãƒ†ã‚´ãƒªãƒ¼"] for _, r in moe_df.dropna(subset=["ç’°å¢ƒçœå’Œå"]).iterrows() }
fuku_map = { _norm_name(r["ç¦å³¶çœŒå’Œå"]): r["ç¦å³¶çœŒã‚«ãƒ†ã‚´ãƒªãƒ¼"] for _, r in fuku_df.dropna(subset=["ç¦å³¶çœŒå’Œå"]).iterrows() }

# èµ°æŸ»ï¼šprecç¨®å ã‚’ä¸Šã‹ã‚‰é †ã«è¦‹ã¦ã€ä¸€è‡´ãŒã‚ã‚Œã°å‡ºåŠ›
rows: List[Dict[str, Optional[str]]] = []
for _, r in prec_df.iterrows():
    name = r.get("precç¨®å")
    key  = _norm_name(name)
    moe_cat  = moe_map.get(key)
    fuku_cat = fuku_map.get(key)
    if (moe_cat is not None) or (fuku_cat is not None):
        rows.append(
            {
                "precç¨®å": name,
                "precç’°å¢ƒçœãƒ¬ãƒƒãƒ‰": r.get("precç’°å¢ƒçœãƒ¬ãƒƒãƒ‰"),
                "precçœŒãƒ¬ãƒƒãƒ‰": r.get("precçœŒãƒ¬ãƒƒãƒ‰"),
                "ç’°å¢ƒçœã‚«ãƒ†ã‚´ãƒªãƒ¼": moe_cat,
                "ç¦å³¶çœŒã‚«ãƒ†ã‚´ãƒªãƒ¼": fuku_cat,
                "_ord": r.get("_ord", 0),
            }
        )

result_df = pd.DataFrame(rows).sort_values("_ord").drop(columns=["_ord"], errors="ignore")
st.subheader("âœ… ç…§åˆçµæœï¼ˆä¸€è‡´ã—ãŸã‚‚ã®ï¼‰")
if result_df.empty:
    st.info("ä¸€è‡´ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ—åã®ã‚†ã‚‰ãã‚„è¡¨è¨˜ã‚†ã‚Œï¼ˆå…¨è§’/åŠè§’ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ï¼‰ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
else:
    st.dataframe(result_df, use_container_width=True)

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    buf = io.StringIO()
    result_df.to_csv(buf, index=False)
    st.download_button(
        "ğŸ“¥ ç…§åˆçµæœã‚’CSVã§ä¿å­˜",
        data=buf.getvalue().encode("utf-8-sig"),
        file_name="redlist_match_result.csv",
        mime="text/csv",
        use_container_width=True,
    )

# å‚è€ƒï¼šä»¶æ•°ã‚µãƒãƒª
st.caption(
    f"precå…¥åŠ›: {len(prec_df)} ä»¶ / ç’°å¢ƒçœ: {len(moe_df)} ä»¶ / ç¦å³¶çœŒ: {len(fuku_df)} ä»¶ / ä¸€è‡´: {len(result_df)} ä»¶"
)
