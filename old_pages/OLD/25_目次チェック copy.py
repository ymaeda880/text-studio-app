# -*- coding: utf-8 -*-
# pages/25_ç›®æ¬¡ãƒã‚§ãƒƒã‚¯.py
from __future__ import annotations
import io, re, tempfile
from pathlib import Path
from typing import List, Dict, Any, Tuple

import streamlit as st
import pandas as pd

# ==== PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆ ====
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# ==== DOCXâ†’PDF ====
try:
    import pypandoc
except Exception:
    pypandoc = None
try:
    from docx2pdf import convert as docx2pdf_convert
except Exception:
    docx2pdf_convert = None


# =========================
# UI
# =========================
st.set_page_config(page_title="ğŸ“„ ç›´åˆ—ãƒ†ã‚­ã‚¹ãƒˆæ³•ï¼šé ç•ªå·æŠ½å‡ºï¼ˆæ–¹å¼é¸æŠâ†’å®Ÿè¡Œï¼‰", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ ç›´åˆ—ãƒ†ã‚­ã‚¹ãƒˆæ³•ï¼šé ç•ªå·æŠ½å‡ºï¼ˆå˜ç‹¬è¡Œã®ã¿ï¼‰")

with st.sidebar:
    st.subheader("â‘  å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    uploaded = st.file_uploader("Wordï¼ˆ.docxï¼‰ã¾ãŸã¯ PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["docx", "pdf"])

    st.subheader("â‘¡ ãƒšãƒ¼ã‚¸æ–¹å¼ã‚’é¸æŠ")
    scheme = st.radio(
        "æ–¹å¼",
        ["(1) 1, 2, 3, 4, â€¦", "(2) 1-1, 1-2, 2-1, 2-2, â€¦"],
        index=1
    )

    st.subheader("â‘¢ å¤‰æ›/æŠ½å‡ºã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    prefer = st.selectbox("DOCXâ†’PDF å¤‰æ›ã®å„ªå…ˆé †", ["pandoc,docx2pdf", "docx2pdf,pandoc"], index=0)
    join_pages = st.checkbox("PDFã¯ãƒšãƒ¼ã‚¸ã”ã¨ã§ã¯ãªãå…¨æ–‡ã‚’é€£çµã—ã¦å‡¦ç†ï¼ˆæ¨å¥¨ï¼‰", value=True)
    keep_pdf = st.checkbox("å¤‰æ›PDFã‚’ ./data/last_converted.pdf ã«ä¿å­˜", value=False)

    st.subheader("â‘£ å®Ÿè¡Œ")
    run = st.button("å‡¦ç†é–‹å§‹", type="primary")

st.caption("â€» æŠ½å‡ºã¯ **â€œå˜ç‹¬è¡Œã«ãƒšãƒ¼ã‚¸ç•ªå·ã ã‘ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹è¡Œâ€** ã‚’åŒºåˆ‡ã‚Šã¨ã—ã¦ä½¿ã„ã¾ã™ã€‚æœ¬æ–‡ã«æ··ã–ã‚‹æ•°å­—ã¯ç„¡è¦–ã—ã¾ã™ã€‚")

if not run:
    st.stop()
if not uploaded:
    st.warning("ã¾ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()
if fitz is None and pdfplumber is None:
    st.error("PyMuPDF ã‹ pdfplumber ã®ã©ã¡ã‚‰ã‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚`pip install pymupdf pdfplumber`")
    st.stop()


# =========================
# å¤‰æ› & ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
# =========================
def convert_docx_to_pdf(input_docx: Path, out_pdf: Path, prefer: str) -> str:
    methods = [m.strip().lower() for m in prefer.split(",") if m.strip()]
    errs = []
    for m in methods:
        try:
            if m == "pandoc":
                if pypandoc is None:
                    raise RuntimeError("pypandoc not available")
                pypandoc.convert_file(str(input_docx), "pdf", outputfile=str(out_pdf))
                if out_pdf.exists() and out_pdf.stat().st_size > 0:
                    return "pandoc"
                raise RuntimeError("pandoc produced empty pdf")
            elif m == "docx2pdf":
                if docx2pdf_convert is None:
                    raise RuntimeError("docx2pdf not available")
                docx2pdf_convert(str(input_docx), str(out_pdf))
                if out_pdf.exists() and out_pdf.stat().st_size > 0:
                    return "docx2pdf"
                raise RuntimeError("docx2pdf produced empty pdf")
            else:
                raise RuntimeError(f"unknown method: {m}")
        except Exception as e:
            errs.append(f"{m}: {e}")
    raise RuntimeError("DOCXâ†’PDF conversion failed. " + " / ".join(errs))

def pdf_to_fulltext(pdf_path: Path, join_pages: bool) -> str:
    if fitz is not None:
        doc = fitz.open(str(pdf_path))
        pages = [(p.get_text("text") or "") for p in doc]
        return ("\n".join(pages)) if join_pages else ("\n\n---PAGE-BREAK---\n\n".join(pages))
    with pdfplumber.open(str(pdf_path)) as pdf:
        pages = [(p.extract_text() or "") for p in pdf.pages]
        return ("\n".join(pages)) if join_pages else ("\n\n---PAGE-BREAK---\n\n".join(pages))

# å…¥åŠ›ã®æº–å‚™
Path("data").mkdir(parents=True, exist_ok=True)
suffix = uploaded.name.lower().rsplit(".", 1)[-1]

with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™ä¸­..."):
    if suffix == "pdf":
        with tempfile.TemporaryDirectory() as td:
            td = Path(td)
            pdf_path = td / "input.pdf"
            pdf_path.write_bytes(uploaded.getvalue())
            in_type = "pdf"
            fulltext = pdf_to_fulltext(pdf_path, join_pages=join_pages)
    else:
        with tempfile.TemporaryDirectory() as td:
            td = Path(td)
            docx_path = td / "input.docx"
            docx_path.write_bytes(uploaded.getvalue())
            out_pdf = (Path("data/last_converted.pdf") if keep_pdf else (td / "output.pdf"))
            in_type = convert_docx_to_pdf(docx_path, out_pdf, prefer=prefer)
            fulltext = pdf_to_fulltext(out_pdf, join_pages=join_pages)

st.success(f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†ï¼ˆå…¥åŠ›: {in_type}ï¼‰")


# =========================
# å˜ç‹¬è¡Œãƒ©ãƒ™ãƒ«æ¤œå‡ºï¼ˆæ–¹å¼åˆ¥ï¼‰ï¼‹ å¹´ã£ã½ã„é™¤å¤– + é€£ç•ªãƒã‚§ãƒƒã‚¯
# =========================
HY = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D]"  # å„ç¨®ãƒã‚¤ãƒ•ãƒ³
def z2h_numhy(s: str) -> str:
    s = s.replace("\u3000", " ")
    s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789"))
    return re.sub(HY, "-", s)

def build_label_line_regex(scheme: str) -> re.Pattern:
    if scheme.startswith("(1)"):
        core = r"[0-9ï¼-ï¼™]{1,6}"               # é€£ç•ª
    else:
        core = rf"[0-9ï¼-ï¼™]+(?:{HY}[0-9ï¼-ï¼™]+)+"  # ç« -ãƒšãƒ¼ã‚¸ï¼ˆè¤‡åˆå¯ï¼‰
    return re.compile(rf"^\s*(?:p(?:age)?\.?\s*)?(?P<label>{core})\s*$", re.MULTILINE)

LABEL_LINE_RE = build_label_line_regex(scheme)

def valid_and_reason(label: str, scheme: str, prev_ok: Optional[str]) -> Tuple[bool, str]:
    """
    ãƒ©ãƒ™ãƒ«ã‚’ã€Œãƒšãƒ¼ã‚¸ã¨ã—ã¦æ¡ç”¨ã™ã‚‹ã‹ã€ã‚’åˆ¤å®šã€‚
    - æ–¹å¼(2)ï¼šå…ˆé ­ãŒ >=100ï¼ˆä¾‹: 2018-3ï¼‰ã¯ â€œå¹´ã£ã½ã„â€ ã¨ã—ã¦ä¸æ¡ç”¨
    - é€£ç•ªãƒã‚§ãƒƒã‚¯ï¼šå‰ã®ã€Œæ¡ç”¨ãƒ©ãƒ™ãƒ«ã€ã¨ã®é€£ç¶šæ€§ã‚’ç¢ºèª
      * (1) n ãŒ prev+1 ãªã‚‰æ¡ç”¨ã€‚prev ãŒç„¡ã„æœ€åˆã¯æ¡ç”¨ã€‚
      * (2) chap-page å½¢å¼ï¼š (c,p) ãŒ (c, prev_p+1) ã‹ (c+1, 1) ãªã‚‰æ¡ç”¨
    - é€£ç¶šã§ãªã„å ´åˆã¯ä¸æ¡ç”¨ã«ã—ã€ç†ç”±ã‚’è¿”ã™ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯æ®‹ã™ï¼‰
    """
    if scheme.startswith("(1)"):
        # é€£ç•ª
        try:
            n = int(label)
        except Exception:
            return False, "é€£ç•ªå½¢å¼ã§æ•°å€¤åŒ–ã§ããªã„"
        if prev_ok is None:
            return True, ""  # æœ€åˆã¯æ¡ç”¨
        try:
            prev = int(prev_ok)
        except Exception:
            return True, ""  # å‰ãŒèª­ã‚ãªã‘ã‚Œã°æ¡ç”¨
        if n == prev + 1:
            return True, ""
        else:
            return False, "éé€£ç•ªï¼ˆé€£ç¶šã—ã¦ã„ãªã„ï¼‰"
    else:
        # ç« -ãƒšãƒ¼ã‚¸
        parts = label.split("-")
        if not (len(parts) >= 2 and all(p.isdigit() for p in parts)):
            return False, "ç« -ãƒšãƒ¼ã‚¸å½¢å¼ã§ãªã„"
        chap = int(parts[0])
        # å¹´ã£ã½ã„ï¼ˆä¾‹: 2018-3ï¼‰ã¯ä¸æ¡ç”¨
        if chap >= 100:
            return False, "å¹´ã£ã½ã„ç« ç•ªå·ï¼ˆä¾‹: 2018-3ï¼‰"
        page_n = int(parts[1])
        if prev_ok is None:
            return True, ""
        pparts = prev_ok.split("-")
        if not (len(pparts) >= 2 and all(p.isdigit() for p in pparts)):
            return True, ""  # å‰ãŒèª­ã‚ãªã‘ã‚Œã°æ¡ç”¨
        pchap, ppage = int(pparts[0]), int(pparts[1])
        # åŒã˜ç« ã§ãƒšãƒ¼ã‚¸ãŒ +1 ãªã‚‰é€£ç•ªOK / æ¬¡ã®ç« ã® 1 ãªã‚‰OK
        if (chap == pchap and page_n == ppage + 1) or (chap == pchap + 1 and page_n == 1):
            return True, ""
        else:
            return False, "éé€£ç•ªï¼ˆé€£ç¶šã—ã¦ã„ãªã„ï¼‰"

def split_by_singleline_labels(fulltext: str, scheme: str) -> List[Dict[str, Any]]:
    """
    å˜ç‹¬è¡Œã®ãƒ©ãƒ™ãƒ«ã ã‘ã§åŒºåˆ‡ã‚‹ã€‚
    - ç„¡åŠ¹/éé€£ç•ªã¯ is_page=False, reason ã«ç†ç”±ã‚’å…¥ã‚Œã¦è¡¨ã«ã¯æ®‹ã™
    - is_page=True ã®ã‚‚ã®ã ã‘ã‚’ã€Œå¾Œå·¥ç¨‹ã«ä½¿ç”¨ã€ã§ãã‚‹
    """
    if not fulltext:
        return []
    txt = z2h_numhy(fulltext.replace("\r\n", "\n").replace("\r", "\n"))

    matches = list(LABEL_LINE_RE.finditer(txt))
    if not matches:
        return []

    rows: List[Dict[str, Any]] = []

    def next_nonempty_pos(pos: int) -> int:
        n = pos
        while n < len(txt) and txt[n] == "\n":
            n += 1
        return n

    prev_ok_label: Optional[str] = None  # ç›´å‰ã®ã€Œæ¡ç”¨ã•ã‚ŒãŸã€ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«
    for i, m in enumerate(matches):
        label = z2h_numhy(m.group("label"))
        start = next_nonempty_pos(m.end())
        end = matches[i+1].start() if i+1 < len(matches) else len(txt)
        body = txt[start:end].lstrip("\n ")

        ok, reason = valid_and_reason(label, scheme, prev_ok_label)
        if ok:
            prev_ok_label = label  # æ¡ç”¨ã•ã‚ŒãŸã‚‰æ›´æ–°

        rows.append({
            "page_label": label,
            "is_page": ok,                 # å¾Œå·¥ç¨‹ã«ä½¿ãˆã‚‹ã‹ã©ã†ã‹
            "reason": "" if ok else reason, # ä¸æ¡ç”¨ç†ç”±ï¼ˆä¾‹ï¼šå¹´ã£ã½ã„ï¼éé€£ç•ªï¼‰
            "char_count": len(body),
            "preview": body[:160].replace("\n", " ") + ("â€¦" if len(body) > 160 else "")
        })
    return rows


# =========================
# å®Ÿè¡Œ
# =========================
rows = split_by_singleline_labels(fulltext, scheme)
df = pd.DataFrame(rows)

st.subheader("æŠ½å‡ºçµæœï¼ˆå…¨ä»¶ï¼‰")
st.write(f"æ–¹å¼: **{scheme}**ã€€/ã€€æ¤œå‡ºãƒ©ãƒ™ãƒ«æ•°ï¼š**{len(df)}**")
if len(df):
    st.dataframe(df, use_container_width=True)
else:
    st.warning("å˜ç‹¬è¡Œã®ãƒšãƒ¼ã‚¸ç•ªå·ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# å¾Œå·¥ç¨‹ã§ä½¿ã†å¯¾è±¡ï¼ˆis_page=True ã®ã¿ï¼‰
df_pages = df[df["is_page"] == True].reset_index(drop=True)
st.subheader("å¾Œå·¥ç¨‹ã«ä½¿ç”¨ã™ã‚‹ãƒšãƒ¼ã‚¸ï¼ˆis_page=Trueï¼‰")
st.write(f"æœ‰åŠ¹ãƒšãƒ¼ã‚¸æ•°ï¼š**{len(df_pages)}**")
st.dataframe(df_pages, use_container_width=True)

# è­¦å‘Šã¾ã¨ã‚
df_warn = df[df["is_page"] == False][["page_label", "reason"]].reset_index(drop=True)
if len(df_warn):
    st.subheader("âš ï¸ è­¦å‘Šï¼ˆãƒšãƒ¼ã‚¸ã¨ã—ã¦ä¸æ¡ç”¨ï¼‰")
    st.dataframe(df_warn, use_container_width=True)
    st.caption("ä¾‹ï¼š3-8 ã®æ¬¡ã« 2018-3 ã®ã‚ˆã†ãª â€œå¹´ã£ã½ã„â€ ãƒ©ãƒ™ãƒ«ã¯ä¸æ¡ç”¨ã¨ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ®‹ã—ã€å¾Œå·¥ç¨‹ã‹ã‚‰é™¤å¤–ã—ã¦ã„ã¾ã™ã€‚")

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
buf_all = io.StringIO(); df.to_csv(buf_all, index=False)
st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå…¨ä»¶ï¼‰", data=buf_all.getvalue().encode("utf-8-sig"),
                   file_name="page_segments_all.csv", mime="text/csv")
buf_ok = io.StringIO(); df_pages.to_csv(buf_ok, index=False)
st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆis_page=True ã®ã¿ï¼‰", data=buf_ok.getvalue().encode("utf-8-sig"),
                   file_name="page_segments_valid_only.csv", mime="text/csv")


# =========================
# GPT API ã«ã‚ˆã‚‹ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼
# =========================
from typing import List
from openai import OpenAI


st.header("ğŸ“‘ ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ï¼ˆGPTãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰")

# ---- API ã‚­ãƒ¼ç¢ºèª ----
api_key = st.secrets.get("OPENAI_API_KEY", None) or os.getenv("OPENAI_API_KEY")
if not api_key:
    st.warning("OPENAI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ã€GPT ã«ã‚ˆã‚‹ç›®æ¬¡æ¤œè¨¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚ .streamlit/secrets.toml ã‹ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
else:
    client = OpenAI(api_key=api_key)

    # ---- ç›®æ¬¡å€™è£œã®æŠ½å‡ºï¼ˆç´ ç›´ç‰ˆï¼šè¡Œæœ«ã« 1 / 1-1 / 3-60 ãªã©ãŒã‚ã‚‹è¡Œï¼‰----
    HY = r"[\-\u2010\u2011\u2012\u2013\u2014\u2015\u2212\uFF0D]"  # å„ç¨®ãƒã‚¤ãƒ•ãƒ³
    LEADERS = r"[\.ï¼ãƒ»â€¦]+"                                     # ãƒ‰ãƒƒãƒˆãƒªãƒ¼ãƒ€ãƒ¼ç¾¤

    def z2h_numhy(s: str) -> str:
        s = (s or "").replace("\u3000", " ")
        s = s.translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789"))
        return re.sub(HY, "-", s)

    def build_label_tail_regex(scheme: str) -> re.Pattern:
        if scheme.startswith("(1)"):
            tail = r"(?P<label>[0-9ï¼-ï¼™]{1,6})"
        else:
            tail = rf"(?P<label>[0-9ï¼-ï¼™]+(?:{HY}[0-9ï¼-ï¼™]+)+)"
        pat = rf"""
            ^(?P<head>.*?)                               # å·¦å´æœ¬æ–‡
            (?:\s*{LEADERS}\s*|\s{{2,}})?                # ãƒ‰ãƒƒãƒˆãƒªãƒ¼ãƒ€ãƒ¼ or é€£ç¶šç©ºç™½
            {tail}\s*$                                   # è¡Œæœ«ã«ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«
        """
        return re.compile(pat, re.X)

    LABEL_TAIL_RE = build_label_tail_regex(scheme)

    
    def extract_toc_lines_for_gpt(fulltext: str, limit: int = 250) -> List[str]:
        """
        GPT ã«æ¸¡ã™ TOC è¡Œï¼šè¡Œé ­ãŒã€ç¬¬ã€oræ•°å­—ã§å§‹ã¾ã‚Šã€
        ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã«æ—¥æœ¬èªãªã©ã®æ–‡å­—ã‚’å«ã‚€è¡Œã®ã¿æ¡ç”¨ã€‚
        æ•°å­—ãƒ»è¨˜å·ãƒ»ç©ºç™½ã ã‘ã®è¡Œã¯é™¤å¤–ã€‚
        """
        lines = [l.rstrip() for l in fulltext.replace("\r\n","\n").replace("\r","\n").split("\n")]
        head_ok = re.compile(r"^(ç¬¬|[0-9ï¼-ï¼™])")               # âœ… è¡Œé ­ãŒã€Œç¬¬ã€oræ•°å­—
        text_char = re.compile(r"[A-Za-z\u3040-\u30FF\u4E00-\u9FFF]")  # âœ… æ–‡å­—ãŒå«ã¾ã‚Œã‚‹ã‹
        out: List[str] = []

        for ln in lines:
            s = ln.strip()
            if not s:
                continue
            # è¡Œé ­ãŒã€Œç¬¬ã€ã¾ãŸã¯æ•°å­—ã§å§‹ã¾ã‚‰ãªã„ â†’ é™¤å¤–
            if not head_ok.match(s):
                continue
            # ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ–‡å­—ï¼‰ãŒä¸€åˆ‡ãªã„ â†’ é™¤å¤–
            if not text_char.search(s):
                continue

            m = LABEL_TAIL_RE.match(s)
            if not m:
                continue

            head = re.sub(rf"\s*{LEADERS}\s*$", "", m.group("head")).strip()
            label = z2h_numhy(m.group("label"))

            # ã‚¿ã‚¤ãƒˆãƒ«ãŒçŸ­ã™ãã‚‹ã‚‚ã®ã‚‚é™¤å¤–
            if len(head) <= 1:
                continue

            out.append(f"{head} ::: {label}")
            if len(out) >= limit:
                break

        return out



    toc_lines = extract_toc_lines_for_gpt(fulltext)
    if not toc_lines:
        st.info("GPT ã«æ¸¡ã™ç›®æ¬¡å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.markdown("### æŠ½å‡ºã•ã‚ŒãŸç›®æ¬¡å€™è£œï¼ˆä¸Šä½ï¼‰")
        st.code("\n".join(toc_lines[:60]))

        # ---- GPT ã¸æŠ•ã’ã‚‹å…¥åŠ›ã‚’æº–å‚™ ----
        # ãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ã¯ is_page=True ã®ã‚‚ã®ã‚’å„ªå…ˆï¼ˆãªã‘ã‚Œã°å…¨ df ã‹ã‚‰ï¼‰
        try:
            valid_labels_series = df_pages["page_label"].astype(str)
        except Exception:
            valid_labels_series = df["page_label"].astype(str) if "page_label" in df.columns else pd.Series([], dtype=str)

        # ãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ã®ãŸã‚å…ˆé ­ N ä»¶ã ã‘
        VALID_MAX = 800
        TOC_MAX   = 250
        valid_labels_list = valid_labels_series.tolist()[:VALID_MAX]
        toc_for_prompt     = toc_lines[:TOC_MAX]

        system_prompt = (
            "ã‚ãªãŸã¯PDF/Wordãƒ¬ãƒãƒ¼ãƒˆã®æ ¡æ­£æ‹…å½“ã§ã™ã€‚"
            "ä¸ãˆã‚‰ã‚ŒãŸã€ç›®æ¬¡å€™è£œã®è¡Œã€ã¨ã€æŠ½å‡ºã•ã‚ŒãŸå®Ÿãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ä¸€è¦§ã€ã‚’ç…§åˆã—ã€"
            "å„ç›®æ¬¡è¡ŒãŒæŒ‡ã™ãƒšãƒ¼ã‚¸ç•ªå·ãŒå®Ÿåœ¨ã—ã¦ã„ã‚‹ã‹ã€ç« ç•ªå·ã¨æ•´åˆã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚"
            "çŸ­ãç®‡æ¡æ›¸ãã§ã€ä»¥ä¸‹ã®åˆ†é¡ã§å‡ºã—ã¦ãã ã•ã„ï¼š\n"
            "ãƒ»OKï¼ˆãƒšãƒ¼ã‚¸ãŒå­˜åœ¨ã—æ•´åˆï¼‰\n"
            "ãƒ»ã‚ºãƒ¬ï¼ˆãƒšãƒ¼ã‚¸ã¯å­˜åœ¨ã™ã‚‹ãŒç« ã‚„é †åºã®æ•´åˆãŒå¼±ã„ï¼‰\n"
            "ãƒ»ä¸æ˜ï¼ˆãƒšãƒ¼ã‚¸ãŒæœªæ¤œå‡ºï¼æœ¬æ–‡å´ã§è¦‹å½“ãŸã‚‰ãªã„ï¼‰\n"
            "ã¾ãŸã€æœ€å¾Œã«ã€å…¨éƒ¨OKã§ã‚ã‚Œã°ã€OKå¡—è£…ã§ãªã„æ™‚ã¯ã‚ºãƒ¬ã¦ã„ã‚‹ã¨æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚"
        )

        # ç« -ãƒšãƒ¼ã‚¸æ–¹å¼ã®ãƒ’ãƒ³ãƒˆï¼ˆä¾‹ï¼š3-60 ã®ç« =3 ã‚’ç« è¦‹å‡ºã—ã¨ç…§åˆã™ã‚‹æ–¹å‘æ€§ï¼‰
        scheme_hint = "ç« -ãƒšãƒ¼ã‚¸æ–¹å¼ï¼ˆä¾‹: 3-60ï¼‰ã€‚ç« ã¯ãƒã‚¤ãƒ•ãƒ³å·¦å´ã€‚" if scheme.startswith("(2)") else "é€£ç•ªæ–¹å¼ï¼ˆä¾‹: 1,2,3, ...ï¼‰ã€‚"

        user_prompt = (
            f"ã€æ–¹å¼ã€‘{scheme_hint}\n"
            "ã€ç›®æ¬¡å€™è£œï¼ˆå·¦ï¼šã‚¿ã‚¤ãƒˆãƒ«ã€å³ï¼šãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼‰ã€‘\n"
            + "\n".join(toc_for_prompt) + "\n\n"
            "ã€æŠ½å‡ºæ¸ˆã¿ã®å®Ÿãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼ˆis_page=True å„ªå…ˆï¼‰ã€‘\n"
            + ", ".join(valid_labels_list)
        )

        # ---- å‘¼ã³å‡ºã—ï¼ˆâ€» gpt-5-mini ã¯ temperature æŒ‡å®šä¸å¯ï¼‰----
        with st.spinner("GPT ã«ã‚ˆã‚‹ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­â€¦"):
            resp = client.chat.completions.create(
                model="gpt-5-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            )

        gpt_answer = resp.choices[0].message.content.strip()
        st.success("GPT ã«ã‚ˆã‚‹æ¤œè¨¼çµæœ")
        st.text_area("ğŸ” GPTã®åˆ¤å®šãƒ»æŒ‡æ‘˜", gpt_answer, height=420)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆMarkdownï¼‰
        md_buf = io.StringIO()
        md_buf.write("# ç›®æ¬¡ãƒšãƒ¼ã‚¸æ¤œè¨¼ï¼ˆGPTçµæœï¼‰\n\n")
        md_buf.write("## ç›®æ¬¡å€™è£œï¼ˆå…ˆé ­ï¼‰\n")
        md_buf.write("```\n" + "\n".join(toc_for_prompt) + "\n```\n\n")
        md_buf.write("## æŠ½å‡ºãƒšãƒ¼ã‚¸ãƒ©ãƒ™ãƒ«ï¼ˆæŠœç²‹ï¼‰\n")
        md_buf.write("```\n" + ", ".join(valid_labels_list[:200]) + "\n```\n\n")
        md_buf.write("## GPTã®å›ç­”\n\n")
        md_buf.write(gpt_answer + "\n")
        st.download_button(
            "ğŸ“¥ GPTçµæœã‚’Markdownã§ä¿å­˜",
            data=md_buf.getvalue().encode("utf-8"),
            file_name="toc_check_gpt_result.md",
            mime="text/markdown",
        )
