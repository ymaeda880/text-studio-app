# lib/text_loaders.py
# ------------------------------------------------------------
# ğŸ“¥ ãƒ†ã‚­ã‚¹ãƒˆèª­è¾¼ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ.txt / .docx / .pdf / pasteï¼‰
#  - UIï¼ˆStreamlitç­‰ï¼‰ã«ä¾å­˜ã—ãªã„ç´”ç²‹é–¢æ•°ç¾¤
#  - ä¾‹å¤–ã¯ RuntimeError ã‚’ä¸­å¿ƒã«æŠ•ã’ã‚‹ï¼ˆUIå´ã§æ•æ‰ã—ã¦è¡¨ç¤ºï¼‰
# ------------------------------------------------------------
from __future__ import annotations
from io import BytesIO
from typing import List, Dict, Union

# ========== åŸºæœ¬ãƒ­ãƒ¼ãƒ€ï¼ˆ.txt / .docx / .pdfï¼‰ ==========
def read_txt(file_or_bytes: Union[bytes, "UploadedFile"]) -> str:
    """
    .txt ã‚’æ–‡å­—åˆ—åŒ–ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®šï¼‰ã€‚
    file_or_bytes: bytes ã‹ã€.read() ã§ãã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆStreamlit UploadedFile ç­‰ï¼‰
    """
    data = file_or_bytes if isinstance(file_or_bytes, (bytes, bytearray)) else file_or_bytes.read()
    for enc in ("utf-8", "utf-16", "shift_jis", "cp932"):
        try:
            return bytes(data).decode(enc)
        except Exception:
            continue
    return bytes(data).decode("utf-8", errors="ignore")


def read_docx(file_or_bytes: Union[bytes, "UploadedFile"]) -> str:
    """
    .docx ã‚’æ®µè½ï¼‹è¡¨ã‹ã‚‰æŠ½å‡ºã—ã¦æ–‡å­—åˆ—åŒ–ã€‚
    """
    try:
        from docx import Document
    except ImportError as e:
        raise RuntimeError("python-docx ãŒå¿…è¦ã§ã™ã€‚`pip install python-docx` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚") from e

    data = file_or_bytes if isinstance(file_or_bytes, (bytes, bytearray)) else file_or_bytes.read()
    doc = Document(BytesIO(data))
    texts: List[str] = [p.text for p in doc.paragraphs]
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                texts.append(cell.text)
    return "\n".join(texts).strip()


def extract_pdf_text(data: bytes) -> Dict[str, Union[str, int]]:
    """
    PDFã®ãƒ†ã‚­ã‚¹ãƒˆå±¤ã‚’æŠ½å‡ºã—ã€çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™ã€‚
    returns: {"text": str, "visible": int, "pages": int}
      - text: æ”¹è¡Œä»˜ãã®æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ
      - visible: ç©ºç™½ä»¥å¤–ã®å°å­—å¯èƒ½æ–‡å­—æ•°ï¼ˆâ‰ˆãƒ†ã‚­ã‚¹ãƒˆå±¤ã®æœ‰ç„¡ã®ç›®å®‰ï¼‰
      - pages: PDFãƒšãƒ¼ã‚¸æ•°
    """
    try:
        import fitz  # PyMuPDF
    except ImportError as e:
        raise RuntimeError("pymupdf ãŒå¿…è¦ã§ã™ã€‚`pip install pymupdf` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚") from e

    try:
        doc = fitz.open(stream=data, filetype="pdf")
    except Exception as e:
        raise RuntimeError(f"PDFã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ: {e}") from e

    if doc.is_encrypted:
        doc.close()
        raise RuntimeError("ã“ã®PDFã¯æš—å·åŒ–ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¿è­·ï¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚")

    texts: List[str] = []
    try:
        for page in doc:
            t = page.get_text("text") or ""
            texts.append(t.strip())
        pages = len(doc)
    finally:
        doc.close()

    full = "\n".join(texts).strip()
    visible = sum(ch.isprintable() and not ch.isspace() for ch in full)
    return {"text": full, "visible": int(visible), "pages": int(pages)}


def load_text_generic(uploaded_file) -> str:
    """
    æ‹¡å¼µå­ã§ç°¡æ˜“åˆ†å²ã—ã¦æ–‡å­—åˆ—åŒ–ï¼ˆ.txt / .docx / .pdfï¼‰ã€‚
    - .pdf ã¯ãƒ†ã‚­ã‚¹ãƒˆå±¤ãŒãªã„å ´åˆã§ã‚‚ç©ºæ–‡å­—ã‚’è¿”ã—å¾—ã‚‹ï¼ˆUIå´ã§OCRã‚’æ¡ˆå†…ã™ã‚‹æƒ³å®šï¼‰
    """
    name = (uploaded_file.name or "").lower()
    if name.endswith(".txt"):
        return read_txt(uploaded_file)
    elif name.endswith(".docx"):
        return read_docx(uploaded_file)
    elif name.endswith(".pdf"):
        data = uploaded_file.read()
        stats = extract_pdf_text(data)
        return stats["text"].strip()
    else:
        raise RuntimeError("å¯¾å¿œå½¢å¼ã¯ .txt / .docx / .pdf ã«é™ã‚‰ã‚Œã¾ã™ã€‚")

# ========== è²¼ã‚Šä»˜ã‘ï¼ˆpasteï¼‰é–¢é€£ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========
def normalize_newlines(text: str) -> str:
    """æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã‚’ LF ã«æ­£è¦åŒ–ã€‚"""
    return text.replace("\r\n", "\n").replace("\r", "\n")

def strip_bom(text: str) -> str:
    """å…ˆé ­ã®BOMã‚’é™¤å»ã€‚"""
    return text.lstrip("\ufeff")

def collapse_blank_lines(text: str, keep: int = 1) -> str:
    """
    é€£ç¶šã™ã‚‹ç©ºè¡Œã‚’ keep è¡Œã¾ã§ã«åœ§ç¸®ã€‚keep>=1 ã‚’æ¨å¥¨ã€‚
    """
    lines = normalize_newlines(text).split("\n")
    out: List[str] = []
    blank_run = 0
    for ln in lines:
        if ln.strip() == "":
            blank_run += 1
            if blank_run <= keep:
                out.append("")
        else:
            blank_run = 0
            out.append(ln)
    return "\n".join(out)

def trim_trailing_spaces(text: str) -> str:
    """å„è¡Œæœ«ã®ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤ã€‚"""
    return "\n".join([ln.rstrip() for ln in normalize_newlines(text).split("\n")])

def load_text_from_paste(
    text: str,
    *,
    normalize: bool = True,
    collapse_blanks: bool = False,
    keep_blank_lines: int = 1,
    trim_trailing: bool = True,
) -> str:
    """
    è²¼ã‚Šä»˜ã‘ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢ã—ã¦è¿”ã™ã€‚
    - normalize=True: æ”¹è¡Œã‚’LFã«çµ±ä¸€ã—BOMé™¤å»
    - collapse_blanks=True: é€£ç¶šç©ºè¡Œã‚’ keep_blank_lines è¡Œã¾ã§åœ§ç¸®
    - trim_trailing=True: å„è¡Œæœ«ã®ä½™åˆ†ãªç©ºç™½ã‚’å‰Šã‚‹
    """
    if text is None:
        return ""
    s = text
    if normalize:
        s = strip_bom(normalize_newlines(s))
    if trim_trailing:
        s = trim_trailing_spaces(s)
    if collapse_blanks:
        s = collapse_blank_lines(s, keep=keep_blank_lines)
    return s.strip()
